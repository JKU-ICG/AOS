{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyaos.LFR_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7480\\2820526199.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyaos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLFR_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mread_poses_and_images\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpose_to_virtualcamera\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_aos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_window\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyaos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLFR_utils\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyaos.LFR_utils'"
     ]
    }
   ],
   "source": [
    "from bz2 import decompress\n",
    "from concurrent.futures import thread\n",
    "from filecmp import BUFSIZE\n",
    "from re import A\n",
    "import socket\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import zlib\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib as plt\n",
    "import math\n",
    "import utm\n",
    "import time\n",
    "from pyaos.LFR_utils import read_poses_and_images,pose_to_virtualcamera, init_aos, init_window\n",
    "import pyaos.LFR_utils as utils\n",
    "from pathlib import Path\n",
    "import pyaos.lfr as LFR\n",
    "from PIL import Image\n",
    "import glm\n",
    "from datetime import datetime\n",
    "import importlib\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from scipy import interpolate\n",
    "import spectral\n",
    "from skimage import img_as_float\n",
    "import utm\n",
    "import cv2\n",
    "import math\n",
    "import glm\n",
    "import scipy.interpolate\n",
    "import time\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Download_Location = r'C:\\Users\\Rakesh\\Downloads'\n",
    "print(Download_Location)\n",
    "Images_Path = os.path.join(Download_Location,'images')\n",
    "os.mkdir(Images_Path)\n",
    "Stages_Path = os.path.join(Download_Location,'stages')\n",
    "os.mkdir(Stages_Path)\n",
    "Integral_Path = os.path.join(Download_Location,'integrals')\n",
    "os.mkdir(Integral_Path)\n",
    "Live_Debug_Path = os.path.join(Download_Location,'live_debug')\n",
    "os.mkdir(Live_Debug_Path)\n",
    "Final_result = os.path.join(Download_Location,'Final_result')\n",
    "os.mkdir(Final_result)\n",
    "plots = os.path.join(Download_Location,'plots')\n",
    "os.mkdir(plots)\n",
    "leader_blob_image_folder = os.path.join(Download_Location,'leader_blob_image')\n",
    "os.mkdir(leader_blob_image_folder)\n",
    "leader_rx_image_folder = os.path.join(Download_Location,'leader_rx_image')\n",
    "os.mkdir(leader_rx_image_folder)\n",
    "gen_integral_blob_img_folder = os.path.join(Download_Location,'gen_integral_blob_img')\n",
    "os.mkdir(gen_integral_blob_img_folder)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import os\n",
    "# from zipfile import ZipFile\n",
    "# import json\n",
    "# import os\n",
    "  \n",
    "# path = r'C:\\Users\\Rakesh\\Downloads'  # path where the tree.json file shpould be kept\n",
    "\n",
    "# camera_info_file = os.path.join(path,'trees_500.json')\n",
    "# with open(camera_info_file) as json_file:\n",
    "#     camera_Dict = json.load(json_file)\n",
    "# print(len(camera_Dict['positions']))\n",
    "# xaxislist = []\n",
    "# zaxislist = []\n",
    "# yaxislist = []\n",
    "# for i in range (0, len(camera_Dict['positions'] )):\n",
    "#     xaxislist.append(camera_Dict['positions'][i]['x'])\n",
    "#     yaxislist.append(camera_Dict['positions'][i]['y'])\n",
    "#     zaxislist.append(camera_Dict['positions'][i]['z'])\n",
    "    \n",
    "# treex = ' '.join([str(item) for item in xaxislist])\n",
    "# treey = ' '.join([str(item) for item in zaxislist])\n",
    "treex = str(0)\n",
    "treey = str(0)\n",
    "\n",
    "#print(zaxislist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class evaluate_metric:\n",
    "    _aos = None\n",
    "    _fov = 22.815436217896945#43.10803984095769#43.50668199945787#50.815436217896945\n",
    "    _rx_threshold = 0.999\n",
    "    _debug = False\n",
    "    _x_off = 0.0\n",
    "    _y_off = 0.0\n",
    "    _f_ = None\n",
    "    _focalplane_height = 0.0\n",
    "    _compass_correction = 0.0\n",
    "    _integration_count = 0\n",
    "    _previous_img_mask = None\n",
    "    _previous_detection_pose = None\n",
    "    _prev_images = []\n",
    "    _prev_thermal_images = []\n",
    "    _current_thermal_images_list = []\n",
    "    _current_RGB_images_list = []\n",
    "    _current_center_camera_id = None\n",
    "    \n",
    "    _calc_leader_current_integral = True\n",
    "\n",
    "    _prev_images_poses = []\n",
    "    _prev_blob_images = []\n",
    "\n",
    "    def __init__(self,aos_ptr,fieldofview,rx_threshold, dem_height, compasscorrection, debug_mode = False):\n",
    "        self._aos = aos_ptr\n",
    "        self._fov = fieldofview\n",
    "        self._rx_threshold = rx_threshold\n",
    "        self._focalplane_height = dem_height\n",
    "        self._compass_correction = compasscorrection\n",
    "        self._debug = debug_mode\n",
    "        self._integration_count = 0\n",
    "        if self._debug:\n",
    "            # build random function\n",
    "            xc, yc = self.get_mesh()\n",
    "            #np.random.seed(100)#int(time.time())\n",
    "            np.random.seed(int(time.time()))\n",
    "            z = np.random.rand(*xc.shape)*30-15 # -15...15\n",
    "            self._x_off = self._y_off = 0.0\n",
    "            # define the objective function\n",
    "            self._f_ = interpolate.RBFInterpolator(self.to_linear(xc, yc), z.ravel())\n",
    "\n",
    "    def set_rx_threshold(self, rx_threshold):\n",
    "        self._rx_threshold = rx_threshold\n",
    "\n",
    "    def get_rx_threshold(self):\n",
    "        return self._rx_threshold\n",
    "    \n",
    "    def set_focalplane_height(self, dem_height):\n",
    "        self._focalplane_height = dem_height\n",
    "\n",
    "    def get_focalplane_height(self):\n",
    "        return self._focalplane_height\n",
    "    \n",
    "    def set_fov(self, fieldofview):\n",
    "        self._fov = fieldofview\n",
    "\n",
    "    def get_fov(self):\n",
    "        return self._fov\n",
    "    \n",
    "    def set_compass_correction(self, compasscorrection):\n",
    "        self._compass_correction = compasscorrection\n",
    "\n",
    "    def get_compass_correction(self):\n",
    "        return self._compass_correction\n",
    "    \n",
    "\n",
    "\n",
    "    def f(self, x,y):\n",
    "        #global x_off,y_off\n",
    "        s=np.reshape(self._f_(np.stack([x.ravel(),y.ravel()], -1)), x.shape)\n",
    "        m=np.sin((x/50)* (3.14/2))*np.sin((y/50)* (3.14/2))\n",
    "        m[m < 0.8] = 0\n",
    "        m[m > 0.8] = 1\n",
    "        #m=np.sin(x+self._x_off)*np.sin(y+self._y_off)\n",
    "        #m[m < 0.8] = 0\n",
    "        #m[m > 0.8] = 1\n",
    "        s=s*m\n",
    "        s[s == 0] = -15\n",
    "        return s     \n",
    "    def get_mesh(self,n=20): # meshsize\n",
    "        return np.meshgrid(np.linspace(0, 100, n),\n",
    "                       np.linspace(0, 100, n + 1))\n",
    "\n",
    "    def to_linear(self,x, y): \n",
    "        return np.stack([x.ravel(), y.ravel()], -1)\n",
    "\n",
    "    def divide_by_alpha(self,rimg2):\n",
    "        a = np.stack((rimg2[:,:,3],rimg2[:,:,3],rimg2[:,:,3]),axis=-1)\n",
    "        return rimg2[:,:,:3]/a\n",
    "\n",
    "    def pose_to_virtualcamera(self, vpose ):\n",
    "        vp = glm.mat4(*np.array(vpose).transpose().flatten())\n",
    "        #vp = vpose.copy()\n",
    "        ivp = glm.inverse(glm.transpose(vp))\n",
    "        #ivp = glm.inverse(vpose)\n",
    "        Posvec = glm.vec3(ivp[3])\n",
    "        Upvec = glm.vec3(ivp[1])\n",
    "        FrontVec = glm.vec3(ivp[2])\n",
    "        lookAt = glm.lookAt(Posvec, Posvec + FrontVec, Upvec)\n",
    "        cameraviewarr = np.asarray(lookAt)\n",
    "        #print(cameraviewarr)\n",
    "        return cameraviewarr\n",
    "        # #vp = glm.mat4(*np.array(vpose).transpose().flatten())\n",
    "        # inversecamerapose = glm.inverse(vpose)\n",
    "        # #ivp = glm.inverse(glm.transpose(inversecamerapose))\n",
    "        # Posvec = glm.vec3(inversecamerapose[3])\n",
    "        # Upvec = glm.vec3(inversecamerapose[1])\n",
    "        # FrontVec = glm.vec3(inversecamerapose[2])\n",
    "        # cameraviewarr = np.array(glm.lookAt(Posvec, Posvec + FrontVec, Upvec)) \n",
    "        # return cameraviewarr\n",
    "        # #lookAt = glm.lookAt(Posvec, Posvec + FrontVec, Upvec)\n",
    "        # #return np.asarray(glm.transpose(lookAt))\n",
    "   \n",
    "\n",
    "    def detect_anomaly(self,single_images, confCoefficient):\n",
    "        bw_images_list = []\n",
    "        rx_images_list = []\n",
    "        print(\"confCoefficient\", confCoefficient)\n",
    "        for i in range(len(single_images)):\n",
    "            RGB_image = single_images[i]\n",
    "            rxScore = spectral.rx(RGB_image)\n",
    "            min_rx_score = np.min(rxScore)\n",
    "            max_rx_score = np.max(rxScore)\n",
    "            rxScore = img_as_float(rxScore)\n",
    "            rescaled_rx_score = ((rxScore - min_rx_score) / (max_rx_score - min_rx_score))\n",
    "            rescaled_rx_score_int = np.asarray(rescaled_rx_score*255,dtype=np.uint8)\n",
    "            #print('Normalized Max Score:', np.min(rescaled_rx_score_int))\n",
    "            #print('Normalized Min Score:', np.max(rescaled_rx_score_int))\n",
    "            count, bins_count = np.histogram(rescaled_rx_score_int, bins = 256)\n",
    "            # finding the PDF of the histogram using count values\n",
    "            pdf = count / np.prod(np.size(rescaled_rx_score_int)) \n",
    "            # using numpy np.cumsum to calculate the CDF\n",
    "            # We can also find using the PDF values by looping and adding\n",
    "            cdf = np.cumsum(pdf)\n",
    "            rxThreshold = [ n for n,i in enumerate(cdf) if i>confCoefficient ][1]\n",
    "            ##rxThreshold =  np.nonzero(cdf > confCoefficient, 1 );\n",
    "            print ('RX Threshold: ' , rxThreshold)\n",
    "            rx_images_list.append(rxScore)\n",
    "            bw = rescaled_rx_score_int > rxThreshold\n",
    "            cv_bw = np.asarray(bw*255,dtype=np.uint8)\n",
    "            img = np.zeros((cv_bw.shape[0],cv_bw.shape[1],3),dtype=RGB_image.dtype)\n",
    "            img[:,:,0] = cv_bw\n",
    "            img[:,:,1] = cv_bw\n",
    "            img[:,:,2] = cv_bw\n",
    "            bw_images_list.append(img)\n",
    "            #cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_' + str(i)+'_rx_blob.png'), img)\n",
    "            #nzCount = np.count_nonzero(bw)\n",
    "            #print('Total NZ Count after Threshold: ', nzCount)\n",
    "        return bw_images_list,rx_images_list\n",
    "    \n",
    "    def project_images_to_all(self,aos, img_list, pose_list,fov,center_camera_index = None, project_images = False):\n",
    "        aos.clearViews()\n",
    "        proj_img_list = []\n",
    "        for i in range(len(img_list)):\n",
    "            aos.addView(img_list[i], pose_list[i], \"DEM BlobTrack\")\n",
    "        aos.setDEMTransform([0,0,self._focalplane_height])\n",
    "        #aos.setPoseCorrectionall(len(img_list),[0,0,0], [0,0, self._compass_correction])\n",
    "        for i in range(len(img_list)):\n",
    "            renderering_ids = []\n",
    "            if project_images:\n",
    "                renderering_ids.append(i)\n",
    "                if center_camera_index == None:\n",
    "                    for j in range(len(img_list)):\n",
    "                        cmr_proj = []\n",
    "                        img_renderering_ids = []\n",
    "                        img_renderering_ids.append(j)\n",
    "                        #proj_img = aos.render(self.pose_to_virtualcamera(aos.getPose(i)), fov, img_renderering_ids)\n",
    "                        proj_img = aos.render(self.pose_to_virtualcamera(pose_list[i]), fov, img_renderering_ids)\n",
    "                        tmp = self.divide_by_alpha(proj_img)\n",
    "                        cmr_proj.append(tmp)\n",
    "                    proj_img_list.append(cmr_proj)\n",
    "                else:\n",
    "                    proj_img = aos.render(self.pose_to_virtualcamera(pose_list[center_camera_index]), fov, renderering_ids)\n",
    "                    tmp = self.divide_by_alpha(proj_img)\n",
    "                    proj_img_list.append(tmp)\n",
    "            else:\n",
    "                if center_camera_index == None:\n",
    "                    proj_img = aos.render(self.pose_to_virtualcamera(pose_list[i]), fov, renderering_ids)\n",
    "                    tmp = self.divide_by_alpha(proj_img)\n",
    "                    proj_img_list.append(tmp)\n",
    "                else:\n",
    "                    if i == center_camera_index:\n",
    "                        proj_img = aos.render(self.pose_to_virtualcamera(pose_list[center_camera_index]), fov, renderering_ids)\n",
    "                        tmp = self.divide_by_alpha(proj_img)\n",
    "                        proj_img_list.append(tmp)\n",
    "        return proj_img_list\n",
    "\n",
    "    def find_center_camera_highest_projection(self,image_list):\n",
    "        max_contour_img_id = None\n",
    "        max_countour_list = []\n",
    "        max_countour_center_list = []\n",
    "        max_contour_bounding_rect_list = []\n",
    "        contour_img = np.zeros((image_list[0].shape[0],image_list[0].shape[1]))\n",
    "        ################For all Images calculate contours and find max###########################################\n",
    "        #######################contour in each images######################################################\n",
    "        for i in range(len(image_list)):\n",
    "            contours,hierarchy  = cv2.findContours(np.asarray(image_list[i][:,:,0],dtype=np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            max_countour = 0\n",
    "            max_countour_center = ()\n",
    "            max_contour_bounding_rect = ()\n",
    "            #print(i,len(contours))\n",
    "            for k in range(len(contours)):\n",
    "                contour_area = cv2.contourArea(contours[k])\n",
    "                x,y,w,h = cv2.boundingRect(contours[k])\n",
    "                #contour_area_list.append(contour_area)\n",
    "                if contour_area > max_countour:\n",
    "                    max_countour = contour_area\n",
    "                    M = cv2.moments(contours[k])\n",
    "                    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                    max_countour_center = (cX,cY)\n",
    "                    max_contour_bounding_rect = (x,y,w,h)\n",
    "            max_countour_list.append(max_countour)\n",
    "            max_countour_center_list.append(max_countour_center)\n",
    "            max_contour_bounding_rect_list.append(max_contour_bounding_rect)\n",
    "        ################For Image Indices with Highest Contour###########################################\n",
    "        #################If Two Image has same Contour length######################################################\n",
    "        #################than select one where blob is closer to center######################################################\n",
    "        print(\"Integral max_countour_list\", max_countour_list)\n",
    "        print(\"Integral max_countour_list\", max_countour_center_list)\n",
    "        max_indices = [index for index, item in enumerate(max_countour_list) if item == max(max_countour_list)]\n",
    "        if len(max_indices) > 1:\n",
    "            distance_center = 10000000\n",
    "            for i in range(len(max_indices)):\n",
    "                distance = math.sqrt(math.pow((max_countour_center_list[i][0] - 512),2)+ math.pow((max_countour_center_list[i][1] - 512),2))\n",
    "                if distance < distance_center:\n",
    "                    max_contour_img_id = max_indices[i]\n",
    "                    distance_center  = distance\n",
    "        else:\n",
    "            max_contour_img_id = max_indices[0]\n",
    "        ################Get Bounding box location of contour and create###########################################\n",
    "        ######################mask image with rect set to 255######################################################\n",
    "        rect = max_contour_bounding_rect_list[max_contour_img_id]\n",
    "        print(\"max_contour_img_id\", max_contour_img_id)\n",
    "        print(\"rect of bounding box\", rect)\n",
    "        contour_img[rect[1]:rect[1]+rect[3],rect[0]:rect[0]+rect[2]] = 255\n",
    "        center_img_max_contour  = max_countour_list[max_contour_img_id]\n",
    "        ################return center image with highest contour and ###########################################\n",
    "        ######################its corresponding mask image and ######################################################\n",
    "        ######################its corresponding contour area######################################################\n",
    "        return max_contour_img_id, contour_img, center_img_max_contour,rect\n",
    "    \n",
    "    def find_leader(self,single_proj_img, mask_img):\n",
    "        max_contour = 0\n",
    "        leader_id = None\n",
    "        ################For all Images calculate contours within the mask###########################################\n",
    "        #######################and find image with maximum contour######################################################\n",
    "        for i in range(len(single_proj_img)):\n",
    "            img = single_proj_img[i]\n",
    "            tmp_img = np.asarray(img[:,:,0],dtype=np.uint8)\n",
    "            tmp_mask_img = np.asarray(mask_img,dtype=np.uint8)\n",
    "            #print(\"sizes\", tmp_img.shape, tmp_mask_img.shape)\n",
    "            #print(\"dtype\", tmp_img.dtype, tmp_mask_img.dtype)\n",
    "            #tmp_img = np.zeros((single_proj_img[i].shape[0],single_proj_img[i].shape[1]),dtype=np.uint8)\n",
    "            cnt_tmp_img = np.zeros((single_proj_img[i].shape[0],single_proj_img[i].shape[1]),dtype=np.uint8)\n",
    "            cv2.bitwise_and(tmp_img, tmp_mask_img, cnt_tmp_img)\n",
    "            contours,hierarchy  = cv2.findContours(np.asarray(cnt_tmp_img[:,:],dtype=np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            curr_img_max_contour = 0\n",
    "            for k in range(len(contours)):\n",
    "                contour_area = cv2.contourArea(contours[k])\n",
    "                if contour_area > curr_img_max_contour:\n",
    "                    curr_img_max_contour = contour_area\n",
    "            print(\"Single curr_img_max_contour\", i, curr_img_max_contour)\n",
    "            if curr_img_max_contour > max_contour:\n",
    "                max_contour = curr_img_max_contour\n",
    "                leader_id = i\n",
    "        ################return leader index and maximum contour size within the leader###########################################\n",
    "        #######################and find image with maximum contour######################################################\n",
    "        return leader_id, max_contour\n",
    "    \n",
    "    def find_leader_within_images(self,single_images,site_poses, fov = None, rxthreshold =  None, dem_height = None, compasscorrection = None ,pos = None):\n",
    "        if fov == None:\n",
    "            fov = self._fov\n",
    "        else:\n",
    "            self._fov = fov\n",
    "        if rxthreshold == None:\n",
    "            rxthreshold = self._rx_threshold\n",
    "        else:\n",
    "            self._rx_threshold = rxthreshold\n",
    "        if dem_height == None:\n",
    "            dem_height = self._focalplane_height\n",
    "        else :\n",
    "            self._focalplane_height = dem_height\n",
    "        if compasscorrection == None:\n",
    "            compasscorrection = self._compass_correction\n",
    "        else :\n",
    "            self._compass_correction = compasscorrection\n",
    "        if self._debug:\n",
    "            obj = self.f(pos[0], pos[1])\n",
    "            Leader_index = obj.argmax()\n",
    "            leader_contour = obj[Leader_index]\n",
    "        else :\n",
    "            self._current_thermal_images_list = []\n",
    "            self._current_RGB_images_list = []\n",
    "            if len(single_images)>=1:\n",
    "                no_channels = single_images[0].shape[2]\n",
    "                if no_channels > 3:\n",
    "                    for i in range(len(single_images)):\n",
    "                        img = single_images[i]\n",
    "                        rgb_img = img[:,:,0:3]\n",
    "                        thermal_img = np.zeros(rgb_img.shape,dtype = rgb_img.dtype)\n",
    "                        thermal_img[:,:,0] = img[:,:,3]\n",
    "                        thermal_img[:,:,1] = img[:,:,3]\n",
    "                        thermal_img[:,:,2] = img[:,:,3]\n",
    "                        self._current_RGB_images_list.append(rgb_img)\n",
    "                        self._current_thermal_images_list.append(thermal_img)\n",
    "                elif no_channels == 3:\n",
    "                    for i in range(len(single_images)):\n",
    "                        img = single_images[i]\n",
    "                        self._current_RGB_images_list.append(rgb_img)\n",
    "  \n",
    "            rgb_integral_images = self.project_images_to_all(self._aos, self._current_RGB_images_list, site_poses,fov,center_camera_index=None,project_images=False)\n",
    "            if len(self._current_thermal_images_list)>= 1:\n",
    "                thermal_integral_images = self.project_images_to_all(self._aos, self._current_thermal_images_list, site_poses,fov,center_camera_index=None,project_images=False)\n",
    "            ################################################################\n",
    "            ##############After Generating Blob Images############################\n",
    "            #########Set Each camera as virtual camera and ####################\n",
    "            ##############project all Rx_bw images###########################\n",
    "            #print(\"len of single images\", len(single_images))\n",
    "            #########First do Blob detection on all Single Images###########\n",
    "            blob_images,rx_images = self.detect_anomaly(single_images, confCoefficient = rxthreshold)\n",
    "            ###############REquired Images##########################################\n",
    "            tmp_blob_images = blob_images\n",
    "            tmp_rx_images = rx_images\n",
    "            #display_all(single_images) //---- display all Single Images in subplots\n",
    "            #display_all(blob_images) //---- display all bw Images in subplots\n",
    "            ################################################################\n",
    "            ##############After Generating Blob Images############################\n",
    "            #########Set Each camera as virtual camera and ####################\n",
    "            ##############project all Rx_bw images###########################\n",
    "            proj_images = self.project_images_to_all(self._aos, blob_images, site_poses,fov,center_camera_index=None,project_images=False)\n",
    "            #print(len(proj_images))  //debug\n",
    "            ################################################################\n",
    "            ##############After Generating integrated Blob Images############################\n",
    "            #########Find Which Image contains the Maximum Contour ####################\n",
    "            ##########and generate a Mask Image with the maximum contour###########################\n",
    "            center_camera_id, mask_img, center_camera_max_contour_area,rect = self.find_center_camera_highest_projection(proj_images)\n",
    "            self._current_center_camera_id = center_camera_id\n",
    "            #print(center_camera_id)  //debug\n",
    "            if self._calc_leader_current_integral == False:\n",
    "                #######################################################################\n",
    "                ##############After Finding the Center Camera############################\n",
    "                #########Find Projection of All images to this Camera####################\n",
    "                ########################################################################\n",
    "                single_proj_images = self.project_images_to_all(self._aos, blob_images, site_poses,fov,center_camera_index=center_camera_id,project_images=True)\n",
    "                ################################################################\n",
    "                ##############Now Find Leader############################\n",
    "                #########By Finding largest Contour in this Image####################\n",
    "                ###################################################################\n",
    "                Leader_index, leader_contour = self.find_leader(single_proj_images,mask_img)\n",
    "                leader_blob_image = tmp_blob_images[Leader_index]\n",
    "            else:\n",
    "                Leader_index = center_camera_id\n",
    "                leader_contour = center_camera_max_contour_area\n",
    "                leader_blob_image = proj_images[Leader_index]\n",
    "            \n",
    "            leader_rx_image = tmp_rx_images[Leader_index]\n",
    "            print(\"leader_rx_image datatype\",leader_rx_image.dtype)\n",
    "            print(\"leader_rx_image dimensions\",leader_rx_image.shape)\n",
    "            \n",
    "            #Leader_index = 1\n",
    "            #center_camera_id = 1\n",
    "            center_rx_integral_image  = np.asarray(proj_images[center_camera_id],dtype=np.uint8)\n",
    "            center_rgb_integral_image  = np.asarray(rgb_integral_images[center_camera_id],dtype=np.uint8)\n",
    "            #leader_rx_image_proj = np.asarray(single_proj_images[Leader_index],dtype=np.uint8)\n",
    "            leader_unprojected_rx_image = np.asarray(blob_images[Leader_index],dtype=np.uint8)\n",
    "            center_thermal_integral_image = np.zeros((single_images[0].shape[0],single_images[0].shape[1],single_images[0].shape[2]),dtype=np.uint8)\n",
    "            if len(self._current_thermal_images_list)>= 1:\n",
    "                center_thermal_integral_image = np.asarray(thermal_integral_images[center_camera_id],dtype=np.uint8)\n",
    "                cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_thermal_integral.png'), center_thermal_integral_image)\n",
    "                cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_thermal_integral.png'), center_thermal_integral_image)\n",
    "            #datasets_folder_live_debug = os.path.join( r\"E:\\Droneswarms_Feb_clientserverdevelopment\\live_debug\" )\n",
    "            cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+'_'+str(int(Leader_index))+'_'+str(rxthreshold)+ '_rxunprojected.png'), leader_unprojected_rx_image); \n",
    "            #cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+'_'+str(int(Leader_index))+'_'+str(int(leader_contour))+ '_rx.png'), leader_rx_image_proj); \n",
    "            cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_integral.png'), center_rgb_integral_image)\n",
    "            cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+'_'+str(int(center_camera_id))+'_'+str(int(center_camera_max_contour_area))+ '_rxintegral.png'), center_rx_integral_image)\n",
    "            cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_integral.png'), center_rgb_integral_image)\n",
    "            print('Image integral Dimensions :', center_rgb_integral_image.shape);\n",
    "            #cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+'_'+str(int(center_camera_id))+'_'+str(int(center_camera_max_contour_area))+ '_rxintegral.png'), center_rx_integral_image)\n",
    "            center_mask_img = np.asarray(mask_img,dtype=np.uint8)\n",
    "            cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+'_'+str(int(Leader_index))+'_'+str(int(leader_contour))+ '_rxintegralmask.png'), center_mask_img)\n",
    "        return Leader_index, leader_contour, center_mask_img, center_camera_id,leader_blob_image, leader_rx_image,rect\n",
    "            \n",
    "        #     center_rgb_integral_image  = np.asarray(rgb_integral_images[center_camera_id],dtype=np.uint8)\n",
    "        #     leader_rx_image = np.asarray(single_proj_images[Leader_index],dtype=np.uint8)\n",
    "        #     datasets_folder_drone2 = os.path.join( r\"E:\\Droneswarms_Feb_clientserverdevelopment\\drone2\" )\n",
    "        #     cv2.imwrite(os.path.join( datasets_folder_drone2,  str(self._integration_count)+ '_rx.jpg'), leader_rx_image); \n",
    "        #     cv2.imwrite(os.path.join( datasets_folder_drone2,  str(self._integration_count)+ '_integral.jpg'), center_rgb_integral_image);\n",
    "        #     self._integration_count = self._integration_count + 1\n",
    "        #     center_mask_img = np.asarray(mask_img,dtype=np.uint8)\n",
    "        # return Leader_index, leader_contour, center_mask_img, center_camera_id\n",
    "    \n",
    "    def get_relevent_info(self,single_images,site_poses, fov = None, rxthreshold =  None, dem_height = None, compasscorrection = None , pos = None):\n",
    "        if fov == None:\n",
    "            fov = self._fov\n",
    "        else:\n",
    "            self._fov = fov\n",
    "        if rxthreshold == None:\n",
    "            rxthreshold = self._rx_threshold\n",
    "        else:\n",
    "            self._rx_threshold = rxthreshold\n",
    "        if dem_height == None:\n",
    "            dem_height = self._focalplane_height\n",
    "        else :\n",
    "            self._focalplane_height = dem_height\n",
    "        if compasscorrection == None:\n",
    "            compasscorrection = self._compass_correction\n",
    "        else :\n",
    "            self._compass_correction = compasscorrection\n",
    "        ################################################################\n",
    "        ##############After Generating Blob Images############################\n",
    "        #########Set Each camera as virtual camera and ####################\n",
    "        ##############project all Rx_bw images###########################\n",
    "        print(\"len of single images\", len(single_images))\n",
    "        rgb_integral_images = self.project_images_to_all(self._aos, single_images, site_poses,fov,center_camera_index=None,project_images=False)\n",
    "        #########First do Blob detection on all Single Images###########\n",
    "        blob_images,rx_images = self.detect_anomaly(single_images, confCoefficient = rxthreshold)\n",
    "        print(\"len of blob images\", len(blob_images))\n",
    "        for i in range(len(blob_images)):\n",
    "            cv2.imwrite(os.path.join( Live_Debug_Path,  str(i)+ '_blobimages_debug_blobthreshold.png'), np.asarray(blob_images[i],dtype=np.uint8))\n",
    "        #display_all(single_images) //---- display all Single Images in subplots\n",
    "        #display_all(blob_images) //---- display all bw Images in subplots\n",
    "        ################################################################\n",
    "        ##############After Generating Blob Images############################\n",
    "        #########Set Each camera as virtual camera and ####################\n",
    "        ##############project all Rx_bw images###########################\n",
    "        proj_images = self.project_images_to_all(self._aos, blob_images, site_poses,fov,center_camera_index=None,project_images=False)\n",
    "        print(\"len of proj images\", len(proj_images))\n",
    "        for i in range(len(proj_images)):\n",
    "            cv2.imwrite(os.path.join( Live_Debug_Path,  str(i)+ '_integral_debug_blobthreshold.png'), np.asarray(proj_images[i],dtype=np.uint8))\n",
    "        #print(len(proj_images))  //debug\n",
    "        ################################################################\n",
    "        ##############After Generating integrated Blob Images############################\n",
    "        #########Find Which Image contains the Maximum Contour ####################\n",
    "        ##########and generate a Mask Image with the maximum contour###########################\n",
    "        center_camera_id, mask_img, center_camera_max_contour_area,rect = self.find_center_camera_highest_projection(proj_images)\n",
    "        #print(center_camera_id)  //debug\n",
    "        if self._calc_leader_current_integral == False:\n",
    "            #######################################################################\n",
    "            ##############After Finding the Center Camera############################\n",
    "            #########Find Projection of All images to this Camera####################\n",
    "            ########################################################################\n",
    "            single_proj_images = self.project_images_to_all(self._aos, blob_images, site_poses,fov,center_camera_index=center_camera_id,project_images=True)\n",
    "            ################################################################\n",
    "            ##############Now Find Leader############################\n",
    "            #########By Finding largest Contour in this Image####################\n",
    "            ###################################################################\n",
    "            Leader_index, leader_contour = self.find_leader(single_proj_images,mask_img)\n",
    "            leader_rx_image = np.asarray(single_proj_images[Leader_index],dtype=np.uint8)\n",
    "        else:\n",
    "            Leader_index = center_camera_id\n",
    "            leader_contour = center_camera_max_contour_area\n",
    "            leader_rx_image = np.asarray(proj_images[Leader_index],dtype=np.uint8)\n",
    "\n",
    "\n",
    "        center_rgb_integral_image  = np.asarray(rgb_integral_images[center_camera_id],dtype=np.uint8)\n",
    "        \n",
    "        return center_rgb_integral_image, leader_rx_image, Leader_index, leader_contour\n",
    "        \n",
    "    \n",
    "    def should_add_image_integral(self,aos,integral_img,single_img,img_poses,fov = 22.815436217896945,rx_threshold = 0.998):\n",
    "        #########First do Blob detection on all Integral Image###########\n",
    "        blob_images,rx_images = self.detect_anomaly(integral_img, confCoefficient = rx_threshold)\n",
    "        #display_all(single_images) //---- display all Single Images in subplots\n",
    "        #display_all(blob_images) //---- display all bw Images in subplots\n",
    "        ################################################################\n",
    "        ##############After Generating integrated Blob Images############################\n",
    "        #########Find Which Image contains the Maximum Contour ####################\n",
    "        ##########and generate a Mask Image with the maximum contour###########################\n",
    "        center_camera_id, mask_img, center_camera_max_contour_area,rect = self.find_center_camera_highest_projection(blob_images)\n",
    "        #print(center_camera_id)  //debug\n",
    "        future_integaral_img_list = []\n",
    "        future_integaral_img_list.append(integral_img)\n",
    "        future_integaral_img_list.append(single_img)\n",
    "        #######################################################################\n",
    "        ##############After Finding the Center Camera############################\n",
    "        #########Find Projection of All images to this Camera####################\n",
    "        ########################################################################\n",
    "        future_integaral_img = self.project_images_to_all(self._aos, future_integaral_img_list, img_poses,fov,center_camera_index=0,project_images=False)\n",
    "        ################################################################\n",
    "        ##############Now Find Leader############################\n",
    "        #########By Finding largest Contour in this Image####################\n",
    "        ###################################################################\n",
    "        center_camera_id, mask_img, future_integaral_img_max_contour_area = self.find_center_camera_highest_projection(future_integaral_img)\n",
    "        if (center_camera_max_contour_area >= future_integaral_img_max_contour_area ):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "            \n",
    "    def integrate_informative_images(self, single_images, single_poses, virtual_camera_pose, detection_mask = None, detection_pose = None):\n",
    "        ############generate blob images --- can be optimized later to remove anomaly detection again and again####################################\n",
    "        blob_images,rx_images = self.detect_anomaly(single_images, confCoefficient = self._rx_threshold)\n",
    "        self._aos.clearViews()\n",
    "        prev_img_max_contour = 0\n",
    "        gen_integral_blob_img = np.zeros((blob_images[0].shape[0],blob_images[0].shape[1]),dtype=np.uint8)\n",
    "        ##########################Check if previous mask is there if not if there is new mask use it########################################\n",
    "        if detection_mask is None:\n",
    "            current_detection_mask = self._previous_img_mask\n",
    "            current_detection_pose = self._previous_detection_pose\n",
    "        else:\n",
    "            current_detection_mask = detection_mask\n",
    "            current_detection_pose = detection_pose\n",
    "            self._previous_img_mask = detection_mask\n",
    "            self._previous_detection_pose = detection_pose\n",
    "        if type(current_detection_mask) is np.ndarray :\n",
    "            ##########################Project the mask to current virtual camera########################################\n",
    "            self._aos.addView(current_detection_mask, current_detection_pose, \"Detection Mask\")\n",
    "            img_renderering_ids = []\n",
    "            self._aos.setDEMTransform([0,0,self._focalplane_height])\n",
    "            #aos.setPoseCorrectionall(1,[0,0,0], [0,0, self._compass_correction])\n",
    "            tmp_projected_detection_mask = self._aos.render(self.pose_to_virtualcamera(single_poses[self._current_center_camera_id]), self._fov, img_renderering_ids)\n",
    "            projected_detection_mask = self.divide_by_alpha(tmp_projected_detection_mask)\n",
    "            self._aos.clearViews()\n",
    "            prev_img_max_contour = 0\n",
    "            ##########################If previous images exist than find best contour of prev integral using previous blob images########################################\n",
    "            if len(self._prev_images) != 0:\n",
    "                for i in range(len(self._prev_images)):\n",
    "                    self._aos.addView(self._prev_blob_images[i], self._prev_images_poses[i], \"DEM BlobTrack\")\n",
    "                img_renderering_ids = []\n",
    "                self._aos.setDEMTransform([0,0,self._focalplane_height])\n",
    "                #aos.setPoseCorrectionall(len(self._prev_blob_images),[0,0,0], [0,0, self._compass_correction])\n",
    "                tmp_prev_integ__blob_img = self._aos.render(self.pose_to_virtualcamera(single_poses[self._current_center_camera_id]), self._fov, img_renderering_ids)\n",
    "                prev_integ__blob_img = self.divide_by_alpha(tmp_prev_integ__blob_img)\n",
    "                tmp_img = np.asarray(prev_integ__blob_img[:,:,0],dtype=np.uint8)\n",
    "                tmp_mask_img = np.asarray(projected_detection_mask[:,:,0],dtype=np.uint8)\n",
    "                prev_tmp_img = np.zeros((tmp_img.shape[0],tmp_img.shape[1]),dtype=np.uint8)\n",
    "                cv2.bitwise_and(tmp_img, tmp_mask_img, prev_tmp_img)\n",
    "                gen_integral_blob_img = np.asarray(prev_tmp_img[:,:],dtype=np.uint8)\n",
    "                contours,hierarchy  = cv2.findContours(np.asarray(prev_tmp_img[:,:],dtype=np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                for k in range(len(contours)):\n",
    "                    contour_area = cv2.contourArea(contours[k])\n",
    "                    if contour_area > prev_img_max_contour:\n",
    "                        prev_img_max_contour = contour_area\n",
    "            print(\"prev_contour_area\",prev_img_max_contour)\n",
    "            ##########################Check if adding image to the rendering improve integral or not########################################\n",
    "            added_prev_img = True\n",
    "            for i in range(len(single_images)):\n",
    "                if added_prev_img:\n",
    "                    print(\"Added View\")\n",
    "                    self._aos.addView(blob_images[i], single_poses[i], \"DEM BlobTrack\")\n",
    "                else:\n",
    "                    print(\"Replaced View\")\n",
    "                    self._aos.replaceView(self._aos.getViews()-1,blob_images[i], single_poses[i], \"DEM BlobTrack\")\n",
    "                img_renderering_ids = []\n",
    "                self._aos.setDEMTransform([0,0,self._focalplane_height])\n",
    "                #aos.setPoseCorrectionall(self._aos.getViews(),[0,0,0], [0,0, self._compass_correction])\n",
    "                tmp_tmp_integral_img = self._aos.render(self.pose_to_virtualcamera(single_poses[self._current_center_camera_id]), self._fov, img_renderering_ids)\n",
    "                tmp_integral_img = self.divide_by_alpha(tmp_tmp_integral_img)\n",
    "                tmp_img = np.asarray(tmp_integral_img[:,:,0],dtype=np.uint8)\n",
    "                tmp_mask_img = np.asarray(projected_detection_mask[:,:,0],dtype=np.uint8)\n",
    "                curr_tmp_img = np.zeros((tmp_img.shape[0],tmp_img.shape[1]),dtype=np.uint8)\n",
    "                cv2.bitwise_and(tmp_img, tmp_mask_img, curr_tmp_img)\n",
    "                contours,hierarchy  = cv2.findContours(np.asarray(curr_tmp_img[:,:],dtype=np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                add_img = False\n",
    "                for k in range(len(contours)):\n",
    "                    contour_area = cv2.contourArea(contours[k])\n",
    "                    print(\"curr_contour_area and Image Added\",prev_img_max_contour)\n",
    "                    if contour_area > prev_img_max_contour:\n",
    "                        prev_img_max_contour = contour_area\n",
    "                        print(\"curr_contour_area and Image Added\",prev_img_max_contour)\n",
    "                        add_img = True\n",
    "                if add_img:\n",
    "                    print(\"Added to Prev List\")\n",
    "                    added_prev_img = True\n",
    "                    self._prev_blob_images.append(blob_images[i])\n",
    "                    self._prev_images.append(self._current_RGB_images_list[i])\n",
    "                    if len(self._current_thermal_images_list)>= 1:\n",
    "                        self._prev_thermal_images.append(self._current_thermal_images_list[i])\n",
    "                    self._prev_images_poses.append(single_poses[i])\n",
    "                    gen_integral_blob_img = np.asarray(curr_tmp_img[:,:],dtype=np.uint8)\n",
    "                else :\n",
    "                    print(\"Do not Add to Prev List\")\n",
    "                    added_prev_img = False       \n",
    "        else:\n",
    "            print(\"same as integral image\")\n",
    "            rgb_integral_images = self.project_images_to_all(self._aos, self._current_RGB_images_list, single_poses,self._fov,center_camera_index=None,project_images=False)\n",
    "            if len(self._current_thermal_images_list)>= 1:\n",
    "                thermal_integral_images = self.project_images_to_all(self._aos, self._current_thermal_images_list, single_poses,self._fov,center_camera_index=None,project_images=False)\n",
    "                thermal_integral_img = np.asarray(thermal_integral_images[self._current_center_camera_id],dtype=np.uint8)\n",
    "                cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_gen_thermal_integral.png'), thermal_integral_img)\n",
    "                cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_thermal_integral.png'), thermal_integral_img)\n",
    "            rgb_integral_img  = np.asarray(rgb_integral_images[self._current_center_camera_id],dtype=np.uint8)\n",
    "            cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_gen_integral.png'), rgb_integral_img)  \n",
    "            cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_integral.png'), rgb_integral_img) \n",
    "\n",
    "        self._aos.clearViews()\n",
    "        len_info = []\n",
    "        len_info.append(str(len(self._prev_images)) + '\\n')\n",
    "        with open(os.path.join(Live_Debug_Path,'History_Info.txt'), 'a') as f:\n",
    "            f.writelines('\\n'.join(len_info))\n",
    "        \n",
    "        print(len(self._prev_images))\n",
    "        if len(self._prev_images) :\n",
    "            for i in range(len(self._prev_images)):\n",
    "                    self._aos.addView(self._prev_images[i], self._prev_images_poses[i], \"DEM BlobTrack\")\n",
    "            img_renderering_ids = []\n",
    "            self._aos.setDEMTransform([0,0,self._focalplane_height])\n",
    "            #aos.setPoseCorrectionall(len(self._prev_blob_images),[0,0,0], [0,0, self._compass_correction])\n",
    "            #tmp_rgb_integral_img = self._aos.render(self.pose_to_virtualcamera(virtual_camera_pose), self._fov, img_renderering_ids) ## edited in oct\n",
    "            tmp_rgb_integral_img = self._aos.render(self.pose_to_virtualcamera(single_poses[self._current_center_camera_id]), self._fov, img_renderering_ids)\n",
    "            rgb_integral_img = self.divide_by_alpha(tmp_rgb_integral_img)\n",
    "            #datasets_folder_live_debug= os.path.join( r\"E:\\Droneswarms_Feb_clientserverdevelopment\\live_debug\" )\n",
    "            #cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_integral.jpg'), rgb_integral_img);\n",
    "            cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_gen_integral.png'), rgb_integral_img)\n",
    "            cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_integral.png'), rgb_integral_img)\n",
    "            if len(self._current_thermal_images_list)>= 1:\n",
    "                self._aos.clearViews()\n",
    "                for i in range(len(self._prev_thermal_images)):\n",
    "                    self._aos.addView(self._prev_thermal_images[i], self._prev_images_poses[i], \"DEM BlobTrack\")\n",
    "                img_renderering_ids = []\n",
    "                self._aos.setDEMTransform([0,0,self._focalplane_height])\n",
    "                ##tmp_thermal_integral_img = self._aos.render(self.pose_to_virtualcamera(virtual_camera_pose), self._fov, img_renderering_ids) ##edited in oct\n",
    "                tmp_thermal_integral_img = self._aos.render(self.pose_to_virtualcamera(single_poses[self._current_center_camera_id]), self._fov, img_renderering_ids)\n",
    "                thermal_integral_img = self.divide_by_alpha(tmp_thermal_integral_img)\n",
    "                #cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_integral.jpg'), rgb_integral_img);\n",
    "                cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_gen_thermal_integral.png'), thermal_integral_img)\n",
    "                cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_thermal_integral.png'), thermal_integral_img)\n",
    "        else :\n",
    "            print(\"same as integral image\")\n",
    "            rgb_integral_images = self.project_images_to_all(self._aos, self._current_RGB_images_list, single_poses,self._fov,center_camera_index=None,project_images=False)\n",
    "            if len(self._current_thermal_images_list)>= 1:\n",
    "                thermal_integral_images = self.project_images_to_all(self._aos, self._current_thermal_images_list, single_poses,self._fov,center_camera_index=None,project_images=False)\n",
    "                thermal_integral_img = np.asarray(thermal_integral_images[self._current_center_camera_id],dtype=np.uint8)\n",
    "                cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_gen_thermal_integral.png'), thermal_integral_img)\n",
    "                cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_thermal_integral.png'), thermal_integral_img)\n",
    "            rgb_integral_img  = np.asarray(rgb_integral_images[self._current_center_camera_id],dtype=np.uint8)\n",
    "            cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_gen_integral.png'), rgb_integral_img) \n",
    "            cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_integral.png'), rgb_integral_img) \n",
    "        self._integration_count = self._integration_count + 1\n",
    "        return rgb_integral_img, prev_img_max_contour,gen_integral_blob_img\n",
    "\n",
    "        \n",
    "class drone_pso:\n",
    "    _fov = 45#22.815436217896945#43.10803984095769#43.50668199945787#50.815436217896945\n",
    "    _rx_threshold = 0.999\n",
    "    _no_of_drones = 10\n",
    "    _distance_factor = 2.0\n",
    "    _scanning_bearing = 0.0\n",
    "    _empty_scene_rx_blob_size_threshold = 500.0\n",
    "    _scandirec_waypoint_distance = 3.0\n",
    "    _init = True\n",
    "    _aos = None\n",
    "    _images = None\n",
    "    _poses = None\n",
    "    _previous_drone_pos = None\n",
    "    _center_waypoint = None\n",
    "    _changing_back_speed = 2.0\n",
    "    _cognitive_local_fac = 0.2\n",
    "    _social_global_fac = 0.2\n",
    "    _minimum_drone_distance = _distance_factor\n",
    "    _metric_cal = None\n",
    "    _debug = False\n",
    "    _current_gps_waypoints = None\n",
    "    _waypoint_count = 0\n",
    "    \n",
    "    def __init__(self,aos_ptr,no_drones,fieldofview,rxthreshold,distancebtwndrones,scanningdirection,scanning_direction_waypoint_distance,emptysceneblobthreshold, starting_loc_gps, changingtolinearspeed, localfac, globalfac, minimumdistancebetweendrone, debug_mode = False):\n",
    "        \n",
    "        self._aos = aos_ptr\n",
    "        self._no_of_drones = no_drones\n",
    "        self._fov = fieldofview\n",
    "        self._rx_threshold = rxthreshold\n",
    "        self._distance_factor = distancebtwndrones\n",
    "        self._scanning_bearing = scanningdirection\n",
    "        self._empty_scene_rx_blob_size_threshold = emptysceneblobthreshold\n",
    "        self._center_waypoint = starting_loc_gps\n",
    "        self._changing_back_speed = changingtolinearspeed\n",
    "        self._cognitive_local_fac = localfac\n",
    "        self._social_global_fac = globalfac\n",
    "        self._minimum_drone_distance = minimumdistancebetweendrone\n",
    "        self._metric_cal = evaluate_metric(self._aos, self._fov,self._rx_threshold, dem_height= 0.0,compasscorrection=0.0,debug_mode=debug_mode)\n",
    "        self._debug = debug_mode\n",
    "        self._scandirec_waypoint_distance = scanning_direction_waypoint_distance\n",
    "        self._waypoint_count = 0\n",
    "        self._continous_converging = 0\n",
    "        self._startingcentreposition = [0,-12]  #[0,-12]\n",
    "        self._blob_person_position = [0,10]\n",
    "        self._current_blob_position = [0,10]\n",
    "\n",
    "        \n",
    "        if self._debug:\n",
    "            np.random.seed(100)\n",
    "        self._centered_drone_array = np.arange(-(int)((self._no_of_drones-1)/2),(int)((self._no_of_drones+2)/2),1) * self._distance_factor\n",
    "        if self._debug:\n",
    "            self._direction_vector = [3.0,3.0]\n",
    "        else :\n",
    "            self._direction_vector = [np.sin(np.deg2rad( self._scanning_bearing)), np.cos(np.deg2rad( self._scanning_bearing))]\n",
    "        self._center_east,self._center_north,self._zone_number, self._zone_letter = utm.from_latlon(self._center_waypoint[0],self._center_waypoint[1])\n",
    "        \n",
    "        self._vec_perpend_to_scan_dir = self.perpendicular(self.normalize(self._direction_vector))\n",
    "        print(self._vec_perpend_to_scan_dir)\n",
    "        print(self._direction_vector)\n",
    "        \n",
    "        self._rel_drone_pos = np.transpose(np.array(list(tuple(self._vec_perpend_to_scan_dir* drone_pos_to_center) for drone_pos_to_center in self._centered_drone_array)))\n",
    "        print(self._rel_drone_pos.shape)\n",
    "       # self._rel_drone_pos = self._rel_drone_pos + (np.transpose(np.tile(np.array(self._startingcentreposition),(self._no_of_drones,1))))\n",
    "        \n",
    "        print(self._centered_drone_array)\n",
    "        print(self._rel_drone_pos.shape)\n",
    "        print(self._rel_drone_pos)\n",
    "        \n",
    "        \n",
    "        self._mean_drone_pos = np.mean(self._rel_drone_pos,1).reshape(2,1)\n",
    "        self._rel_drone_pos = self._rel_drone_pos - np.repeat(self._mean_drone_pos,self._no_of_drones,axis = 1)\n",
    "        #self._rel_drone_pos = self._rel_drone_pos + (np.transpose(np.tile(np.array(self._startingcentreposition),(self._no_of_drones,1))))\n",
    "\n",
    "        self._rand_velocity_vec = self._scanning_dir_vec = np.random.randn(2, self._no_of_drones) * 0.1\n",
    "        normalized_scan_vec = self.normalize(self._direction_vector)\n",
    "        \n",
    "        for i in range(self._no_of_drones):\n",
    "            #self._scanning_dir_vec[:,i] = (self._direction_vector[0],self._direction_vector[1])\n",
    "            self._scanning_dir_vec[:,i] = (normalized_scan_vec[0]*self._scandirec_waypoint_distance,normalized_scan_vec[1]*self._scandirec_waypoint_distance)\n",
    "        #self._scanning_dir_vec = np.repeat(self._direction_vector,self._no_of_drones,axis = 1)\n",
    "\n",
    "        drones_next_east_loc = self._rel_drone_pos[0,:] + self._center_east\n",
    "        drones_next_north_loc = self._rel_drone_pos[1,:] + self._center_north\n",
    "       \n",
    "\n",
    "        drones_next_lat,drones_next_lon = utm.to_latlon(drones_next_east_loc, drones_next_north_loc, self._zone_number, self._zone_letter)\n",
    "     \n",
    "        drones_next_loc = list(zip(drones_next_lat, drones_next_lon))\n",
    "        \n",
    "        self._previous_drone_pos = self._rel_drone_pos + (np.transpose(np.tile(np.array(self._startingcentreposition),(self._no_of_drones,1))))  #self._rel_drone_pos\n",
    "        self._current_gps_waypoints = drones_next_loc\n",
    "        \n",
    "        #return drones_next_loc, self._previous_drone_pos\n",
    "    def set_scanning_direction(self, scanning_bearing):\n",
    "        self._scanning_bearing = scanning_bearing\n",
    "        if self._debug:\n",
    "            self._direction_vector = [3.0,3.0]\n",
    "        else :\n",
    "            self._direction_vector = [np.sin(np.deg2rad( self._scanning_bearing)), np.cos(np.deg2rad( self._scanning_bearing))]\n",
    "  \n",
    "        self._vec_perpend_to_scan_dir = self.perpendicular(self.normalize(self._direction_vector))\n",
    "        print(self._vec_perpend_to_scan_dir)\n",
    "        print(self._direction_vector)\n",
    "        \n",
    "        self._rel_drone_pos = np.transpose(np.array(list(tuple(self._vec_perpend_to_scan_dir* drone_pos_to_center) for drone_pos_to_center in self._centered_drone_array)))\n",
    "        print(self._rel_drone_pos.shape)\n",
    "        # self._rel_drone_pos = self._rel_drone_pos + (np.transpose(np.tile(np.array(self._startingcentreposition),(self._no_of_drones,1))))\n",
    "        \n",
    "        print(self._centered_drone_array)\n",
    "        print(self._rel_drone_pos.shape)\n",
    "        print(self._rel_drone_pos)\n",
    "    \n",
    "        self._mean_drone_pos = np.mean(self._rel_drone_pos,1).reshape(2,1)\n",
    "        self._rel_drone_pos = self._rel_drone_pos - np.repeat(self._mean_drone_pos,self._no_of_drones,axis = 1)\n",
    "        #self._rel_drone_pos = self._rel_drone_pos + (np.transpose(np.tile(np.array(self._startingcentreposition),(self._no_of_drones,1))))\n",
    "\n",
    "        normalized_scan_vec = self.normalize(self._direction_vector)\n",
    "        for i in range(self._no_of_drones):\n",
    "            self._scanning_dir_vec[:,i] = (normalized_scan_vec[0]*self._scandirec_waypoint_distance,normalized_scan_vec[1]*self._scandirec_waypoint_distance)\n",
    "\n",
    "    def set_scan_direction_distance(self,scanning_direction_waypoint_distance):\n",
    "        self._scandirec_waypoint_distance = scanning_direction_waypoint_distance\n",
    "        normalized_scan_vec = self.normalize(self._direction_vector)\n",
    "        for i in range(self._no_of_drones):\n",
    "            self._scanning_dir_vec[:,i] = (normalized_scan_vec[0]*self._scandirec_waypoint_distance,normalized_scan_vec[1]*self._scandirec_waypoint_distance)\n",
    "\n",
    "    def set_emptyblob_threshold(self, contour_area_threshold):\n",
    "        self._empty_scene_rx_blob_size_threshold = contour_area_threshold\n",
    "\n",
    "    def get_rx_threshold(self):\n",
    "        return self._empty_scene_rx_blob_size_threshold\n",
    "    \n",
    "    def determine_emptyblob_threshold(self,single_images,site_poses, fov = None, rxthreshold =  None, dem_height = None, compasscorrection = None , pos = None):\n",
    "        center_rgb_integral_image, leader_rx_image, Leader_index, leader_contour = self._metric_cal.get_relevent_info(single_images,site_poses, fov, rxthreshold, dem_height, compasscorrection, pos)\n",
    "        return center_rgb_integral_image, leader_rx_image, Leader_index, leader_contour\n",
    "        \n",
    "    def get_current_waypoints(self):\n",
    "        return self._current_gps_waypoints, self._previous_drone_pos\n",
    "\n",
    "    def get_leader_info(self, images, poses):\n",
    "        position = self._previous_drone_pos\n",
    "        leader_index, leader_contour_area, mask_img, camera_id,leader_blob_image, leader_rx_image,rect = self._metric_cal.find_leader_within_images(images, poses, self._fov, rxthreshold=None, pos = position)\n",
    "\n",
    "    def get_waypoints_with_pso(self,images, poses, virtual_camera_pose):\n",
    "        \n",
    "        self._waypoint_count = self._waypoint_count + 1\n",
    "        position = self._previous_drone_pos\n",
    "        #if self._debug:\n",
    "            #print(\"Previous Pos for Finding Leader\", self._previous_drone_pos)\n",
    "        leader_index, leader_contour_area, mask_img, camera_id,leader_blob_image, leader_rx_image,rect = self._metric_cal.find_leader_within_images(images, poses, self._fov, rxthreshold=None, pos = position)\n",
    "        if (leader_contour_area < self._empty_scene_rx_blob_size_threshold):\n",
    "            #print(\"Project to Old Mask\")\n",
    "            integral_image, prev_contour_area, gen_integral_blob_img = self._metric_cal.integrate_informative_images(images, poses, virtual_camera_pose, None, None)\n",
    "            #prev_contour_area = leader_contour_area\n",
    "        else :\n",
    "            #print(\"Project to New Mask\")\n",
    "            integral_image, prev_contour_area, gen_integral_blob_img = self._metric_cal.integrate_informative_images(images, poses, virtual_camera_pose, mask_img, poses[camera_id])\n",
    "        info = []\n",
    "        info.append('WayPoint_Count ' + str(self._waypoint_count) + ' \\n')\n",
    "        info.append('Leader Index ' + str(leader_index) + ' \\n')\n",
    "        info.append('Leader Contour ' + str(leader_contour_area) + ' \\n')\n",
    "        info.append('Contour Threshold ' + str(self._empty_scene_rx_blob_size_threshold) + ' \\n')\n",
    "        \n",
    "        #integral_image, integral_camera_pose = self._metric_cal.integrate_informative_images(self._aos, images, poses, self._prev_images, self._prev_poses, virtual_camera_pose )\n",
    "        #if self._debug:\n",
    "            #print(\"Leader Index, Leader Area\", leader_index, leader_contour_area)\n",
    "        if (leader_contour_area < self._empty_scene_rx_blob_size_threshold): #or (iteration >=exit_iteration):\n",
    "            self._continous_converging = 0\n",
    "            curr_drone_rel_pos = np.repeat(np.mean(self._previous_drone_pos,1).reshape(2,1),self._no_of_drones,axis = 1) + self._rel_drone_pos #line formation around center of gravety of previous swarm position\n",
    "            info.append('Previous Drone Positions ' + str(self._previous_drone_pos[0,:]) + '_' +  str(self._previous_drone_pos[1,:])+ ' \\n')\n",
    "            info.append('Mean Previous Drone Positions ' + str(np.repeat(np.mean(self._previous_drone_pos,1).reshape(2,1),self._no_of_drones,axis = 1)[0,:]) + '_' +  str(np.repeat(np.mean(self._previous_drone_pos,1).reshape(2,1),self._no_of_drones,axis = 1)[1,:])+ ' \\n')\n",
    "            info.append('relative Drone Positions ' + str(self._rel_drone_pos[0,:]) + '_' +  str(self._rel_drone_pos[1,:])+ ' \\n')\n",
    "            info.append('current starting Drone Positions ' + str(curr_drone_rel_pos[0,:]) + '_' +  str(curr_drone_rel_pos[1,:])+ ' \\n')\n",
    "            #velocity_vec = self._scanning_dir_vec + self._changing_back_speed * (curr_drone_rel_pos - self._previous_drone_pos)\n",
    "            #velocity_vec = self._scanning_dir_vec + self._changing_back_speed * self.normalize_vectors(curr_drone_rel_pos - self._previous_drone_pos)\n",
    "            velocity_vec = self._scanning_dir_vec + self._changing_back_speed * (curr_drone_rel_pos - self._previous_drone_pos)\n",
    "\n",
    "            info.append('scanning direction vector ' + str(self._scanning_dir_vec[0,:]) + '_' +  str(self._scanning_dir_vec[1,:])+ ' \\n')\n",
    "            info.append('changing back speed ' + str(self._changing_back_speed) + ' \\n')\n",
    "            info.append('velocity vector ' + str(velocity_vec[0,:]) + '_' +  str(velocity_vec[1,:])+ ' \\n')\n",
    "            #info.append('Normalize velocity vector ' + str(velocity_vec_norm[0,:]) + '_' +  str(velocity_vec_norm[1,:])+ ' \\n')\n",
    "            new_drone_rel_pos = self._previous_drone_pos + velocity_vec\n",
    "            self._previous_drone_pos = new_drone_rel_pos\n",
    "            info.append('Moving Straight ' + str(new_drone_rel_pos[0,:]) + '_' +  str(new_drone_rel_pos[1,:])+ ' \\n')\n",
    "        else :\n",
    "            self._continous_converging = self._continous_converging + 1\n",
    "            if self._debug:\n",
    "                np.random.seed(100)\n",
    "            rand_mov_vec = np.random.rand(2, self._no_of_drones)*2 - np.ones(2*self._no_of_drones).reshape(2, self._no_of_drones)\n",
    "            #if self._debug:\n",
    "                #print(\"rand_mov_vec\", rand_mov_vec)\n",
    "                #print(\"leader pos\", self._previous_drone_pos[:,leader_index].reshape(-1,1))\n",
    "            #resp_vel_vec = self._cognitive_local_fac * self.normalize(rand_mov_vec) + self._social_global_fac * self.normalize((self._previous_drone_pos[:,leader_index].reshape(-1,1) - self._previous_drone_pos))\n",
    "            resp_vel_vec = self._cognitive_local_fac * self.normalize_vectors(rand_mov_vec) + self._social_global_fac * self.normalize_vectors((self._previous_drone_pos[:,leader_index].reshape(-1,1) - self._previous_drone_pos))\n",
    "            #if self._debug:\n",
    "                #print(\"Previous Pos\", self._previous_drone_pos)\n",
    "                #print(\"Velocity Vector\", resp_vel_vec) \n",
    "            new_drone_rel_pos = self._previous_drone_pos + resp_vel_vec\n",
    "            info.append('Converging Before Rutherford Scattering ' + str(new_drone_rel_pos[0,:]) + '_' +  str(new_drone_rel_pos[1,:])+ ' \\n')\n",
    "            #if self._debug:\n",
    "                #print(\"new drone_pos\", new_drone_rel_pos) \n",
    "            new_drone_rel_pos = self.rutherford_scattering(new_drone_rel_pos,self._no_of_drones,self._minimum_drone_distance) # minimal distance constraint (Rutherford Scattering)\n",
    "            #if self._debug:\n",
    "                #print(\"ruttherfordScanning\", new_drone_rel_pos) \n",
    "            self._previous_drone_pos = new_drone_rel_pos\n",
    "            info.append('Minimum Distance Within Rutherford Scattering ' + str(self._minimum_drone_distance) + ' \\n')\n",
    "            info.append('Converging After Rutherford Scattering ' + str(new_drone_rel_pos[0,:]) + '_' + str(new_drone_rel_pos[1,:])+ ' \\n')\n",
    "            \n",
    "\n",
    "        drones_next_east_loc = new_drone_rel_pos[0,:] + self._center_east\n",
    "        drones_next_north_loc = new_drone_rel_pos[1,:] + self._center_north\n",
    "\n",
    "        drones_next_lat,drones_next_lon = utm.to_latlon(drones_next_east_loc,drones_next_north_loc, self._zone_number, self._zone_letter)\n",
    "        info.append('drones next lat ' + str(drones_next_lat) + ' drones next lon ' + str(drones_next_lon)+ ' \\n')\n",
    "        drones_next_loc = zip(drones_next_lat, drones_next_lon)\n",
    "        #print(list(drones_next_loc))\n",
    "        self._current_gps_waypoints = drones_next_loc\n",
    "        #datasets_folder_live_debug= os.path.join( r\"E:\\Droneswarms_Feb_clientserverdevelopment\\live_debug\" )\n",
    "        with open(os.path.join(Live_Debug_Path,'WayPoint_Info.txt'), 'a') as f:\n",
    "            f.writelines('\\n'.join(info))\n",
    "        return drones_next_loc, self._previous_drone_pos, integral_image,leader_contour_area, leader_index, prev_contour_area,camera_id,leader_blob_image, leader_rx_image,gen_integral_blob_img,rect\n",
    "    \n",
    "    def get_waypoints_with_pso_motion(self,images, poses, virtual_camera_pose):\n",
    "        if self._waypoint_count == 0:\n",
    "            self._previous_drone_pos  = np.array([[9.9717100350285, 7.509278207141478, 7.9509800794951735, 10.435511445470253, -0.7602028575178091, 13.721811741972076, 1.924510020547081, 4.666728601049116, 3.231715985565085, 0.936382834234614], [-8.656215061944506, -5.710321502200583, -0.16034449090046393, 3.5812591450458786, 0.30581173782537846, -5.231449516231961, -7.244081751496854, -2.52686032502034, 3.1534761204635524, -3.2818597748696416]], dtype = 'float')\n",
    "            ###below is for old drones n=10 300trees/ha without altitude bias\n",
    "            #self._previous_drone_pos  =  np.array([[1.8115134503385846, 10.133639847964734, 12.629432704779868, 11.903718818156282, 6.7633418126185845, 4.691795821233404, 5.602373545591946, 8.155933054264636, 7.186430847096473, 0.3061385423385319], [-5.02637415149285, 5.097264629755322, 1.958122637084436, -3.986459164351714, 7.253806446287938, 1.848477920955482, -6.393277670197103, 1.9794189449672637, -2.746389521970734, 1.4854112721404695]], dtype = 'float')\n",
    "\n",
    "        self._waypoint_count = self._waypoint_count + 1\n",
    "        position = self._previous_drone_pos\n",
    "        personorientation = 100\n",
    "        #if self._debug:\n",
    "            #print(\"Previous Pos for Finding Leader\", self._previous_drone_pos)\n",
    "        leader_index, leader_contour_area, mask_img, camera_id,leader_blob_image, leader_rx_image,rect = self._metric_cal.find_leader_within_images(images, poses, self._fov, rxthreshold=None, pos = position)\n",
    "        # if (leader_contour_area < self._empty_scene_rx_blob_size_threshold):\n",
    "        #     self._continous_converging = 0\n",
    "        #     #print(\"Project to Old Mask\")\n",
    "        #     #integral_image, prev_contour_area, gen_integral_blob_img = self._metric_cal.integrate_informative_images(images, poses, virtual_camera_pose, None, None)\n",
    "        #     integral_image, prev_contour_area, gen_integral_blob_img = self._metric_cal.integrate_informative_images(images, poses, virtual_camera_pose, mask_img, poses[camera_id])\n",
    "        #     motion = []\n",
    "        #     motion.append('Waypoint ' + str(self._waypoint_count) + ' \\n')\n",
    "        #     motion.append('No convergence'  + ' \\n') \n",
    "        #     # motion.append('person ' + str(person) + ' \\n')\n",
    "        #     motion.append('No convergence'  + ' \\n')  \n",
    "        #     motion.append('Scanning_direction ' + str(self._scanning_dir_vec) + ' \\n')\n",
    "        #     #motion.append('personorientation ' + str(personorientation) + ' \\n')\n",
    "            \n",
    "        #     #motion.append('Distancetravelledbyperson ' + str(person_distance) + ' \\n')\n",
    "        #     motion.append('Scanning_direction_Waypoint_Distance_c3 ' + str(self._scandirec_waypoint_distance) + ' \\n')\n",
    "        #     positiondummy = [60,60]  # dummy number\n",
    "        #     rectdummy = [59,59,2,2]\n",
    "        #     import json\n",
    "        #     bd ={\n",
    "        #             self._waypoint_count:positiondummy,\n",
    "                    \n",
    "        #         }\n",
    "\n",
    "\n",
    "\n",
    "        #     with open(r'C:\\Users\\Rakesh\\Downloads\\blobpositions.json','r+') as file4:\n",
    "            \n",
    "        #         data4 = json.load(file4)\n",
    "        #         data4.update(bd)\n",
    "        #         file4.seek(0)\n",
    "        #         json.dump(data4, file4)  \n",
    "                \n",
    "                \n",
    "             \n",
    "        #     rt9 ={\n",
    "        #             self._waypoint_count:rectdummy,\n",
    "                    \n",
    "        #         }\n",
    "\n",
    "\n",
    "\n",
    "        #     with open(r'C:\\Users\\Rakesh\\Downloads\\rectpositions.json','r+') as file10:\n",
    "            \n",
    "        #             data10 = json.load(file10)\n",
    "        #             data10.update(rt9)\n",
    "        #             file10.seek(0)\n",
    "        #             json.dump(data10, file10)    \n",
    "        #     #prev_contour_area = leader_contour_area\n",
    "        # else :\n",
    "        #     self._continous_converging = self._continous_converging + 1\n",
    "        #     #print(\"Project to New Mask\")\n",
    "        #     integral_image, prev_contour_area, gen_integral_blob_img = self._metric_cal.integrate_informative_images(images, poses, virtual_camera_pose, mask_img, poses[camera_id])\n",
    "        #     previous_blob_personposition = self._blob_person_position \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        #     altitude_list = [43,41,39,37,35,36,38,40,42,44]\n",
    "        #     new_leader_index = leader_index\n",
    "        #     coverage = 2*altitude_list[new_leader_index]*np.tan(np.deg2rad(25))\n",
    "        #     resolution = 512\n",
    "        #     metretopixels = coverage/resolution\n",
    "        #     blob_posx = rect[0] + rect[2]/2\n",
    "        #     blob_posy = rect[1] + rect[3]/2\n",
    "        #     blob_posxinpixels = blob_posx * metretopixels\n",
    "        #     blob_posyinpixels = blob_posy * metretopixels\n",
    "        #     blobposition = [blob_posxinpixels,blob_posyinpixels]\n",
    "        #     ref_loc = self._previous_drone_pos\n",
    "        #     integralposition_centre = [ref_loc[0][new_leader_index], ref_loc[1][new_leader_index]]\n",
    "        #     integral_startposition = [integralposition_centre[0] - coverage/2, integralposition_centre[1] - coverage/2]\n",
    "        #     blob_personposition = [blobposition[0] +(integral_startposition[0]), blobposition[1] + (integral_startposition[1])]\n",
    "            \n",
    "\n",
    "        #     dronemeanx=(np.mean(ref_loc[0]))\n",
    "        #     dronemeany=(np.mean(ref_loc[1]))\n",
    "        #     dronemeanpos = [dronemeanx,dronemeany]\n",
    "        #     dy = (-blob_personposition[1]-(-dronemeany))\n",
    "        #     dx = (blob_personposition[0]-dronemeanx)\n",
    "\n",
    "        #     Scanning_direction = np.arctan2(dy,dx)\n",
    "        #     Scanning_direction = ((np.degrees(Scanning_direction))%360)+90\n",
    "        #     print(Scanning_direction)\n",
    "        #     if Scanning_direction >=360 :\n",
    "        #         Scanning_direction =  Scanning_direction - 360                             #need to switch sign of yaxis positive is down and negative is up\n",
    "        #         print(Scanning_direction)\n",
    "\n",
    "\n",
    "            \n",
    "        #     # dyp = (-blob_personposition[1]-(-previous_blob_personposition[1]))\n",
    "        #     # dxp = (blob_personposition[0]-previous_blob_personposition[0])\n",
    "        #     # personorientation = np.arctan2(dyp,dxp)\n",
    "        #     # personorientation = ((np.degrees(personorientation))%360)+90\n",
    "        #     # print(personorientation)\n",
    "        #     # if personorientation >=360 :\n",
    "        #     #     personorientation = personorientation - 360                             #need to switch sign of yaxis positive is down and negative is up\n",
    "        #     #     print(personorientation)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        #     c = []\n",
    "        #     drone_speed = 10\n",
    "        #     for i in range (0, 10):\n",
    "        #         distancedrone = math.sqrt( ((ref_loc[0][i]-prevwaypoints[0][i])**2)+((ref_loc[1][i]-prevwaypoints[1][i])**2) )\n",
    "        #         c.append(distancedrone)\n",
    "                \n",
    "        #     print(c)\n",
    "        #     new_max_distance =  max(c)    \n",
    "        #     print(max(c))\n",
    "            \n",
    "        #     drone_totaltime = (new_max_distance/drone_speed)\n",
    "            \n",
    "            \n",
    "            \n",
    "        #     delta = 0.3\n",
    "        #     person_distance = math.sqrt( (blob_personposition[0] - previous_blob_personposition[0] )**2 + (blob_personposition[1] - previous_blob_personposition[1])**2 )\n",
    "            \n",
    "        #     # person_time = drone_totaltime\n",
    "        #     # person_calculatedspeed = person_distance/person_time\n",
    "        #     # person_simspeed = 3    \n",
    "        #     c3 = person_distance #person_calculatedspeed *  person_time # to be updated\n",
    "        #     Scanning_direction_Waypoint_Distance = c3 + delta #c3   \n",
    "        #     if self._continous_converging > 1:\n",
    "        #         self.set_scan_direction_distance(Scanning_direction_Waypoint_Distance)\n",
    "            \n",
    "        #     import json\n",
    "        #     bd ={\n",
    "        #             self._waypoint_count:blob_personposition,\n",
    "                    \n",
    "        #         }\n",
    "\n",
    "            \n",
    "\n",
    "        #     with open(r'C:\\Users\\Rakesh\\Downloads\\blobpositions.json','r+') as file3:\n",
    "            \n",
    "        #             data3 = json.load(file3)\n",
    "        #             data3.update(bd)\n",
    "        #             file3.seek(0)\n",
    "        #             json.dump(data3, file3)  \n",
    "                    \n",
    "                    \n",
    "        #     import json\n",
    "        #     rt ={\n",
    "        #             self._waypoint_count:rect,\n",
    "                    \n",
    "        #         }\n",
    "\n",
    "\n",
    "\n",
    "        #     with open(r'C:\\Users\\Rakesh\\Downloads\\rectpositions.json','r+') as file6:\n",
    "            \n",
    "        #             data6 = json.load(file6)\n",
    "        #             data6.update(rt)\n",
    "        #             file6.seek(0)\n",
    "        #             json.dump(data6, file6)   \n",
    "                    \n",
    "                    \n",
    "        #     import json\n",
    "        #     sd1 ={\n",
    "        #             self._waypoint_count:Scanning_direction_Waypoint_Distance,\n",
    "                    \n",
    "        #         }\n",
    "\n",
    "\n",
    "\n",
    "        #     with open(r'C:\\Users\\Rakesh\\Downloads\\scanningwaypointdistance.json','r+') as file11:\n",
    "            \n",
    "        #             data11 = json.load(file11)\n",
    "        #             data11.update(sd1)\n",
    "        #             file11.seek(0)\n",
    "        #             json.dump(data11, file11)                   \n",
    "        \n",
    "\n",
    "        #     # print(\"simulated_personposition\",person)\n",
    "        #     print(\"previous_blob_personposition\",previous_blob_personposition)\n",
    "        #     print(\"coverage\",coverage)\n",
    "        #     print(\"new_leader_index\",new_leader_index)\n",
    "        #     print(\"blobposition\",blobposition)\n",
    "        #     print(\"integralposition_centre\",integralposition_centre)\n",
    "        #     print(\"integral_startposition\",integral_startposition)\n",
    "        #     print(\"currentblob_personposition\",blob_personposition)\n",
    "        #     print(\"dronemeanpos\",dronemeanpos)\n",
    "        #     print(\"Scanning_direction\",Scanning_direction)\n",
    "        #     #print(\"personorientation\",personorientation)\n",
    "        #     # print(\"timeforcurrentiteration\",person_time)\n",
    "        #     print(\"Distancetravelledbyperson\",person_distance)\n",
    "        #     print(\"c3\",Scanning_direction_Waypoint_Distance)\n",
    "            \n",
    "            \n",
    "        #     motion = []\n",
    "        #     motion.append('Waypoint ' + str(self._waypoint_count) + ' \\n')\n",
    "        #     motion.append('rect ' + str(rect) + ' \\n')\n",
    "        #     motion.append('previous_blob_personposition ' + str(previous_blob_personposition) + ' \\n')\n",
    "        #     motion.append('coverage ' + str(coverage) + ' \\n')\n",
    "        #     motion.append('new_leader_index ' + str(new_leader_index) + ' \\n')\n",
    "        #     motion.append('blobposition ' + str(blobposition) + ' \\n')\n",
    "        #     motion.append('integralposition_centre ' + str(integralposition_centre) + ' \\n')\n",
    "        #     motion.append('integral_startposition ' + str(integral_startposition) + ' \\n')\n",
    "        #     motion.append('currentblob_personposition ' + str(blob_personposition) + ' \\n')\n",
    "        #     motion.append('dronemeanpos ' + str(dronemeanpos) + ' \\n')\n",
    "        #     motion.append('Scanning_direction ' + str(Scanning_direction) + ' \\n')\n",
    "        #     #motion.append('personorientation ' + str(personorientation) + ' \\n')\n",
    "        #     # motion.append('timeforcurrentiteration ' + str(person_time) + ' \\n')\n",
    "        #     motion.append('Distancetravelledbyperson ' + str(person_distance) + ' \\n')\n",
    "        #     motion.append('Scanning_direction_Waypoint_Distance_c3 ' + str(Scanning_direction_Waypoint_Distance) + ' \\n')\n",
    "        #     self.set_scanning_direction(Scanning_direction)\n",
    "            \n",
    "        #     self._blob_person_position = blob_personposition\n",
    "\n",
    "        # with open(os.path.join(Live_Debug_Path,'motion.txt'), 'a') as f:\n",
    "        #     f.writelines('\\n'.join(motion))            \n",
    "        info = []\n",
    "        info.append('WayPoint_Count ' + str(self._waypoint_count) + ' \\n')\n",
    "        info.append('Leader Index ' + str(leader_index) + ' \\n')\n",
    "        info.append('Leader Contour ' + str(leader_contour_area) + ' \\n')\n",
    "        info.append('Contour Threshold ' + str(self._empty_scene_rx_blob_size_threshold) + ' \\n')\n",
    "        \n",
    "        #integral_image, integral_camera_pose = self._metric_cal.integrate_informative_images(self._aos, images, poses, self._prev_images, self._prev_poses, virtual_camera_pose )\n",
    "        #if self._debug:\n",
    "            #print(\"Leader Index, Leader Area\", leader_index, leader_contour_area)\n",
    "        if (leader_contour_area < self._empty_scene_rx_blob_size_threshold): #or (iteration >=exit_iteration):\n",
    "\n",
    "            # dronemeanx=(np.mean(self._previous_drone_pos[0]))\n",
    "            # dronemeany=(np.mean(self._previous_drone_pos[1]))\n",
    "            # dronemeanpos = [dronemeanx,dronemeany]\n",
    "            # dy = (-self._blob_person_position[1]-(-dronemeany))\n",
    "            # dx = (self._blob_person_position[0]-dronemeanx)\n",
    "\n",
    "            # Scanning_direction = np.arctan2(dy,dx)\n",
    "            # Scanning_direction = ((np.degrees(Scanning_direction))%360)+90\n",
    "            # print(Scanning_direction)\n",
    "            # if Scanning_direction >=360 :\n",
    "            #     Scanning_direction =  Scanning_direction - 360                             #need to switch sign of yaxis positive is down and negative is up\n",
    "            #     print(Scanning_direction)\n",
    "\n",
    "            # self.set_scanning_direction(Scanning_direction)\n",
    "            curr_drone_rel_pos = np.repeat(np.mean(self._previous_drone_pos,1).reshape(2,1),self._no_of_drones,axis = 1) + self._rel_drone_pos #line formation around center of gravety of previous swarm position\n",
    "            info.append('Previous Drone Positions ' + str(self._previous_drone_pos[0,:]) + '_' +  str(self._previous_drone_pos[1,:])+ ' \\n')\n",
    "            info.append('Mean Previous Drone Positions ' + str(np.repeat(np.mean(self._previous_drone_pos,1).reshape(2,1),self._no_of_drones,axis = 1)[0,:]) + '_' +  str(np.repeat(np.mean(self._previous_drone_pos,1).reshape(2,1),self._no_of_drones,axis = 1)[1,:])+ ' \\n')\n",
    "            info.append('relative Drone Positions ' + str(self._rel_drone_pos[0,:]) + '_' +  str(self._rel_drone_pos[1,:])+ ' \\n')\n",
    "            info.append('current starting Drone Positions ' + str(curr_drone_rel_pos[0,:]) + '_' +  str(curr_drone_rel_pos[1,:])+ ' \\n')\n",
    "            info.append('Mean Current Drone Positions ' + str(np.repeat(np.mean(curr_drone_rel_pos,1).reshape(2,1),self._no_of_drones,axis = 1)[0,:]) + '_' +  str(np.repeat(np.mean(curr_drone_rel_pos,1).reshape(2,1),self._no_of_drones,axis = 1)[1,:])+ ' \\n')\n",
    "\n",
    "            #velocity_vec = self._scanning_dir_vec + self._changing_back_speed * (curr_drone_rel_pos - self._previous_drone_pos)\n",
    "            #velocity_vec = self._scanning_dir_vec + self._changing_back_speed * self.normalize_vectors(curr_drone_rel_pos - self._previous_drone_pos)\n",
    "            velocity_vec = self._scanning_dir_vec + self._changing_back_speed * (curr_drone_rel_pos - self._previous_drone_pos)\n",
    "\n",
    "            info.append('scanning direction vector ' + str(self._scanning_dir_vec[0,:]) + '_' +  str(self._scanning_dir_vec[1,:])+ ' \\n')\n",
    "            info.append('changing back speed ' + str(self._changing_back_speed) + ' \\n')\n",
    "            info.append('velocity vector ' + str(velocity_vec[0,:]) + '_' +  str(velocity_vec[1,:])+ ' \\n')\n",
    "            #info.append('Normalize velocity vector ' + str(velocity_vec_norm[0,:]) + '_' +  str(velocity_vec_norm[1,:])+ ' \\n')\n",
    "            new_drone_rel_pos = self._previous_drone_pos + velocity_vec\n",
    "            ###############xxxxxxxxxxxxxxxCurrent iteration ref loc = new_drone_rel_pos and previous loc = self._previous_drone_posxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "            self._previous_drone_pos = new_drone_rel_pos\n",
    "            info.append('Moving Straight ' + str(new_drone_rel_pos[0,:]) + '_' +  str(new_drone_rel_pos[1,:])+ ' \\n')\n",
    "            \n",
    "           \n",
    "            self._continous_converging = 0\n",
    "            #print(\"Project to Old Mask\")\n",
    "            #integral_image, prev_contour_area, gen_integral_blob_img = self._metric_cal.integrate_informative_images(images, poses, virtual_camera_pose, None, None)\n",
    "            integral_image, prev_contour_area, gen_integral_blob_img = self._metric_cal.integrate_informative_images(images, poses, virtual_camera_pose, mask_img, poses[camera_id])\n",
    "            motion = []\n",
    "            motion.append('Waypoint ' + str(self._waypoint_count) + ' \\n')\n",
    "            motion.append('No convergence'  + ' \\n') \n",
    "            # motion.append('person ' + str(person) + ' \\n')\n",
    "            motion.append('No convergence'  + ' \\n')  \n",
    "            #motion.append('Scanning_direction ' + str(Scanning_direction) + ' \\n')\n",
    "            #motion.append('personorientation ' + str(personorientation) + ' \\n')\n",
    "            \n",
    "            #motion.append('Distancetravelledbyperson ' + str(person_distance) + ' \\n')\n",
    "            motion.append('Scanning_direction_Waypoint_Distance_c3 ' + str(self._scandirec_waypoint_distance) + ' \\n')\n",
    "            positiondummy = [60,60]  # dummy number\n",
    "            rectdummy = [59,59,2,2]\n",
    "            import json\n",
    "            bd ={\n",
    "                    self._waypoint_count:positiondummy,\n",
    "                    \n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "            with open(r'C:\\Users\\Rakesh\\Downloads\\blobpositions.json','r+') as file4:\n",
    "            \n",
    "                data4 = json.load(file4)\n",
    "                data4.update(bd)\n",
    "                file4.seek(0)\n",
    "                json.dump(data4, file4)  \n",
    "                \n",
    "                \n",
    "             \n",
    "            rt9 ={\n",
    "                    self._waypoint_count:rectdummy,\n",
    "                    \n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "            with open(r'C:\\Users\\Rakesh\\Downloads\\rectpositions.json','r+') as file10:\n",
    "            \n",
    "                    data10 = json.load(file10)\n",
    "                    data10.update(rt9)\n",
    "                    file10.seek(0)\n",
    "                    json.dump(data10, file10)  \n",
    "                    \n",
    "                    \n",
    "            sd14 ={\n",
    "                    self._waypoint_count:self._scandirec_waypoint_distance,\n",
    "                    \n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "            with open(r'C:\\Users\\Rakesh\\Downloads\\scanningwaypointdistance.json','r+') as file14:\n",
    "            \n",
    "                    data14 = json.load(file14)\n",
    "                    data14.update(sd14)\n",
    "                    file14.seek(0)\n",
    "                    json.dump(data14, file14)         \n",
    "                     \n",
    "            #prev_contour_area = leader_contour_area\n",
    "        else :\n",
    "            if self._debug:\n",
    "                np.random.seed(100)\n",
    "            rand_mov_vec = np.random.rand(2, self._no_of_drones)*2 - np.ones(2*self._no_of_drones).reshape(2, self._no_of_drones)\n",
    "            #if self._debug:\n",
    "                #print(\"rand_mov_vec\", rand_mov_vec)\n",
    "                #print(\"leader pos\", self._previous_drone_pos[:,leader_index].reshape(-1,1))\n",
    "            #resp_vel_vec = self._cognitive_local_fac * self.normalize(rand_mov_vec) + self._social_global_fac * self.normalize((self._previous_drone_pos[:,leader_index].reshape(-1,1) - self._previous_drone_pos))\n",
    "            resp_vel_vec = self._cognitive_local_fac * self.normalize_vectors(rand_mov_vec) + self._social_global_fac * self.normalize_vectors((self._previous_drone_pos[:,leader_index].reshape(-1,1) - self._previous_drone_pos))\n",
    "            #if self._debug:\n",
    "                #print(\"Previous Pos\", self._previous_drone_pos)\n",
    "                #print(\"Velocity Vector\", resp_vel_vec) \n",
    "            new_drone_rel_pos = self._previous_drone_pos + resp_vel_vec\n",
    "            info.append('Converging Before Rutherford Scattering ' + str(new_drone_rel_pos[0,:]) + '_' +  str(new_drone_rel_pos[1,:])+ ' \\n')\n",
    "            #if self._debug:\n",
    "                #print(\"new drone_pos\", new_drone_rel_pos) \n",
    "            new_drone_rel_pos = self.rutherford_scattering(new_drone_rel_pos,self._no_of_drones,self._minimum_drone_distance) # minimal distance constraint (Rutherford Scattering)\n",
    "            #if self._debug:\n",
    "                #print(\"ruttherfordScanning\", new_drone_rel_pos) \n",
    "            ###############xxxxxxxxxxxxxxxCurrent iteration ref loc = new_drone_rel_pos and previous loc = self._previous_drone_posxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "            \n",
    "            currentdronepos = new_drone_rel_pos\n",
    "            previousdronepos = self._previous_drone_pos\n",
    "            \n",
    "            self._previous_drone_pos = new_drone_rel_pos\n",
    "            info.append('Minimum Distance Within Rutherford Scattering ' + str(self._minimum_drone_distance) + ' \\n')\n",
    "            info.append('Converging After Rutherford Scattering ' + str(new_drone_rel_pos[0,:]) + '_' + str(new_drone_rel_pos[1,:])+ ' \\n')\n",
    "            \n",
    "            \n",
    "            self._continous_converging = self._continous_converging + 1\n",
    "            #print(\"Project to New Mask\")\n",
    "            integral_image, prev_contour_area, gen_integral_blob_img = self._metric_cal.integrate_informative_images(images, poses, virtual_camera_pose, mask_img, poses[camera_id])\n",
    "            previous_blob_personposition = self._blob_person_position \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            altitude_list = [43,41,39,37,35,36,38,40,42,44] #[35,36,37,38,39,40,41,42,43,44]  #[40,40,40,40,40,40,40,40,40,40] #[43,41,39,37,35,36,38,40,42,44]\n",
    "            new_leader_index = leader_index\n",
    "            coverage = 2*altitude_list[new_leader_index]*np.tan(np.deg2rad(25))\n",
    "            resolution = 512\n",
    "            metretopixels = coverage/resolution\n",
    "            blob_posx = rect[0] + rect[2]/2\n",
    "            blob_posy = rect[1] + rect[3]/2\n",
    "            blob_posxinpixels = blob_posx * metretopixels\n",
    "            blob_posyinpixels = blob_posy * metretopixels\n",
    "            blobposition = [blob_posxinpixels,blob_posyinpixels]\n",
    "            ref_loc = previousdronepos\n",
    "            integralposition_centre = [ref_loc[0][new_leader_index], ref_loc[1][new_leader_index]]\n",
    "            integral_startposition = [integralposition_centre[0] - coverage/2, integralposition_centre[1] - coverage/2]\n",
    "            blob_personposition = [blobposition[0] +(integral_startposition[0]), blobposition[1] + (integral_startposition[1])]\n",
    "            \n",
    "\n",
    "            dronemeanx=(np.mean(ref_loc[0]))\n",
    "            dronemeany=(np.mean(ref_loc[1]))\n",
    "            dronemeanpos = [dronemeanx,dronemeany]\n",
    "            dy = (-blob_personposition[1]-(-dronemeany))\n",
    "            dx = (blob_personposition[0]-dronemeanx)\n",
    "\n",
    "            Scanning_direction = np.arctan2(dy,dx)\n",
    "            Scanning_direction = ((np.degrees(Scanning_direction))%360)+90\n",
    "            print(Scanning_direction)\n",
    "            if Scanning_direction >=360 :\n",
    "                Scanning_direction =  Scanning_direction - 360                             #need to switch sign of yaxis positive is down and negative is up\n",
    "                print(Scanning_direction)\n",
    "\n",
    "\n",
    "            \n",
    "            # dyp = (-blob_personposition[1]-(-previous_blob_personposition[1]))\n",
    "            # dxp = (blob_personposition[0]-previous_blob_personposition[0])\n",
    "            # personorientation = np.arctan2(dyp,dxp)\n",
    "            # personorientation = ((np.degrees(personorientation))%360)+90\n",
    "            # print(personorientation)\n",
    "            # if personorientation >=360 :\n",
    "            #     personorientation = personorientation - 360                             #need to switch sign of yaxis positive is down and negative is up\n",
    "            #     print(personorientation)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            c = []\n",
    "            drone_speed = 10\n",
    "            for i in range (0, 10):\n",
    "                distancedrone = math.sqrt( ((currentdronepos[0][i]-previousdronepos[0][i])**2)+((currentdronepos[1][i]-previousdronepos[1][i])**2) )\n",
    "                c.append(distancedrone)\n",
    "                \n",
    "            print(c)\n",
    "            new_max_distance =  max(c)    \n",
    "            print(max(c))\n",
    "            \n",
    "            drone_totaltime = (new_max_distance/drone_speed)\n",
    "            \n",
    "            \n",
    "            \n",
    "            delta = 1 * drone_totaltime\n",
    "            person_distance = math.sqrt( (blob_personposition[0] - previous_blob_personposition[0] )**2 + (blob_personposition[1] - previous_blob_personposition[1])**2 )\n",
    "            \n",
    "            # person_time = drone_totaltime\n",
    "            # person_calculatedspeed = person_distance/person_time\n",
    "            # person_simspeed = 3    \n",
    "            c3 = person_distance #person_calculatedspeed *  person_time # to be updated\n",
    "            Scanning_direction_Waypoint_Distance = c3 + delta #c3   \n",
    "            if self._continous_converging > 1:\n",
    "                self.set_scan_direction_distance(Scanning_direction_Waypoint_Distance)\n",
    "            \n",
    "            import json\n",
    "            bd ={\n",
    "                    self._waypoint_count:blob_personposition,\n",
    "                    \n",
    "                }\n",
    "\n",
    "            \n",
    "\n",
    "            with open(r'C:\\Users\\Rakesh\\Downloads\\blobpositions.json','r+') as file3:\n",
    "            \n",
    "                    data3 = json.load(file3)\n",
    "                    data3.update(bd)\n",
    "                    file3.seek(0)\n",
    "                    json.dump(data3, file3)  \n",
    "                    \n",
    "                    \n",
    "            import json\n",
    "            rt ={\n",
    "                    self._waypoint_count:rect,\n",
    "                    \n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "            with open(r'C:\\Users\\Rakesh\\Downloads\\rectpositions.json','r+') as file6:\n",
    "            \n",
    "                    data6 = json.load(file6)\n",
    "                    data6.update(rt)\n",
    "                    file6.seek(0)\n",
    "                    json.dump(data6, file6)   \n",
    "                    \n",
    "                    \n",
    "            import json\n",
    "            sd1 ={\n",
    "                    self._waypoint_count:Scanning_direction_Waypoint_Distance,\n",
    "                    \n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "            with open(r'C:\\Users\\Rakesh\\Downloads\\scanningwaypointdistance.json','r+') as file11:\n",
    "            \n",
    "                    data11 = json.load(file11)\n",
    "                    data11.update(sd1)\n",
    "                    file11.seek(0)\n",
    "                    json.dump(data11, file11)                   \n",
    "        \n",
    "\n",
    "            # print(\"simulated_personposition\",person)\n",
    "            print(\"previous_blob_personposition\",previous_blob_personposition)\n",
    "            print(\"coverage\",coverage)\n",
    "            print(\"new_leader_index\",new_leader_index)\n",
    "            print(\"blobposition\",blobposition)\n",
    "            print(\"integralposition_centre\",integralposition_centre)\n",
    "            print(\"integral_startposition\",integral_startposition)\n",
    "            print(\"currentblob_personposition\",blob_personposition)\n",
    "            print(\"dronemeanpos\",dronemeanpos)\n",
    "            print(\"Scanning_direction\",Scanning_direction)\n",
    "            #print(\"personorientation\",personorientation)\n",
    "            # print(\"timeforcurrentiteration\",person_time)\n",
    "            print(\"Distancetravelledbyperson\",person_distance)\n",
    "            print(\"c3\",Scanning_direction_Waypoint_Distance)\n",
    "            \n",
    "            \n",
    "            motion = []\n",
    "            motion.append('Waypoint ' + str(self._waypoint_count) + ' \\n')\n",
    "            motion.append('rect ' + str(rect) + ' \\n')\n",
    "            motion.append('previous_blob_personposition ' + str(previous_blob_personposition) + ' \\n')\n",
    "            motion.append('coverage ' + str(coverage) + ' \\n')\n",
    "            motion.append('new_leader_index ' + str(new_leader_index) + ' \\n')\n",
    "            motion.append('blobposition ' + str(blobposition) + ' \\n')\n",
    "            motion.append('integralposition_centre ' + str(integralposition_centre) + ' \\n')\n",
    "            motion.append('integral_startposition ' + str(integral_startposition) + ' \\n')\n",
    "            motion.append('currentblob_personposition ' + str(blob_personposition) + ' \\n')\n",
    "            motion.append('dronemeanpos ' + str(dronemeanpos) + ' \\n')\n",
    "            motion.append('Scanning_direction ' + str(Scanning_direction) + ' \\n')\n",
    "            #motion.append('personorientation ' + str(personorientation) + ' \\n')\n",
    "            # motion.append('timeforcurrentiteration ' + str(person_time) + ' \\n')\n",
    "            motion.append('Distancetravelledbyperson ' + str(person_distance) + ' \\n')\n",
    "            motion.append('Scanning_direction_Waypoint_Distance_c3 ' + str(Scanning_direction_Waypoint_Distance) + ' \\n')\n",
    "            self.set_scanning_direction(Scanning_direction)\n",
    "            \n",
    "            self._blob_person_position = blob_personposition\n",
    "\n",
    "        with open(os.path.join(Live_Debug_Path,'motion.txt'), 'a') as f:\n",
    "            f.writelines('\\n'.join(motion))\n",
    "            \n",
    "\n",
    "        drones_next_east_loc = new_drone_rel_pos[0,:] + self._center_east\n",
    "        drones_next_north_loc = new_drone_rel_pos[1,:] + self._center_north\n",
    "\n",
    "        drones_next_lat,drones_next_lon = utm.to_latlon(drones_next_east_loc,drones_next_north_loc, self._zone_number, self._zone_letter)\n",
    "        info.append('drones next lat ' + str(drones_next_lat) + ' drones next lon ' + str(drones_next_lon)+ ' \\n')\n",
    "        drones_next_loc = zip(drones_next_lat, drones_next_lon)\n",
    "        #print(list(drones_next_loc))\n",
    "        self._current_gps_waypoints = drones_next_loc\n",
    "        #datasets_folder_live_debug= os.path.join( r\"E:\\Droneswarms_Feb_clientserverdevelopment\\live_debug\" )\n",
    "        with open(os.path.join(Live_Debug_Path,'WayPoint_Info.txt'), 'a') as f:\n",
    "            f.writelines('\\n'.join(info))\n",
    "        return drones_next_loc, self._previous_drone_pos, integral_image,leader_contour_area, leader_index, prev_contour_area,camera_id,leader_blob_image, leader_rx_image,gen_integral_blob_img,rect,personorientation,self._blob_person_position\n",
    "\n",
    "    def euclidean_distance_sqr(self,point1, point2):\n",
    "        \"\"\" euclidean_distance_sqr([1,2],[2,4])\n",
    "        5\n",
    "        \"\"\"\n",
    "        return (point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2\n",
    "\n",
    "\n",
    "    def column_based_sort(self,array, column=0):\n",
    "        \"\"\"\n",
    "        column_based_sort([(5, 1), (4, 2), (3, 0)], 1)\n",
    "        [(3, 0), (5, 1), (4, 2)]\n",
    "        \"\"\"\n",
    "        return sorted(array, key=lambda x: x[column])\n",
    "\n",
    "\n",
    "    def dis_between_closest_pair(self,points, points_counts, min_dis=float(\"inf\")):\n",
    "        \"\"\"\n",
    "        brute force approach to find distance between closest pair points\n",
    "\n",
    "        Parameters :\n",
    "        points, points_count, min_dis (list(tuple(int, int)), int, int)\n",
    "\n",
    "        Returns :\n",
    "        min_dis (float):  distance between closest pair of points\n",
    "\n",
    "        dis_between_closest_pair([[1,2],[2,4],[5,7],[8,9],[11,0]],5)\n",
    "        5\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        for i in range(points_counts - 1):\n",
    "            for j in range(i + 1, points_counts):\n",
    "                current_dis = self.euclidean_distance_sqr(points[i], points[j])\n",
    "                if current_dis < min_dis:\n",
    "                    min_dis = current_dis\n",
    "        return min_dis\n",
    "\n",
    "\n",
    "    def dis_between_closest_in_strip(self,points, points_counts, min_dis=float(\"inf\")):\n",
    "        \"\"\"\n",
    "        closest pair of points in strip\n",
    "\n",
    "        Parameters :\n",
    "        points, points_count, min_dis (list(tuple(int, int)), int, int)\n",
    "\n",
    "        Returns :\n",
    "        min_dis (float):  distance btw closest pair of points in the strip (< min_dis)\n",
    "\n",
    "        dis_between_closest_in_strip([[1,2],[2,4],[5,7],[8,9],[11,0]],5)\n",
    "        85\n",
    "        \"\"\"\n",
    "\n",
    "        for i in range(min(6, points_counts - 1), points_counts):\n",
    "            for j in range(max(0, i - 6), i):\n",
    "                current_dis = self.euclidean_distance_sqr(points[i], points[j])\n",
    "                if current_dis < min_dis:\n",
    "                    min_dis = current_dis\n",
    "        return min_dis\n",
    "\n",
    "\n",
    "\n",
    "    def closest_pair_of_points_sqr(self,points_sorted_on_x, points_sorted_on_y, points_counts):\n",
    "        \"\"\"divide and conquer approach\n",
    "\n",
    "        Parameters :\n",
    "        points, points_count (list(tuple(int, int)), int)\n",
    "\n",
    "        Returns :\n",
    "        (float):  distance btw closest pair of points\n",
    "\n",
    "        closest_pair_of_points_sqr([(1, 2), (3, 4)], [(5, 6), (7, 8)], 2)\n",
    "        8\n",
    "        \"\"\"\n",
    "\n",
    "        # base case\n",
    "        if points_counts <= 3:\n",
    "            return self.dis_between_closest_pair(points_sorted_on_x, points_counts)\n",
    "\n",
    "        # recursion\n",
    "        mid = points_counts // 2\n",
    "        closest_in_left = self.closest_pair_of_points_sqr(\n",
    "            points_sorted_on_x, points_sorted_on_y[:mid], mid\n",
    "        )\n",
    "        closest_in_right = self.closest_pair_of_points_sqr(\n",
    "            points_sorted_on_y, points_sorted_on_y[mid:], points_counts - mid\n",
    "        )\n",
    "        closest_pair_dis = min(closest_in_left, closest_in_right)\n",
    "\n",
    "        \"\"\"\n",
    "        cross_strip contains the points, whose Xcoords are at a\n",
    "        distance(< closest_pair_dis) from mid's Xcoord\n",
    "        \"\"\"\n",
    "\n",
    "        cross_strip = []\n",
    "        for point in points_sorted_on_x:\n",
    "            if abs(point[0] - points_sorted_on_x[mid][0]) < closest_pair_dis:\n",
    "                cross_strip.append(point)\n",
    "\n",
    "        closest_in_strip = self.dis_between_closest_in_strip(\n",
    "            cross_strip, len(cross_strip), closest_pair_dis\n",
    "        )\n",
    "        return min(closest_pair_dis, closest_in_strip)\n",
    "\n",
    "\n",
    "    def closest_pair_of_points(self,points, points_counts):\n",
    "        \"\"\"\n",
    "        closest_pair_of_points([(2, 3), (12, 30)], len([(2, 3), (12, 30)]))\n",
    "        28.792360097775937\n",
    "        \"\"\"\n",
    "        points_sorted_on_x = self.column_based_sort(points, column=0)\n",
    "        points_sorted_on_y = self.column_based_sort(points, column=1)\n",
    "        return (\n",
    "            self.closest_pair_of_points_sqr(\n",
    "                points_sorted_on_x, points_sorted_on_y, points_counts\n",
    "            )\n",
    "        ) ** 0.5\n",
    "\n",
    "\n",
    "\n",
    "    def perpendicular( self, a ) :\n",
    "        b = np.empty_like(a)\n",
    "        b[0] = -a[1]\n",
    "        b[1] = a[0]\n",
    "        return b\n",
    "\n",
    "    def normalize(self,a):\n",
    "        a = np.array(a)\n",
    "        return a/np.linalg.norm(a)\n",
    "\n",
    "        \n",
    "    def dis_between_farthest_pair(self,points, points_counts, min_dis=float(0)):\n",
    "        \"\"\"\n",
    "        brute force approach to find distance between closest pair points\n",
    "\n",
    "        Parameters :\n",
    "        points, points_count, min_dis (list(tuple(int, int)), int, int)\n",
    "\n",
    "        Returns :\n",
    "        min_dis (float):  distance between closest pair of points\n",
    "\n",
    "        dis_between_closest_pair([[1,2],[2,4],[5,7],[8,9],[11,0]],5)\n",
    "        5\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        for i in range(points_counts - 1):\n",
    "            for j in range(i + 1, points_counts):\n",
    "                current_dis = self.euclidean_distance_sqr(points[i], points[j])\n",
    "                if current_dis > min_dis:\n",
    "                    min_dis = current_dis\n",
    "        return min_dis\n",
    "\n",
    "    def dis_between_farthest_in_strip(self,points, points_counts, min_dis=float(0)):\n",
    "        \"\"\"\n",
    "        closest pair of points in strip\n",
    "\n",
    "        Parameters :\n",
    "        points, points_count, min_dis (list(tuple(int, int)), int, int)\n",
    "\n",
    "        Returns :\n",
    "        min_dis (float):  distance btw closest pair of points in the strip (< min_dis)\n",
    "\n",
    "        dis_between_closest_in_strip([[1,2],[2,4],[5,7],[8,9],[11,0]],5)\n",
    "        85\n",
    "        \"\"\"\n",
    "\n",
    "        for i in range(min(6, points_counts - 1), points_counts):\n",
    "            for j in range(max(0, i - 6), i):\n",
    "                current_dis = self.euclidean_distance_sqr(points[i], points[j])\n",
    "                if current_dis > min_dis:\n",
    "                    min_dis = current_dis\n",
    "        return min_dis\n",
    "\n",
    "    def farthest_pair_of_points_sqr(self,points_sorted_on_x, points_sorted_on_y, points_counts):\n",
    "        \"\"\"divide and conquer approach\n",
    "\n",
    "        Parameters :\n",
    "        points, points_count (list(tuple(int, int)), int)\n",
    "\n",
    "        Returns :\n",
    "        (float):  distance btw closest pair of points\n",
    "\n",
    "        closest_pair_of_points_sqr([(1, 2), (3, 4)], [(5, 6), (7, 8)], 2)\n",
    "        8\n",
    "        \"\"\"\n",
    "\n",
    "        # base case\n",
    "        if points_counts <= 3:\n",
    "            return self.dis_between_farthest_pair(points_sorted_on_x, points_counts)\n",
    "\n",
    "        # recursion\n",
    "        mid = points_counts // 2\n",
    "        closest_in_left = self.closest_pair_of_points_sqr(\n",
    "            points_sorted_on_x, points_sorted_on_y[:mid], mid\n",
    "        )\n",
    "        closest_in_right = self.closest_pair_of_points_sqr(\n",
    "            points_sorted_on_y, points_sorted_on_y[mid:], points_counts - mid\n",
    "        )\n",
    "        closest_pair_dis = max(closest_in_left, closest_in_right)\n",
    "\n",
    "        \"\"\"\n",
    "        cross_strip contains the points, whose Xcoords are at a\n",
    "        distance(< closest_pair_dis) from mid's Xcoord\n",
    "        \"\"\"\n",
    "\n",
    "        cross_strip = []\n",
    "        for point in points_sorted_on_x:\n",
    "            if abs(point[0] - points_sorted_on_x[mid][0]) > closest_pair_dis:\n",
    "                cross_strip.append(point)\n",
    "\n",
    "        closest_in_strip = self.dis_between_farthest_in_strip(\n",
    "            cross_strip, len(cross_strip), closest_pair_dis\n",
    "        )\n",
    "        return max(closest_pair_dis, closest_in_strip)\n",
    "\n",
    "\n",
    "    def farthest_pair_of_points(self,points, points_counts):\n",
    "        \"\"\"\n",
    "        closest_pair_of_points([(2, 3), (12, 30)], len([(2, 3), (12, 30)]))\n",
    "        28.792360097775937\n",
    "        \"\"\"\n",
    "        points_sorted_on_x = self.column_based_sort(points, column=0)\n",
    "        points_sorted_on_y = self.column_based_sort(points, column=1)\n",
    "        return (\n",
    "            self.farthest_pair_of_points_sqr(\n",
    "                points_sorted_on_x, points_sorted_on_y, points_counts\n",
    "            )\n",
    "        ) ** 0.5\n",
    "\n",
    "    def normalize(self,v):\n",
    "        norm = np.linalg.norm(v)\n",
    "        if norm == 0: \n",
    "            return v\n",
    "        return v / norm\n",
    "\n",
    "    def normalize_vectors(self,v):\n",
    "        #print(\"normalizing vectors\",v.shape[1])\n",
    "        for i in range(v.shape[1]):\n",
    "            temp = [v[0,i],v[1,i]]\n",
    "            norm = np.linalg.norm(temp)\n",
    "            if norm > 0.0: \n",
    "                v[0,i] = v[0,i]/norm\n",
    "                v[1,i] = v[1,i]/norm\n",
    "        return v\n",
    "\n",
    "    def dist(self,p1, p2):\n",
    "        return math.sqrt((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2)\n",
    "\n",
    "\n",
    "    # def rutherford_scattering(self,Y,N,f):     # new_drone_rel_pos, self._no_of_drones, self._minimum_drone_distance\n",
    "    #     ndim = 2\n",
    "    #     masses = np.ones(N)                    \n",
    "    #     charges = np.ones((N))*f\n",
    "    #     loc_arr = np.transpose(Y) \n",
    "    #     speed_arr = np.zeros((N, ndim))\n",
    "\n",
    "    #     # compute charge matrix, ie c1 * c2\n",
    "    #     charge_matrix = -1 * np.outer(charges, charges)\n",
    "\n",
    "    #     time = np.linspace(0, 0.5)\n",
    "    #     dt = np.ediff1d(time).mean()\n",
    "\n",
    "    #     for i, t in enumerate(time):\n",
    "    #         # get (dx, dy) for every point\n",
    "    #         delta = (loc_arr.T[..., np.newaxis] - loc_arr.T[:, np.newaxis]).T\n",
    "    #         # calculate Euclidean distance\n",
    "    #         distances = np.linalg.norm(delta, axis=-1)\n",
    "    #         # and normalised unit vector\n",
    "    #         unit_vector = (delta.T / distances).T\n",
    "    #         unit_vector[np.isnan(unit_vector)] = 0 # replace NaN values with 0\n",
    "\n",
    "    #         # calculate force\n",
    "    #         force = charge_matrix / distances**2 # norm gives length of delta vector\n",
    "    #         force[np.isinf(force)] = 0 # NaN forces are 0\n",
    "\n",
    "    #         # calculate acceleration in all dimensions\n",
    "    #         acc = (unit_vector.T * force / masses).T.sum(axis=1)\n",
    "    #         # v = a * dt\n",
    "    #         speed_arr += acc * dt\n",
    "\n",
    "    #         # increment position, xyz = v * dt\n",
    "    #         loc_arr += speed_arr * dt \n",
    "\n",
    "    #     return(np.transpose(loc_arr))\n",
    "    \n",
    "    \n",
    "    def rutherford_scattering(self,Y,N,f):\n",
    "        ndim = 2\n",
    "    \n",
    "        charges = np.ones((N))*f  #        charges = np.ones((N))*0.032*f\n",
    "\n",
    "        loc_arr = np.transpose(Y) \n",
    "        speed_arr = np.zeros((N, ndim))\n",
    "\n",
    "        # compute charge matrix, ie c1 * c2\n",
    "        charge_matrix = -1 * np.outer(charges, charges)\n",
    "        #print(charge_matrix)\n",
    "        time = np.linspace(0, 0.5,500)\n",
    "        dt = np.ediff1d(time).mean()\n",
    "        masses = np.ones(N) *dt  #        masses = np.ones(N) *dt *dt\n",
    "\n",
    "\n",
    "        for i, t in enumerate(time):\n",
    "            # get (dx, dy) for every point\n",
    "            delta = (loc_arr.T[..., np.newaxis] - loc_arr.T[:, np.newaxis]).T\n",
    "            #print(delta)\n",
    "            # calculate Euclidean distance\n",
    "            distances = np.linalg.norm(delta, axis=-1)\n",
    "            # and normalised unit vector\n",
    "            unit_vector = (delta.T / distances).T\n",
    "            unit_vector[np.isnan(unit_vector)] = 0 # replace NaN values with 0\n",
    "\n",
    "            # calculate force\n",
    "            force = charge_matrix / distances**2 # norm gives length of delta vector\n",
    "            force[np.isinf(force)] = 0 # NaN forces are 0\n",
    "\n",
    "            # calculate acceleration in all dimensions\n",
    "            acc = (unit_vector.T * force / masses).T.sum(axis=1)\n",
    "            # v = a * dt\n",
    "            speed_arr = acc * dt\n",
    "\n",
    "            # increment position, xyz = v * dt\n",
    "            loc_arr += speed_arr * dt \n",
    "\n",
    "        return(np.transpose(loc_arr))\n",
    "\n",
    "def eul2rotm(theta) :\n",
    "    s_1 = math.sin(theta[0])\n",
    "    c_1 = math.cos(theta[0]) \n",
    "    s_2 = math.sin(theta[1]) \n",
    "    c_2 = math.cos(theta[1]) \n",
    "    s_3 = math.sin(theta[2]) \n",
    "    c_3 = math.cos(theta[2])\n",
    "    rotm = np.identity(3)\n",
    "    rotm[0,0] =  c_1*c_2\n",
    "    rotm[0,1] =  c_1*s_2*s_3 - s_1*c_3\n",
    "    rotm[0,2] =  c_1*s_2*c_3 + s_1*s_3\n",
    "\n",
    "    rotm[1,0] =  s_1*c_2\n",
    "    rotm[1,1] =  s_1*s_2*s_3 + c_1*c_3\n",
    "    rotm[1,2] =  s_1*s_2*c_3 - c_1*s_3\n",
    "\n",
    "    rotm[2,0] = -s_2\n",
    "    rotm[2,1] =  c_2*s_3\n",
    "    rotm[2,2] =  c_2*c_3        \n",
    "\n",
    "    return rotm\n",
    "\n",
    "\n",
    "def imshow(image, *args, **kwargs):\n",
    "     \n",
    "    if len(image.shape) == 3: \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    plt.imshow(image, *args, **kwargs)\n",
    "    plt.axis('off')\n",
    "    \n",
    "\n",
    "def divide_by_alpha(img):\n",
    "    a = img[:,:,3]\n",
    "    aaa = np.stack((a,a,a),axis=-1)\n",
    "    rgb = img[:,:,:3]/aaa \n",
    "    rgb[aaa==0] = np.nan\n",
    "    return rgb\n",
    "\n",
    "def divide_by_alpha1(rimg2):\n",
    "    a = np.stack((rimg2[:,:,3],rimg2[:,:,3],rimg2[:,:,3]),axis=-1)\n",
    "    return rimg2[:,:,:3]/a\n",
    "\n",
    "\n",
    "def createviewmateuler(eulerang, camLocation):\n",
    "    \n",
    "    rotationmat = eul2rotm(eulerang)\n",
    "    translVec =  np.reshape((-camLocation @ rotationmat),(3,1))\n",
    "    conjoinedmat = (np.append(np.transpose(rotationmat), translVec, axis=1))\n",
    "    return conjoinedmat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################Definations defined above###############################################################\n",
    "#############################Start the Chrome Browser###############################################################\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "options = Options()\n",
    "\n",
    "\n",
    "options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "options.add_experimental_option(\"excludeSwitches\",[\"enable-automation\"])\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "#############################Start the AOS Renderer###############################################################\n",
    "w,h,fovDegrees = 512, 512, 50 # # resolution and field of view\n",
    "render_fov = 50\n",
    "\n",
    "if 'window' not in locals() or window == None:\n",
    "                                    \n",
    "    window = LFR.PyGlfwWindow( w, h, 'AOS' )  \n",
    "     \n",
    "aos = LFR.PyAOS(w,h,fovDegrees) \n",
    "set_folder = r'D:\\Rendering\\AOS-alpha_mask'\n",
    "aos.loadDEM( os.path.join(set_folder,'zero_plane.obj'))\n",
    "\n",
    "\n",
    "NumberofDrones = 10\n",
    "fov = 50\n",
    "rxthreshold = 0.9998\n",
    "dem_height = 33\n",
    "distance_btwn_drones = 4.2 #4.0 \n",
    "Scanning_direction = 0\n",
    "Scanning_direction_Waypoint_Distance = 2.0 #c3\n",
    "emptyblobthreshold = 0.0\n",
    "changing_to_linear_speed = 0.3 #c5\n",
    "local_fac = 1.0   #c1\n",
    "global_fac = 2.0   #c2  # global fac > local fac   # local fac == minimum distance\n",
    "minimum_distance_btwn_drone = 4.2 #c4  4.0\n",
    "\n",
    "\n",
    "person=[0,10]   #[8,21] (0,10), (-3,10)\n",
    "personorientation = 100\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#prevwaypoints = np.array([[0,0,0,0,0,0,0,0,0,0],[-12,-12,-12,-12,-12,-12,-12,-12,-12,-12]], dtype = 'float')   # should be same as refloc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################Get Drones Initial Positions###############################################################\n",
    "test_drone_pso = drone_pso(aos,NumberofDrones,fov,rxthreshold,distance_btwn_drones,Scanning_direction,Scanning_direction_Waypoint_Distance,emptyblobthreshold,(48.335836, 14.326644),changing_to_linear_speed,local_fac,global_fac,minimum_distance_btwn_drone,False)\n",
    "current_gps_locations,ref_loc = test_drone_pso.get_current_waypoints()\n",
    "\n",
    "#for i in range (10):\n",
    "#    ref_loc[1][i]= -20\n",
    "    \n",
    "# 48.335836, 14.326644\n",
    "# added from n=10 sparse t = 175 last iteration = 63 (or 125 in data.json)\n",
    "\n",
    "ref_loc =  np.array([[9.9717100350285, 7.509278207141478, 7.9509800794951735, 10.435511445470253, -0.7602028575178091, 13.721811741972076, 1.924510020547081, 4.666728601049116, 3.231715985565085, 0.936382834234614], [-8.656215061944506, -5.710321502200583, -0.16034449090046393, 3.5812591450458786, 0.30581173782537846, -5.231449516231961, -7.244081751496854, -2.52686032502034, 3.1534761204635524, -3.2818597748696416]], dtype = 'float')\n",
    "\n",
    "###below is for old drones n=10 300trees/ha without altitude bias\n",
    "#ref_loc =  np.array([[1.8115134503385846, 10.133639847964734, 12.629432704779868, 11.903718818156282, 6.7633418126185845, 4.691795821233404, 5.602373545591946, 8.155933054264636, 7.186430847096473, 0.3061385423385319], [-5.02637415149285, 5.097264629755322, 1.958122637084436, -3.986459164351714, 7.253806446287938, 1.848477920955482, -6.393277670197103, 1.9794189449672637, -2.746389521970734, 1.4854112721404695]], dtype = 'float')\n",
    "#print(ref_loc)\n",
    "\n",
    "\n",
    "prevwaypoints = ref_loc\n",
    "\n",
    "#print(prevwaypoints)\n",
    "drone_names = ['1','2','3','4','5','6','7','8','9','10']\n",
    "\n",
    "#############################For First Step --- Determining Person Blob Size###############################################################\n",
    "step_count = 0\n",
    "#############################Create Link for Initial Positions###############################################################\n",
    "altitude_list = [43,41,39,37,35,36,38,40,42,44] # [40,40,40,40,40,40,40,40,40,40] \n",
    "#### For 10 drones\n",
    "link1=\"http://127.0.0.1:5504/?drone1x=\"+str(ref_loc[0][0])+\"&drone1y=\"+str(ref_loc[1][0])+\"&drone2x=\"+str(ref_loc[0][1])+\"&drone2y=\"+str(ref_loc[1][1])+\"&drone3x=\"+str(ref_loc[0][2])+\"&drone3y=\"+str(ref_loc[1][2])+\"&drone4x=\"+str(ref_loc[0][3])+\"&drone4y=\"+str(ref_loc[1][3])+\"&drone5x=\"+str(ref_loc[0][4])+\"&drone5y=\"+str(ref_loc[1][4])+\"&drone6x=\"+str(ref_loc[0][5])+\"&drone6y=\"+str(ref_loc[1][5])+\"&drone7x=\"+str(ref_loc[0][6])+\"&drone7y=\"+str(ref_loc[1][6])+\"&drone8x=\"+str(ref_loc[0][7])+\"&drone8y=\"+str(ref_loc[1][7])+\"&drone9x=\"+str(ref_loc[0][8])+\"&drone9y=\"+str(ref_loc[1][8])+\"&drone10x=\"+str(ref_loc[0][9])+\"&drone10y=\"+str(ref_loc[1][9])+\"&personx=\"+str(person[0])+\"&persony=\"+str(person[1])+\"&personorient=\"+str(personorientation)+\"&filename=\"+('Waypoint'+str(step_count))+\"&xlist=\"+(treex)+\"&ylist=\"+(treey)+\"&prevdrone1x=\"+str(prevwaypoints[0][0])+\"&prevdrone1y=\"+str(prevwaypoints[1][0])+\"&prevdrone2x=\"+str(prevwaypoints[0][1])+\"&prevdrone2y=\"+str(prevwaypoints[1][1])+\"&prevdrone3x=\"+str(prevwaypoints[0][2])+\"&prevdrone3y=\"+str(prevwaypoints[1][2])+\"&prevdrone4x=\"+str(prevwaypoints[0][3])+\"&prevdrone4y=\"+str(prevwaypoints[1][3])+\"&prevdrone5x=\"+str(prevwaypoints[0][4])+\"&prevdrone5y=\"+str(prevwaypoints[1][4])+\"&prevdrone6x=\"+str(prevwaypoints[0][5])+\"&prevdrone6y=\"+str(prevwaypoints[1][5])+\"&prevdrone7x=\"+str(prevwaypoints[0][6])+\"&prevdrone7y=\"+str(prevwaypoints[1][6])+\"&prevdrone8x=\"+str(prevwaypoints[0][7])+\"&prevdrone8y=\"+str(prevwaypoints[1][7])+\"&prevdrone9x=\"+str(prevwaypoints[0][8])+\"&prevdrone9y=\"+str(prevwaypoints[1][8])+\"&prevdrone10x=\"+str(prevwaypoints[0][9])+\"&prevdrone10y=\"+str(prevwaypoints[1][9])+\"&altd1=\"+str(altitude_list[0])+\"&altd2=\"+str(altitude_list[1])+\"&altd3=\"+str(altitude_list[2])+\"&altd4=\"+str(altitude_list[3])+\"&altd5=\"+str(altitude_list[4])+\"&altd6=\"+str(altitude_list[5])+\"&altd7=\"+str(altitude_list[6])+\"&altd8=\"+str(altitude_list[7])+\"&altd9=\"+str(altitude_list[8])+\"&altd10=\"+str(altitude_list[9])\n",
    "\n",
    "print(link1)\n",
    "Saved_Img_Location = \"Waypoint\"+str(step_count) + '.'+'zip'\n",
    "print(Saved_Img_Location)\n",
    "print(os.path.splitext(Saved_Img_Location)[0])\n",
    "Current_Waypoint_Images_Loc = os.path.join(Download_Location,'images', os.path.splitext(Saved_Img_Location)[0])\n",
    "os.mkdir(Current_Waypoint_Images_Loc)\n",
    "Current_Path = os.path.join(Download_Location,Saved_Img_Location)\n",
    "print(Current_Path)\n",
    "#############################Create Poses for Initial Positions###############################################################\n",
    "#############################Create Poses for Initial Positions###############################################################\n",
    "site_poses = []\n",
    "for i in range(NumberofDrones):\n",
    "    EastCentered = (ref_loc[0][i] - 0.0) #Get MeanEast and Set MeanEast\n",
    "    NorthCentered = (0.0 - ref_loc[1][i]) #Get MeanNorth and Set MeanNorth\n",
    "    Alt = dem_height\n",
    "    M = createviewmateuler(np.array([0.0, 0.0, 0.0]),np.array( [ref_loc[0][i], ref_loc[1][i], 35 - altitude_list[i]] ))\n",
    "    ViewMatrix = np.vstack((M, np.array([0.0,0.0,0.0,1.0],dtype=np.float32)))\n",
    "    camerapose = np.asarray(ViewMatrix.transpose(),dtype=np.float32)\n",
    "    site_poses.append(camerapose)  \n",
    "#############################Send the Link to Simulator to generate the images###############################################################\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "options = Options()\n",
    "\n",
    "\n",
    "options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "options.add_experimental_option(\"excludeSwitches\",[\"enable-automation\"])\n",
    "options.add_argument(\"start-maximized\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "driver.maximize_window()\n",
    "driver.get(link1)\n",
    "\n",
    "time.sleep(10)\n",
    "while not os.path.exists(Current_Path):\n",
    "    time.sleep(1)\n",
    "\n",
    "if os.path.isfile(Current_Path):\n",
    "    print(\"read file\")\n",
    "    with ZipFile(Current_Path,'r') as zipObj:\n",
    "        zipObj.extractall(path=Current_Path.split(\".\")[0])\n",
    "else:\n",
    "    print('error')#\n",
    "Current_Path = os.path.join(Download_Location,os.path.splitext(Saved_Img_Location)[0])\n",
    "#############################Read the generated images###############################################################\n",
    "#imagelist = [os.path.basename(x) for x in sorted(glob.glob(os.path.join(top_path, '*.png')))]\n",
    "single_images = []\n",
    "for i in range(NumberofDrones):\n",
    "    image_name = [os.path.basename(x) for x in sorted(glob.glob(os.path.join(Current_Path, drone_names[i], 'camera', '*.png')))]\n",
    "    g_1 = cv2.imread(os.path.join(Current_Path, drone_names[i], 'camera',image_name[0]))\n",
    "    g_2 = cv2.imread(os.path.join(Current_Path, drone_names[i], 'camera',image_name[1]),cv2.IMREAD_GRAYSCALE)\n",
    "    result = np.dstack((g_1, g_2))\n",
    "    print('result: ', result.shape)\n",
    "    #os.remove(os.path.join(Current_Path, drone_names[i], 'camera',image_name[0])) \n",
    "    #os.remove(os.path.join(Current_Path, drone_names[i], 'camera',image_name[1])) \n",
    "    cv2.imwrite(os.path.join(Current_Path, drone_names[i], 'camera','test'+str(i)+'.png'),result)\n",
    "  \n",
    "    \n",
    "for i in range(NumberofDrones):\n",
    "    image_name = [os.path.basename(x) for x in sorted(glob.glob(os.path.join(Current_Path, drone_names[i], 'camera', '*.png')))]\n",
    "    # print(Current_Path)\n",
    "    # print(drone_names[i])\n",
    "    print('camera',image_name[0]) \n",
    "    # print(Current_Waypoint_Images_Loc)\n",
    "    # print(os.path.join(Current_Path, drone_names[i], 'camera',image_name[0]))\n",
    "    shutil.copy2(os.path.join(Current_Path, drone_names[i], 'camera',image_name[2]), os.path.join(Current_Waypoint_Images_Loc,image_name[2]))\n",
    "    img = cv2.imread(os.path.join(Current_Path, drone_names[i], 'camera',image_name[2]),cv2.IMREAD_UNCHANGED)\n",
    "    print('Image Dimensions :', img.shape)\n",
    "    single_images.append(img)\n",
    "print(os.path.splitext(Saved_Img_Location)[0])\n",
    "shutil.copy2(os.path.join(Current_Path, 'stage', 'cropped_image.png'), os.path.join(Stages_Path,os.path.splitext(Saved_Img_Location)[0]+'.png'))\n",
    "print(prevwaypoints)\n",
    "#############################For the First Step ---- Compute the Blob Threshold###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################For the First Step ---- Compute the Blob Threshold###############################################################\n",
    "\n",
    "\n",
    "fov = 50\n",
    "rxthreshold = 0.9998\n",
    "dem_height = 33\n",
    "compasscorrection = 0\n",
    "center_rgb_integral_image, leader_rx_image, Leader_index, leader_contour = test_drone_pso.determine_emptyblob_threshold(single_images,site_poses, fov = fov, rxthreshold =  rxthreshold, dem_height = dem_height, compasscorrection = compasscorrection , pos = None)\n",
    "cv2.imwrite(\"rendered_image_setting_threshold.png\",center_rgb_integral_image)\n",
    "cv2.imwrite(\"leaderrx_image_setting_threshold.png\",leader_rx_image)\n",
    "print(leader_contour)\n",
    "print(Leader_index)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#############################For the First Step ---- set the Blob Threshold###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emptyblobthreshold = 220 #145  #170\n",
    "test_drone_pso.set_emptyblob_threshold(emptyblobthreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person=[0,10]  #[15,21]\n",
    "personorientation = 100\n",
    "######################################Change Person Location After Initialization##########################################################\n",
    "step_count = 1\n",
    "print(ref_loc)\n",
    "print(prevwaypoints)\n",
    "altitude_list = [43,41,39,37,35,36,38,40,42,44] # [40,40,40,40,40,40,40,40,40,40] \n",
    "drawing_current_location = ref_loc\n",
    "drawing_previous_location = prevwaypoints\n",
    "print(ref_loc)\n",
    "print(prevwaypoints)\n",
    "c = []\n",
    "for i in range (0, NumberofDrones):\n",
    "    distance = math.sqrt( ((ref_loc[0][i]-prevwaypoints[0][i])**2)+((ref_loc[1][i]-prevwaypoints[1][i])**2) )\n",
    "    c.append(distance)\n",
    "    \n",
    "print(c)\n",
    "max_distance =  max(c)    \n",
    "print(max(c))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "d = {\n",
    "    1:ref_loc.tolist(),\n",
    "    2:prevwaypoints.tolist()\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "json.dump(d,open(r'C:\\Users\\Rakesh\\Downloads\\data.json',\"w\"))\n",
    "\n",
    "\n",
    "jd = {\n",
    "    1:person,\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "json.dump(jd,open(r'C:\\Users\\Rakesh\\Downloads\\personpositions.json',\"w\"))\n",
    "\n",
    "# i = 3\n",
    "# a = {\n",
    "#     i:prevwaypoints.tolist(),\n",
    "#     4:prevwaypoints.tolist()\n",
    "# }\n",
    "\n",
    "\n",
    "po = {\n",
    "    1:personorientation,\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "json.dump(po,open(r'C:\\Users\\Rakesh\\Downloads\\personorientation.json',\"w\"))\n",
    "\n",
    "rt2 = {\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "json.dump(rt2,open(r'C:\\Users\\Rakesh\\Downloads\\rectpositions.json',\"w\"))\n",
    "\n",
    "import json\n",
    "bd ={\n",
    "        \n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "json.dump(bd,open(r'C:\\Users\\Rakesh\\Downloads\\blobpositions.json',\"w\"))\n",
    "\n",
    "\n",
    "import json\n",
    "sd ={\n",
    "        \n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "json.dump(sd,open(r'C:\\Users\\Rakesh\\Downloads\\scanningwaypointdistance.json',\"w\"))\n",
    "\n",
    "print(ref_loc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(ref_loc)\n",
    "\n",
    "link1=\"http://127.0.0.1:5504/?drone1x=\"+str(ref_loc[0][0])+\"&drone1y=\"+str(ref_loc[1][0])+\"&drone2x=\"+str(ref_loc[0][1])+\"&drone2y=\"+str(ref_loc[1][1])+\"&drone3x=\"+str(ref_loc[0][2])+\"&drone3y=\"+str(ref_loc[1][2])+\"&drone4x=\"+str(ref_loc[0][3])+\"&drone4y=\"+str(ref_loc[1][3])+\"&drone5x=\"+str(ref_loc[0][4])+\"&drone5y=\"+str(ref_loc[1][4])+\"&drone6x=\"+str(ref_loc[0][5])+\"&drone6y=\"+str(ref_loc[1][5])+\"&drone7x=\"+str(ref_loc[0][6])+\"&drone7y=\"+str(ref_loc[1][6])+\"&drone8x=\"+str(ref_loc[0][7])+\"&drone8y=\"+str(ref_loc[1][7])+\"&drone9x=\"+str(ref_loc[0][8])+\"&drone9y=\"+str(ref_loc[1][8])+\"&drone10x=\"+str(ref_loc[0][9])+\"&drone10y=\"+str(ref_loc[1][9])+\"&personx=\"+str(person[0])+\"&persony=\"+str(person[1])+\"&personorient=\"+str(personorientation)+\"&filename=\"+('Waypoint'+str(step_count))+\"&xlist=\"+(treex)+\"&ylist=\"+(treey)+\"&prevdrone1x=\"+str(prevwaypoints[0][0])+\"&prevdrone1y=\"+str(prevwaypoints[1][0])+\"&prevdrone2x=\"+str(prevwaypoints[0][1])+\"&prevdrone2y=\"+str(prevwaypoints[1][1])+\"&prevdrone3x=\"+str(prevwaypoints[0][2])+\"&prevdrone3y=\"+str(prevwaypoints[1][2])+\"&prevdrone4x=\"+str(prevwaypoints[0][3])+\"&prevdrone4y=\"+str(prevwaypoints[1][3])+\"&prevdrone5x=\"+str(prevwaypoints[0][4])+\"&prevdrone5y=\"+str(prevwaypoints[1][4])+\"&prevdrone6x=\"+str(prevwaypoints[0][5])+\"&prevdrone6y=\"+str(prevwaypoints[1][5])+\"&prevdrone7x=\"+str(prevwaypoints[0][6])+\"&prevdrone7y=\"+str(prevwaypoints[1][6])+\"&prevdrone8x=\"+str(prevwaypoints[0][7])+\"&prevdrone8y=\"+str(prevwaypoints[1][7])+\"&prevdrone9x=\"+str(prevwaypoints[0][8])+\"&prevdrone9y=\"+str(prevwaypoints[1][8])+\"&prevdrone10x=\"+str(prevwaypoints[0][9])+\"&prevdrone10y=\"+str(prevwaypoints[1][9])+\"&altd1=\"+str(altitude_list[0])+\"&altd2=\"+str(altitude_list[1])+\"&altd3=\"+str(altitude_list[2])+\"&altd4=\"+str(altitude_list[3])+\"&altd5=\"+str(altitude_list[4])+\"&altd6=\"+str(altitude_list[5])+\"&altd7=\"+str(altitude_list[6])+\"&altd8=\"+str(altitude_list[7])+\"&altd9=\"+str(altitude_list[8])+\"&altd10=\"+str(altitude_list[9])+\"&leader=\"+str(Leader_index)\n",
    "# Leader_index\n",
    "print(link1)\n",
    "print(ref_loc)\n",
    "print(prevwaypoints)\n",
    "Saved_Img_Location = \"Waypoint\"+ str(step_count) + '.'+'zip'\n",
    "print(Saved_Img_Location)\n",
    "print(os.path.splitext(Saved_Img_Location)[0])\n",
    "Current_Waypoint_Images_Loc = os.path.join(Download_Location,'images', os.path.splitext(Saved_Img_Location)[0])\n",
    "os.mkdir(Current_Waypoint_Images_Loc)\n",
    "Current_Path = os.path.join(Download_Location,Saved_Img_Location)\n",
    "print(Current_Path)\n",
    "#############################Create Poses for Initial Positions###############################################################\n",
    "#############################Create Poses for Initial Positions###############################################################\n",
    "site_poses = []\n",
    "for i in range(NumberofDrones):\n",
    "    EastCentered = (ref_loc[0][i] - 0.0) #Get MeanEast and Set MeanEast\n",
    "    NorthCentered = (0.0 - ref_loc[1][i]) #Get MeanNorth and Set MeanNorth\n",
    "    Alt = dem_height\n",
    "    M = createviewmateuler(np.array([0.0, 0.0, 0.0]),np.array( [ref_loc[0][i], ref_loc[1][i],  35 - altitude_list[i]] ))\n",
    "    ViewMatrix = np.vstack((M, np.array([0.0,0.0,0.0,1.0],dtype=np.float32)))\n",
    "    camerapose = np.asarray(ViewMatrix.transpose(),dtype=np.float32)\n",
    "    site_poses.append(camerapose)\n",
    "#############################Send the Link to Simulator to generate the images###############################################################\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "driver.get(link1)\n",
    "driver.maximize_window()\n",
    "time.sleep(10)\n",
    "while not os.path.exists(Current_Path):\n",
    "    time.sleep(1)\n",
    "\n",
    "if os.path.isfile(Current_Path):\n",
    "    print(\"read file\")\n",
    "    with ZipFile(Current_Path,'r') as zipObj:\n",
    "        zipObj.extractall(path=Current_Path.split(\".\")[0])\n",
    "else:\n",
    "    print('error')#\n",
    "Current_Path = os.path.join(Download_Location,os.path.splitext(Saved_Img_Location)[0])\n",
    "#############################Read the generated images###############################################################\n",
    "#imagelist = [os.path.basename(x) for x in sorted(glob.glob(os.path.join(top_path, '*.png')))]\n",
    "single_images = []\n",
    "\n",
    "# thermal_images_list = []\n",
    "# for i in range(NumberofDrones):\n",
    "#     image_name = [os.path.basename(x) for x in sorted(glob.glob(os.path.join(Current_Path, drone_names[i], 'camera', '*.png')))]\n",
    "#     g_2 = cv2.imread(os.path.join(Current_Path, drone_names[i], 'camera',image_name[1]))\n",
    "#     thermal_images_list.append(g_2)\n",
    "\n",
    "for i in range(NumberofDrones):\n",
    "    image_name = [os.path.basename(x) for x in sorted(glob.glob(os.path.join(Current_Path, drone_names[i], 'camera', '*.png')))]\n",
    "    g_1 = cv2.imread(os.path.join(Current_Path, drone_names[i], 'camera',image_name[0]))\n",
    "    g_2 = cv2.imread(os.path.join(Current_Path, drone_names[i], 'camera',image_name[1]),cv2.IMREAD_GRAYSCALE)\n",
    "    result = np.dstack((g_1, g_2))\n",
    "    print('result: ', result.shape)\n",
    "    #os.remove(os.path.join(Current_Path, drone_names[i], 'camera',image_name[0])) \n",
    "    #os.remove(os.path.join(Current_Path, drone_names[i], 'camera',image_name[1])) \n",
    "    cv2.imwrite(os.path.join(Current_Path, drone_names[i], 'camera','test'+str(i)+'.png'),result)\n",
    "\n",
    "for i in range(NumberofDrones):\n",
    "    image_name = [os.path.basename(x) for x in sorted(glob.glob(os.path.join(Current_Path, drone_names[i], 'camera', '*.png')))]\n",
    "    # print(Current_Path)\n",
    "    # print(drone_names[i])\n",
    "    # print('camera',image_name[0]) \n",
    "    # print(Current_Waypoint_Images_Loc)\n",
    "    # print(os.path.join(Current_Path, drone_names[i], 'camera',image_name[0]))\n",
    "    shutil.copy2(os.path.join(Current_Path, drone_names[i], 'camera',image_name[2]), os.path.join(Current_Waypoint_Images_Loc,image_name[2]))\n",
    "    \n",
    "    shutil.copy2(os.path.join(Current_Path, drone_names[i], 'camera',image_name[1]), os.path.join(Current_Waypoint_Images_Loc,image_name[1]))\n",
    "    img = cv2.imread(os.path.join(Current_Path, drone_names[i], 'camera',image_name[2]),cv2.IMREAD_UNCHANGED)\n",
    "    print('Image Dimensions :', img.shape)\n",
    "    single_images.append(img)\n",
    "print(os.path.splitext(Saved_Img_Location)[0])\n",
    "shutil.copy2(os.path.join(Current_Path, 'stage', 'cropped_image.png'), os.path.join(Stages_Path,os.path.splitext(Saved_Img_Location)[0]+'.png'))\n",
    "\n",
    "#############################For the First Step ---- Compute the Blob Threshold###############################################################\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgs = test_drone_pso._metric_cal.project_images_to_all(aos,img_list = thermal_images_list,pose_list=site_poses,fov = fov,center_camera_index=5,project_images=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(imgs))\n",
    "#cv2.imwrite(os.path.join(r'C:\\Users\\Rakesh\\Downloads\\Final_result', ('stuff_' + str(0) + '.png')),imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aos.clearViews();\n",
    "print(ref_loc)\n",
    "print(prevwaypoints)\n",
    "prevwaypoints = ref_loc\n",
    "x_axis_mean = np.mean(np.asarray(ref_loc[0][:]))\n",
    "y_axis_mean = np.mean(np.asarray(ref_loc[1][:]))\n",
    "Alts = dem_height\n",
    "\n",
    "#############################For the First Step ---- Get the Next Locations###############################################################            \n",
    "center_EastCentered = (x_axis_mean - 0.0) #Get MeanEast and Set MeanEast\n",
    "center_NorthCentered = (0.0 - y_axis_mean) #Get MeanNorth and Set MeanNorth\n",
    "#center_M = createviewmateuler(np.array([(0.0), 0, 0]),np.array( [center_EastCentered, center_NorthCentered, -Alts] ))\n",
    "center_M = createviewmateuler(np.array([0.0, 0.0, 0.0]),np.array( [x_axis_mean, y_axis_mean, 0.0] ))\n",
    "center_ViewMatrix = np.vstack((center_M, np.array([0.0,0.0,0.0,1.0],dtype=np.float32)))\n",
    "center_camerapose = np.asarray(center_ViewMatrix.transpose(),dtype=np.float32)\n",
    "\n",
    "\n",
    "\n",
    "newgps, newloc, new_integral_image, new_leader_contour,new_leader_index,metric_area,cameraid,leader_blob_image, leader_rx_image,gen_integral_blob_img,rect,personorientation,blobposition = test_drone_pso.get_waypoints_with_pso_motion(single_images,site_poses,center_camerapose) ## Change Virtual Camera Pose to Center Position\n",
    "#rx_image_normalize = cv2.normalize(leader_rx_image.astype('float'), None, 0.0, 1.0, norm_type=cv2.NORM_MINMAX) #normalize the mask to be between 1 and 0\n",
    "#cv2.imwrite(os.path.join( leader_rx_image_folder,  str(2)+ 'leader_rx_image.png'), ((rx_image_normalize)*255).astype(np.uint8))\n",
    "\n",
    "################################################################################motion################################################################3\n",
    "\n",
    "# previous_blob_personposition = person \n",
    "# coverage = 2*altitude_list[new_leader_index]*np.tan(np.deg2rad(25))\n",
    "# resolution = 512\n",
    "# metretopixels = coverage/resolution\n",
    "# blob_posx = rect[0] + rect[2]/2\n",
    "# blob_posy = rect[1] + rect[3]/2\n",
    "# blob_posxinpixels = blob_posx * metretopixels\n",
    "# blob_posyinpixels = blob_posy * metretopixels\n",
    "# blobposition = [blob_posxinpixels,blob_posyinpixels]\n",
    "# integralposition_centre = [ref_loc[0][new_leader_index], ref_loc[1][new_leader_index]]\n",
    "# integral_startposition = [integralposition_centre[0] - coverage/2, integralposition_centre[1] - coverage/2]\n",
    "# blob_personposition = [blobposition[0] - abs(integral_startposition[0]), blobposition[1] - abs(integral_startposition[1])]\n",
    "\n",
    "# dronemeanx=(np.mean(ref_loc[0]))\n",
    "# dronemeany=(np.mean(ref_loc[1]))\n",
    "# dronemeanpos = [dronemeanx,dronemeany]\n",
    "# dy = (-blob_personposition[1]-(-dronemeany))\n",
    "# dx = (blob_personposition[0]-dronemeanx)\n",
    "\n",
    "# Scanning_direction = np.arctan2(dy,dx)\n",
    "# Scanning_direction = ((np.degrees(Scanning_direction))%360)+90\n",
    "# print(Scanning_direction)\n",
    "# if Scanning_direction == 0 or Scanning_direction>=360 :\n",
    "#     Scanning_direction = 0                             #need to switch sign of yaxis positive is down and negative is up\n",
    "#     print(Scanning_direction)\n",
    "\n",
    "\n",
    "# person = [0,10]\n",
    "# dyp = (-blob_personposition[1]-(-previous_blob_personposition[1]))\n",
    "# dxp = (blob_personposition[0]-previous_blob_personposition[0])\n",
    "# personorientation = np.arctan2(dyp,dxp)\n",
    "# personorientation = ((np.degrees(personorientation))%360)+90\n",
    "# print(personorientation)\n",
    "# if personorientation == 0 or personorientation>=360 :\n",
    "#     personorientation = 0                             #need to switch sign of yaxis positive is down and negative is up\n",
    "#     print(personorientation)\n",
    "    \n",
    "# delta = 0.2    \n",
    "# c3 = 2.0\n",
    "\n",
    "# Scanning_direction_Waypoint_Distance = c3 + delta #c3   # first waypoint so no change in c3\n",
    "\n",
    "# print(\"simulated_personposition\",person)\n",
    "# print(\"previous_blob_personposition\",previous_blob_personposition)\n",
    "# print(\"coverage\",coverage)\n",
    "# print(\"new_leader_index\",new_leader_index)\n",
    "# print(\"blobposition\",blobposition)\n",
    "# print(\"integralposition_centre\",integralposition_centre)\n",
    "# print(\"integral_startposition\",integral_startposition)\n",
    "# print(\"currentblob_personposition\",blob_personposition)\n",
    "# print(\"dronemeanpos\",dronemeanpos)\n",
    "# print(\"Scanning_direction\",Scanning_direction)\n",
    "# print(\"personorientation\",personorientation)\n",
    "# print(\"c3\",Scanning_direction_Waypoint_Distance)\n",
    "\n",
    "# motion = []\n",
    "# motion.append('Waypoint ' + str(1) + ' \\n')\n",
    "# motion.append('person ' + str(person) + ' \\n')\n",
    "# motion.append('previous_blob_personposition ' + str(previous_blob_personposition) + ' \\n')\n",
    "# motion.append('coverage ' + str(coverage) + ' \\n')\n",
    "# motion.append('new_leader_index ' + str(new_leader_index) + ' \\n')\n",
    "# motion.append('blobposition ' + str(blobposition) + ' \\n')\n",
    "# motion.append('integralposition_centre ' + str(integralposition_centre) + ' \\n')\n",
    "# motion.append('integral_startposition ' + str(integral_startposition) + ' \\n')\n",
    "# motion.append('currentblob_personposition ' + str(blob_personposition) + ' \\n')\n",
    "# motion.append('dronemeanpos ' + str(dronemeanpos) + ' \\n')\n",
    "# motion.append('Scanning_direction ' + str(Scanning_direction) + ' \\n')\n",
    "# motion.append('personorientation ' + str(personorientation) + ' \\n')\n",
    "# motion.append('Scanning_direction_Waypoint_Distance_c3 ' + str(Scanning_direction_Waypoint_Distance) + ' \\n')\n",
    "# with open(os.path.join(Live_Debug_Path,'motion.txt'), 'a') as f:\n",
    "#     f.writelines('\\n'.join(motion))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################################################################motion##############################################################################\n",
    "\n",
    "\n",
    "\n",
    "gen_integral_blob_img_bw = gen_integral_blob_img > 1\n",
    "leader_blob_image_bw = leader_blob_image > 1 \n",
    "print(\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",rect)\n",
    "print(\"yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy\",new_leader_index)\n",
    "cv2.imwrite(os.path.join( leader_blob_image_folder,  str(1)+ 'leader_blob_image.png'), np.asarray(leader_blob_image_bw*255,dtype=np.uint8))\n",
    "cv2.imwrite(os.path.join( leader_rx_image_folder,  str(1)+ 'leader_rx_image.png'), leader_rx_image)\n",
    "cv2.imwrite(os.path.join( gen_integral_blob_img_folder,  str(1)+ 'gen_integral_blob_img.png'), np.asarray(gen_integral_blob_img_bw*255,dtype=np.uint8))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(newloc)\n",
    "print(prevwaypoints)\n",
    "print(new_leader_contour)\n",
    "print(new_leader_index, cameraid)\n",
    "print(metric_area)\n",
    "drawing_leader_index = cameraid\n",
    "\n",
    "\n",
    "\n",
    "v1 = {\n",
    "    0:cameraid\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "json.dump(v1,open(r'C:\\Users\\Rakesh\\Downloads\\cameraid.json',\"w\"))\n",
    "\n",
    "\n",
    "v12 = {\n",
    "    0:new_leader_index\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "json.dump(v12,open(r'C:\\Users\\Rakesh\\Downloads\\leader.json',\"w\"))\n",
    "\n",
    "\n",
    "v13 = {\n",
    "    0:metric_area\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "json.dump(v13,open(r'C:\\Users\\Rakesh\\Downloads\\metric_area.json',\"w\"))\n",
    "\n",
    "\n",
    "v14 = {\n",
    "    0:new_leader_contour\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "json.dump(v14,open(r'C:\\Users\\Rakesh\\Downloads\\new_leader_contour.json',\"w\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# altitude_list = [35,36,37,38,39,40,41,42,43,44]\n",
    "# site_poses = []\n",
    "# for i in range(NumberofDrones):\n",
    "#     EastCentered = (ref_loc[0][i] - 0.0) #Get MeanEast and Set MeanEast\n",
    "#     NorthCentered = (0.0 - ref_loc[1][i]) #Get MeanNorth and Set MeanNorth\n",
    "#     Alt = dem_height\n",
    "#     M = createviewmateuler(np.array([0.0, 0.0, 0.0]),np.array( [ref_loc[0][i], ref_loc[1][i],  35 - altitude_list[i]] ))\n",
    "#     ViewMatrix = np.vstack((M, np.array([0.0,0.0,0.0,1.0],dtype=np.float32)))\n",
    "#     camerapose = np.asarray(ViewMatrix.transpose(),dtype=np.float32)\n",
    "#     site_poses.append(camerapose)\n",
    "    \n",
    "\n",
    "# single_images = []\n",
    "# for i in range(NumberofDrones):\n",
    "#     image_name = [os.path.basename(x) for x in sorted(glob.glob(os.path.join(Current_Path, drone_names[i], 'camera', '*.png')))]\n",
    "#     # print(Current_Path)\n",
    "#     # print(drone_names[i])\n",
    "#     # print('camera',image_name[0]) \n",
    "#     # print(Current_Waypoint_Images_Loc)\n",
    "#     # print(os.path.join(Current_Path, drone_names[i], 'camera',image_name[0]))\n",
    "#     shutil.copy2(os.path.join(Current_Path, drone_names[i], 'camera',image_name[1]), os.path.join(Current_Waypoint_Images_Loc,image_name[1]))\n",
    "#     img = cv2.imread(os.path.join(Current_Path, drone_names[i], 'camera',image_name[1]))\n",
    "#     print('Image Dimensions :', img.shape)\n",
    "#     single_images.append(img)\n",
    "\n",
    "# def divide_by_alpha(img):\n",
    "#     a = img[:,:,3]\n",
    "#     aaa = np.stack((a,a,a),axis=-1)\n",
    "#     rgb = img[:,:,:3]/aaa \n",
    "#     rgb[aaa==0] = np.nan\n",
    "#     return rgb\n",
    "\n",
    "\n",
    "# for i in range(NumberofDrones):\n",
    "#     aos.addView(single_images[i], site_poses[i], \"01\")\n",
    "# inversecamerapose = glm.inverse(site_poses[2])\n",
    "# #ivp = glm.inverse(glm.transpose(inversecamerapose))\n",
    "# Posvec = glm.vec3(inversecamerapose[3])\n",
    "# Upvec = glm.vec3(inversecamerapose[1])\n",
    "# FrontVec = glm.vec3(inversecamerapose[2])\n",
    "# cameraviewarr = np.array(glm.lookAt(Posvec, Posvec + FrontVec, Upvec))\n",
    "    \n",
    "    \n",
    "# aos.setDEMTransform([0,0,dem_height])\n",
    "# #aos.setPoseCorrectionall(self._aos.getViews(),[0,0,0], [0,0, self._compass_correction])\n",
    "# tmp_tmp_integral_img = aos.render(cameraviewarr, 50)\n",
    "# tmp_integral_img = divide_by_alpha(tmp_tmp_integral_img)\n",
    "# cv2.imwrite(os.path.join( Integral_Path,  str(step_count-1)+ '_thermal.png'),  np.asarray(tmp_integral_img,dtype=np.uint8))\n",
    "aos.clearViews();\n",
    "\n",
    "\n",
    "#############################For the Second Step ---- Generate the link from the new locations############################################################### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iter=1\n",
    "iter_list = []\n",
    "time_list = []\n",
    "metric_list = []\n",
    "k = 0\n",
    "#metric_list.append(metric_area)\n",
    "metric_list.append(748.5)\n",
    "iter_list.append(iter)\n",
    "\n",
    "print(metric_list)\n",
    "drone_speed = 10\n",
    "if max_distance == 0:\n",
    "    time_taken = 0\n",
    "else:    \n",
    "\n",
    "    time_taken = (max_distance/drone_speed)\n",
    "\n",
    "\n",
    "previous_time = time_taken\n",
    "time_list.append(time_taken)\n",
    "\n",
    "#plt.axis([-10, 200, -40, 1500])\n",
    "plt.axis([-0.5, 120, -40, 1500])\n",
    "print(time_list)\n",
    "print(metric_list)\n",
    "\n",
    "v15 = {\n",
    "    0:time_taken\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "json.dump(v15,open(r'C:\\Users\\Rakesh\\Downloads\\time_taken.json',\"w\"))\n",
    "#plt.xlabel(\"Iteration\", fontsize=14)\n",
    "plt.xlabel(\"Time (seconds)\", fontsize=14)\n",
    "\n",
    "plt.ylabel(\"Metric\", fontsize=14)\n",
    "\n",
    "\n",
    "plt.plot(time_list, metric_list,'xb-', markersize = 6)\n",
    "\n",
    "\n",
    "\n",
    "#plt.show()\n",
    "save_results_to = r'C:/Users/Rakesh/Downloads/plots/'\n",
    "\n",
    "plt.savefig(save_results_to +  'image' + str(k) + '.png')\n",
    "print(metric_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "iter = 1\n",
    "\n",
    "\n",
    "stageimg = cv2.imread( r'C:\\Users\\Rakesh\\Downloads\\stages\\Waypoint' + str(iter) + '.png')\n",
    "\n",
    "img_folder = os.path.join( r'C:\\Users\\Rakesh\\Downloads\\images\\Waypoint' + str(iter))\n",
    "print(img_folder)\n",
    "import re\n",
    "\n",
    "numbers = re.compile(r'(\\d+)')\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts\n",
    "\n",
    "imagelist = []\n",
    "\n",
    "import glob\n",
    "\n",
    "for img in sorted(glob.glob(r'C:\\Users\\Rakesh\\Downloads\\images\\Waypoint' + str(iter) + '/*.png'),key=numericalSort):\n",
    "    n= cv2.imread(img)\n",
    "    imagelist.append(n)\n",
    "    \n",
    "\n",
    "#print(imagelist[0])\n",
    "\n",
    "integral = []\n",
    "integral_img = os.path.join(r'C:\\Users\\Rakesh\\Downloads\\integrals')\n",
    "for imges in sorted(glob.glob(r'C:\\Users\\Rakesh\\Downloads\\integrals' + '/*.png'),key=numericalSort):\n",
    "    r= cv2.imread(imges)\n",
    "    integral.append(r)\n",
    "    print('Image Dimensions :', r.shape)\n",
    "    \n",
    "# cv2.imwrite(os.path.join( leader_blob_image_folder,  str(1)+ 'leader_blob_image.png'), leader_blob_image)\n",
    "# cv2.imwrite(os.path.join( leader_rx_image_folder,  str(1)+ 'leader_rx_image.png'), leader_rx_image)\n",
    "# cv2.imwrite(os.path.join( gen_integral_blob_img_folder,  str(1)+ 'gen_integral_blob_img.png'), gen_integral_blob_img)        \n",
    "       \n",
    "    \n",
    "    \n",
    "#print(integral)    \n",
    "    \n",
    "from cmath import tan\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "thermal_dimension = round((2*(altitude_list[drawing_leader_index])*0.4663*9.33))     # Fov is 50 so theta by 2 is 25  \n",
    "\n",
    "print(thermal_dimension)\n",
    "\n",
    "mask = np.ones((thermal_dimension,thermal_dimension,3), np.uint8)   #(should be changed based on the leader)\n",
    "h, w , k = mask.shape\n",
    "print(drawing_current_location[0][drawing_leader_index])\n",
    "xoff = round((467 + 33 + (9.33 * drawing_current_location[0][drawing_leader_index]) - (thermal_dimension /2)))  # leader x position instead of 18\n",
    "yoff = round((467 + 31 + (9.33 * drawing_current_location[1][drawing_leader_index]) - (thermal_dimension /2)))   # leader y position instead of zero\n",
    "result = stageimg.copy()\n",
    "result[yoff:yoff+h, xoff:xoff+w] = mask    \n",
    "\n",
    "final = result.copy()\n",
    "dim = (thermal_dimension,thermal_dimension)  #(should be changed based on the leader)\n",
    "thermalresizeimg = cv2.resize(integral[3], dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "h1, w1, k1 = thermalresizeimg.shape\n",
    "print('resiyedimage',h1,w1,k1)\n",
    "final[yoff:yoff+h1, xoff:xoff+w1] = thermalresizeimg\n",
    "for i in range (NumberofDrones):\n",
    "    x_currentposition = round(467 + 33 + ((275/(275-(altitude_list[i])))*9.33*drawing_current_location[0][i]))\n",
    "    y_currentposition = round(467 + 31 + ((275/(275-(altitude_list[i])))*9.33*drawing_current_location[1][i]))\n",
    "    x_previousposition = round(467 + 33 + ((275/(275-(altitude_list[i])))*9.33*drawing_previous_location[0][i]))\n",
    "    y_previousposition = round(467 + 31 + ((275/(275-(altitude_list[i])))*9.33*drawing_previous_location[1][i]))\n",
    "    print('x_currentposition',x_currentposition)\n",
    "    print('y_currentposition',y_currentposition)\n",
    "    print('x_previousposition',x_previousposition)\n",
    "    print('y_previousposition',y_previousposition)\n",
    "    \n",
    "\n",
    "\n",
    "    cv2.circle(final, (x_currentposition, y_currentposition), 6, (255, 191, 0), -1)    # dimensions to be changed\n",
    "    \n",
    "     # dimensions to be changed\n",
    "\n",
    "    leaderx_currentposition = round(467 + 33 + ((275/(275-(altitude_list[Leader_index])))*9.33*drawing_current_location[0][Leader_index]))\n",
    "    leadery_currentposition = round(467 + 31 + ((275/(275-(altitude_list[Leader_index])))*9.33*drawing_current_location[1][Leader_index]))    \n",
    "    cv2.circle(final, (leaderx_currentposition, leadery_currentposition), 6, (0, 255, 255), -1)   \n",
    "    \n",
    "    if (math.sqrt((x_previousposition-x_currentposition)**2 + (y_previousposition-y_currentposition)**2)) == 0 :\n",
    "            \n",
    "        division  = 0.1\n",
    "    else:\n",
    "        division  = (math.sqrt((x_previousposition-x_currentposition)**2 + (y_previousposition-y_currentposition)**2))\n",
    "    cv2.arrowedLine(final, (x_previousposition, y_previousposition), (x_currentposition, y_currentposition), (255,255,255), 3, tipLength= 10/division)  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "integral_metric = []\n",
    "integral_metric_img = os.path.join(r'C:\\Users\\Rakesh\\Downloads\\plots')\n",
    "for imges1 in sorted(glob.glob(r'C:\\Users\\Rakesh\\Downloads\\plots' + '/*.png'),key=numericalSort):\n",
    "    r1= cv2.imread(imges1)\n",
    "    integral_metric.append(r1)\n",
    "    print('Image Dimensions :', r1.shape) \n",
    "    \n",
    "    \n",
    "    \n",
    "leader_blob_image_list = []\n",
    "\n",
    "for imges in sorted(glob.glob(r'C:\\Users\\Rakesh\\Downloads\\leader_blob_image' + '/*.png'),key=numericalSort):\n",
    "    r2= cv2.imread(imges)\n",
    "    leader_blob_image_list.append(r2)\n",
    "    \n",
    "leader_rx_image_list = []\n",
    "\n",
    "for imges in sorted(glob.glob(r'C:\\Users\\Rakesh\\Downloads\\leader_rx_image' + '/*.png'),key=numericalSort):\n",
    "    r3= cv2.imread(imges)\n",
    "    leader_rx_image_list.append(r3)    \n",
    "    \n",
    "gen_integral_blob_img_list = []\n",
    "\n",
    "for imges in sorted(glob.glob(r'C:\\Users\\Rakesh\\Downloads\\gen_integral_blob_img' + '/*.png'),key=numericalSort):\n",
    "    r4= cv2.imread(imges)\n",
    "    gen_integral_blob_img_list.append(r4)           \n",
    "\n",
    "\n",
    "#print(integral[iter])\n",
    "dim = (1536,1542)\n",
    "dim1 =(256,256)\n",
    "dim2 =(512,512)\n",
    "white = [255,255,0]\n",
    "rgbimg1= cv2.copyMakeBorder(imagelist[10],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "rgbimg6= cv2.copyMakeBorder(imagelist[15],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "stimg= cv2.copyMakeBorder(final,1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "therimg1= cv2.copyMakeBorder(imagelist[0],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "therimg2= cv2.copyMakeBorder(imagelist[1],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "therimg3= cv2.copyMakeBorder(imagelist[2],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "therimg4= cv2.copyMakeBorder(imagelist[3],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "therimg5= cv2.copyMakeBorder(imagelist[4],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "therimg6= cv2.copyMakeBorder(imagelist[5],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "therimg7= cv2.copyMakeBorder(imagelist[6],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "therimg8= cv2.copyMakeBorder(imagelist[7],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "therimg9= cv2.copyMakeBorder(imagelist[8],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "therimg10= cv2.copyMakeBorder(imagelist[9],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "rgbimg2= cv2.copyMakeBorder(imagelist[11],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "rgbimg3= cv2.copyMakeBorder(imagelist[12],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "rgbimg4= cv2.copyMakeBorder(imagelist[13],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "rgbimg5= cv2.copyMakeBorder(imagelist[14],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "rgbimg7= cv2.copyMakeBorder(imagelist[16],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "rgbimg8= cv2.copyMakeBorder(imagelist[17],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "rgbimg9= cv2.copyMakeBorder(imagelist[18],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "rgbimg10= cv2.copyMakeBorder(imagelist[19],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "irgb1= cv2.copyMakeBorder(integral[2],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "it1= cv2.copyMakeBorder(integral[3],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "met1= cv2.copyMakeBorder(integral_metric[0],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "a1 = cv2.copyMakeBorder(leader_blob_image_list[0],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "a2 = cv2.copyMakeBorder(leader_rx_image_list[0],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "a3 = cv2.copyMakeBorder(gen_integral_blob_img_list[0],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "\n",
    "# img5= cv2.copyMakeBorder(imagelist[4],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "# img6= cv2.copyMakeBorder(imagelist[5],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "# img7= cv2.copyMakeBorder(imagelist[6],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "# img8= cv2.copyMakeBorder(imagelist[7],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "# img9= cv2.copyMakeBorder(imagelist[8],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "# img10= cv2.copyMakeBorder(imagelist[9],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "\n",
    "\n",
    "# stage_img = cv2.resize(stageimg, dim, interpolation = cv2.INTER_AREA)\n",
    "rgbimg1 = cv2.resize(rgbimg1, dim1, interpolation = cv2.INTER_AREA)\n",
    "rgbimg6 = cv2.resize(rgbimg6, dim1, interpolation = cv2.INTER_AREA)\n",
    "stimg = cv2.resize(stimg, dim, interpolation = cv2.INTER_AREA)\n",
    "therimg1 = cv2.resize(therimg1, dim1, interpolation = cv2.INTER_AREA)\n",
    "therimg2 = cv2.resize(therimg2, dim1, interpolation = cv2.INTER_AREA)\n",
    "therimg3 = cv2.resize(therimg3, dim1, interpolation = cv2.INTER_AREA)\n",
    "therimg4 = cv2.resize(therimg4, dim1, interpolation = cv2.INTER_AREA)\n",
    "therimg5 = cv2.resize(therimg5, dim1, interpolation = cv2.INTER_AREA)\n",
    "therimg6 = cv2.resize(therimg6, dim1, interpolation = cv2.INTER_AREA)\n",
    "therimg7 = cv2.resize(therimg7, dim1, interpolation = cv2.INTER_AREA)\n",
    "therimg8 = cv2.resize(therimg8, dim1, interpolation = cv2.INTER_AREA)\n",
    "therimg9 = cv2.resize(therimg9, dim1, interpolation = cv2.INTER_AREA)\n",
    "therimg10 = cv2.resize(therimg10, dim1, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "rgbimg2 = cv2.resize(rgbimg2, dim1, interpolation = cv2.INTER_AREA)\n",
    "rgbimg3 = cv2.resize(rgbimg3, dim1, interpolation = cv2.INTER_AREA)\n",
    "rgbimg4 = cv2.resize(rgbimg4, dim1, interpolation = cv2.INTER_AREA)\n",
    "rgbimg5 = cv2.resize(rgbimg5, dim1, interpolation = cv2.INTER_AREA)\n",
    "rgbimg7 = cv2.resize(rgbimg7, dim1, interpolation = cv2.INTER_AREA)\n",
    "rgbimg8 = cv2.resize(rgbimg8, dim1, interpolation = cv2.INTER_AREA)\n",
    "rgbimg9 = cv2.resize(rgbimg9, dim1, interpolation = cv2.INTER_AREA)\n",
    "rgbimg10 = cv2.resize(rgbimg10, dim1, interpolation = cv2.INTER_AREA)\n",
    "irgb1 = cv2.resize(irgb1, dim2, interpolation = cv2.INTER_AREA)\n",
    "it1 = cv2.resize(it1, dim2, interpolation = cv2.INTER_AREA)\n",
    "met1 = cv2.resize(met1, dim2, interpolation = cv2.INTER_AREA)\n",
    "a1 = cv2.resize(a1, dim1, interpolation = cv2.INTER_AREA)\n",
    "a2 = cv2.resize(a2, dim1, interpolation = cv2.INTER_AREA)\n",
    "a3 = cv2.resize(a3, dim1, interpolation = cv2.INTER_AREA)\n",
    "# img2 = cv2.resize(img2, dim1, interpolation = cv2.INTER_AREA)\n",
    "# img3 = cv2.resize(img3, dim1, interpolation = cv2.INTER_AREA)\n",
    "# img4 = cv2.resize(img4, dim1, interpolation = cv2.INTER_AREA)\n",
    "# img5 = cv2.resize(img5, dim1, interpolation = cv2.INTER_AREA)\n",
    "# img6 = cv2.resize(img6, dim1, interpolation = cv2.INTER_AREA)\n",
    "# img7 = cv2.resize(img7, dim1, interpolation = cv2.INTER_AREA)\n",
    "# img8 = cv2.resize(img8, dim1, interpolation = cv2.INTER_AREA)\n",
    "# img9 = cv2.resize(img9, dim1, interpolation = cv2.INTER_AREA)\n",
    "# img10 = cv2.resize(img10, dim1, interpolation = cv2.INTER_AREA)\n",
    "# img11 = cv2.resize(integral_metric[k], dim1, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "h1, w1 = rgbimg1.shape[:2]\n",
    "h6, w6 = rgbimg6.shape[:2]\n",
    "sh1, sw1 = stimg.shape[:2]\n",
    "h11, w11 = therimg1.shape[:2]\n",
    "h12, w12 = therimg2.shape[:2]\n",
    "h13, w13 = therimg3.shape[:2]\n",
    "h14, w14 = therimg4.shape[:2]\n",
    "h15, w15 = therimg5.shape[:2]\n",
    "h16, w16 = therimg6.shape[:2]\n",
    "h17, w17 = therimg7.shape[:2]\n",
    "h18, w18 = therimg8.shape[:2]\n",
    "h19, w19 = therimg9.shape[:2]\n",
    "h20, w20 = therimg10.shape[:2]\n",
    "h2, w2 = rgbimg2.shape[:2]\n",
    "h3, w3 = rgbimg3.shape[:2]\n",
    "h4, w4 = rgbimg4.shape[:2]\n",
    "h5, w5 = rgbimg5.shape[:2]\n",
    "h7, w7 = rgbimg7.shape[:2]\n",
    "h8, w8 = rgbimg8.shape[:2]\n",
    "h9, w9 = rgbimg9.shape[:2]\n",
    "h10, w10 = rgbimg10.shape[:2]\n",
    "ih1, iw1 = irgb1.shape[:2]\n",
    "ith1, itw1 = it1.shape[:2]\n",
    "meth1, metw1 = met1.shape[:2]\n",
    "a1h, a1w = a1.shape[:2]\n",
    "a2h, a2w = a2.shape[:2]\n",
    "a3h, a3w = a3.shape[:2]\n",
    "\n",
    "# h1, w1 = stage_img.shape[:2]\n",
    "# h2, w2 = integral[iter].shape[:2]\n",
    "# h3, w3 = img1.shape[:2]\n",
    "# h4, w4 = img2.shape[:2]\n",
    "# h5, w5 = img3.shape[:2]\n",
    "# h6, w6 = img4.shape[:2]\n",
    "# h7, w7 = img5.shape[:2]\n",
    "# h8, w8 = img6.shape[:2]\n",
    "# h9, w9 = img7.shape[:2]\n",
    "# h10, w10 = img8.shape[:2]\n",
    "# h11, w11 = img9.shape[:2]\n",
    "# h12, w12 = img10.shape[:2]\n",
    "# h13,w13 = img11.shape[:2]\n",
    "# print(h12, w12)\n",
    "\n",
    "img_3 = np.zeros((1542,3084,3), dtype=np.uint8)\n",
    "# print(img_3[:h1, :w1,:3].shape)\n",
    "# print(img_3[:h2, w1:w1+w2,:3].shape)\n",
    "img_3[:h1, :w1,:3] = rgbimg1\n",
    "img_3[:h1, w1:w1+w6,:3] = rgbimg6\n",
    "img_3[:h6+h1+sh1, w1+w6:w1+w6+sw1 ,:3] = stimg\n",
    "img_3[:h1, w1+w6+sw1:w1+w6+sw1+w11 ,:3] = therimg1\n",
    "img_3[h1:h1+h2, w1+w6+sw1:w1+w6+sw1+w11 ,:3] = therimg2\n",
    "img_3[h1+h2:h1+h2+h3, w1+w6+sw1:w1+w6+sw1+w11 ,:3] = therimg3\n",
    "img_3[h1+h2+h3:h1+h2+h3+h4, w1+w6+sw1:w1+w6+sw1+w11 ,:3] = therimg4\n",
    "img_3[h1+h2+h3+h4:h1+h2+h3+h4+h5, w1+w6+sw1:w1+w6+sw1+w11 ,:3] = therimg5\n",
    "img_3[h1+h2+h3+h4+h5:h1+h2+h3+h4+h5+a1h, w1+w6+sw1:w1+w6+sw1+w11 ,:3] = a1\n",
    "\n",
    "img_3[:h1, w1+w6+sw1+w11:w1+w6+sw1+w11+w16 ,:3] = therimg6\n",
    "img_3[h1:h1+h2, w1+w6+sw1+w11:w1+w6+sw1+w11+w16 ,:3] = therimg7\n",
    "img_3[h1+h2:h1+h2+h3, w1+w6+sw1+w11:w1+w6+sw1+w11+w16 ,:3] = therimg8\n",
    "img_3[h1+h2+h3:h1+h2+h3+h4, w1+w6+sw1+w11:w1+w6+sw1+w11+w16 ,:3] = therimg9\n",
    "img_3[h1+h2+h3+h4:h1+h2+h3+h4+h5, w1+w6+sw1+w11:w1+w6+sw1+w11+w16 ,:3] = therimg10\n",
    "img_3[h1+h2+h3+h4+h5:h1+h2+h3+h4+h5+a3h, w1+w6+sw1+w11:w1+w6+sw1+w11+w16 ,:3] = a3\n",
    "img_3[h1:h1+h2, :w2,:3] = rgbimg2\n",
    "img_3[h1+h2:h1+h2+h3, :w3,:3] = rgbimg3\n",
    "img_3[h1+h2+h3:h1+h2+h3+h4, :w2,:3] = rgbimg4\n",
    "img_3[h1+h2+h3+h4:h1+h2+h3+h4+h5, :w2,:3] = rgbimg5\n",
    "#img_3[h1+h2+h3+h4+h5:h1+h2+h3+h4+h5+a2h, :w2,:3] = a2\n",
    "img_3[h1:h1+h2, w1:w1+w7,:3] = rgbimg7\n",
    "img_3[h1+h2:h1+h2+h3, w1:w1+w8,:3] = rgbimg8\n",
    "img_3[h1+h2+h3:h1+h2+h3+h4, w1:w1+w9,:3] = rgbimg9\n",
    "img_3[h1+h2+h3+h4:h1+h2+h3+h4+h5, w1:w1+w10,:3] = rgbimg10\n",
    "img_3[:h1+h6, w1+w6+sw1+w11+w16:w1+w6+sw1+w11+w16+iw1,:3] = irgb1\n",
    "img_3[h1+h2:h1+h6+ith1, w1+w6+sw1+w11+w16:w1+w6+sw1+w11+w16+iw1,:3] = it1\n",
    "img_3[h1+h2+ith1:h1+h6+ith1+meth1, w1+w6+sw1+w11+w16:w1+w6+sw1+w11+w16+iw1,:3] = met1\n",
    "# img_3[:h2, w1:w1+w2,:3] = integral[iter]\n",
    "\n",
    "# img_3[h1:h1+h3, :w3,:3] = img1\n",
    "# img_3[h1:h1+h3, w3:w3+w4,:3] = img2\n",
    "# img_3[h1:h1+h3, w2:w3+w4+w5,:3] = img3\n",
    "# img_3[h1:h1+h3, w1:w3+w4+w5+w6,:3] = img4\n",
    "# img_3[h1:h1+h3, w1+w3:w3+w4+w5+w6+w7,:3] = img5\n",
    "# img_3[h1+h3:h1+h3+h4, :w8,:3] = img6\n",
    "# img_3[h1+h3:h1+h3+h4, w8:w8+w9,:3] = img7\n",
    "# img_3[h1+h3:h1+h3+h4, w8+w7:w8+w9+w10,:3] = img8\n",
    "# img_3[h1+h3:h1+h3+h4, w8+w7+w9:w8+w9+w10+w11,:3] = img9\n",
    "# img_3[h1+h3:h1+h3+h4, w8+w7+w9+w10:w8+w9+w10+w11+w12,:3] = img10\n",
    "# img_3[h2:h2+h13, w1:w1+w13,:3] = img11\n",
    "\n",
    "\n",
    "# #cv2.putText(img_3,\"Metric:\" + str(new_leader_contour), (830,615), cv2.FONT_HERSHEY_SIMPLEX, 1, 255)\n",
    "# #cv2.putText(img_3,\"Leader_index:\" + str(new_leader_index), (820,660), cv2.FONT_HERSHEY_SIMPLEX, 1, 255)\n",
    "\n",
    "# # print(img_3.shape)\n",
    "\n",
    "# th = 0.1 # defines the value below which a pixel is considered \"black\"\n",
    "# black_pixels = np.where(\n",
    "#     (img_3[:, :, 0] < th) & \n",
    "#     (img_3[:, :, 1] < th) & \n",
    "#     (img_3[:, :, 2] < th)\n",
    "# )\n",
    "# img_3[black_pixels] = [255, 255, 255]\n",
    "\n",
    "cv2.imwrite(os.path.join(r'C:\\Users\\Rakesh\\Downloads\\Final_result', ('stage_' + str(iter) + '.png')),img_3)\n",
    "\n",
    "# iter = iter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ybefore = []\n",
    "yafter = []\n",
    "xbefore = []\n",
    "xafter = []\n",
    "ycamerabefore = []\n",
    "ycameraafter = []\n",
    "xcamerabefore = []\n",
    "xcameraafter = []\n",
    "cameralist = []\n",
    "leaderlist = []\n",
    "currentmeanx = []\n",
    "currentmeany =[]\n",
    "s = 1\n",
    "o = 3\n",
    "p = 4\n",
    "start_time_person = 0\n",
    "iter = 1\n",
    "step_count = 1\n",
    "old_theta = 270\n",
    "for i in range(300):\n",
    "    # if i==9 :\n",
    "    #     emptyblobthreshold = 1000 #145  #170\n",
    "    #     test_drone_pso.set_emptyblob_threshold(emptyblobthreshold)\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    iter = iter + 1\n",
    "    #personorientation = 0       \n",
    "    \n",
    "    aos.clearViews();\n",
    "    #person=[0,10] \n",
    "   \n",
    "    step_count = step_count + 1\n",
    "    ref_loc = newloc\n",
    "    #print(prevwaypoints)\n",
    "    print(ref_loc)\n",
    "    altitude_list = [43,41,39,37,35,36,38,40,42,44] #[40,40,40,40,40,40,40,40,40,40] \n",
    "    drawing_current_location = ref_loc\n",
    "    drawing_previous_location = prevwaypoints\n",
    "    c = []\n",
    "    for i in range (0, NumberofDrones):\n",
    "        distance = math.sqrt( ((ref_loc[0][i]-prevwaypoints[0][i])**2)+((ref_loc[1][i]-prevwaypoints[1][i])**2) )\n",
    "        c.append(distance)\n",
    "        \n",
    "    print(c)\n",
    "    new_max_distance =  max(c)    \n",
    "    print(max(c))\n",
    "    \n",
    "    drone_totaltime = (new_max_distance/drone_speed)\n",
    "    total_time = start_time_person + drone_totaltime\n",
    "    \n",
    "    \n",
    "    \n",
    "    # if iter <= 10:\n",
    "    #     personorientation = 360\n",
    "    #     px = total_time  * (math.sin(np.deg2rad(personorientation)))\n",
    "    #     py = total_time  * (math.cos(np.deg2rad(personorientation))) #0.9848, 0.1736\n",
    "   \n",
    "    \n",
    "    \n",
    "    #  ####################################################################3\n",
    "    \n",
    "    #     person_speed = 4\n",
    "    #     personinx = person_speed * px\n",
    "    #     personiny = person_speed * py\n",
    "    #     person = [((person[0]) + personinx), (person[1] + personiny)]\n",
    "        \n",
    "    # if iter>10 and iter<=50 :  \n",
    "    #     person = person\n",
    "    # if iter> 50:\n",
    "    #     personorientation = 180\n",
    "    #     px = total_time  * (math.sin(np.deg2rad(personorientation)))\n",
    "    #     py = total_time  * (math.cos(np.deg2rad(personorientation))) #0.9848, 0.1736\n",
    "   \n",
    "    \n",
    "    \n",
    "    #  ####################################################################3\n",
    "    \n",
    "    #     person_speed = 4\n",
    "    #     personinx = person_speed * px\n",
    "    #     personiny = person_speed * py\n",
    "    #     person = [((person[0]) + personinx), (person[1] + personiny)]\n",
    "               \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #person = [0,10]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ########################################################################3\n",
    "   \n",
    "\n",
    "    theta = 2*3.14*20\n",
    "    theta = theta/360\n",
    "    \n",
    "    person_speed = 4\n",
    "    personinx = person_speed * total_time\n",
    "    personiny = person_speed * total_time\n",
    "    \n",
    "    new_theta = personinx / theta\n",
    "    \n",
    "    old_theta  = old_theta + new_theta\n",
    "    \n",
    "   \n",
    "    \n",
    "    x_dir = 20*np.cos(np.deg2rad(old_theta))\n",
    "    y_dir = -10 + (-20*np.sin(np.deg2rad(old_theta)))\n",
    "    \n",
    "    new_person = [x_dir,y_dir]\n",
    "    \n",
    "    dx = new_person[0] - person[0]\n",
    "\n",
    "    # Difference in y coordinates\n",
    "    dy = -new_person[1] +person[1]\n",
    "\n",
    "    # Angle between p1 and p2 in radians\n",
    "    personorientation = math.atan2(dy, dx)\n",
    "    personorientation = ((np.degrees(personorientation))%360)+90\n",
    "    \n",
    "    person = new_person\n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    a = {\n",
    "        o:ref_loc.tolist(),\n",
    "        p:prevwaypoints.tolist()\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    with open(r'C:\\Users\\Rakesh\\Downloads\\data.json' , 'r+') as file:\n",
    "            data = json.load(file)\n",
    "            data.update(a)\n",
    "            file.seek(0)\n",
    "            json.dump(data, file)   \n",
    "            \n",
    "            \n",
    "    jd1 = {\n",
    "        iter:person,\n",
    "    \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    with open(r'C:\\Users\\Rakesh\\Downloads\\personpositions.json','r+') as file1:\n",
    "            data1 = json.load(file1)\n",
    "            data1.update(jd1)\n",
    "            file1.seek(0)\n",
    "            json.dump(data1, file1) \n",
    "\n",
    "    # i = 3\n",
    "    # a = {\n",
    "    #     i:prevwaypoints.tolist(),\n",
    "    #     4:prevwaypoints.tolist()\n",
    "    # }\n",
    "\n",
    "\n",
    "    po1 = {\n",
    "        iter:personorientation,\n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    with open(r'C:\\Users\\Rakesh\\Downloads\\personorientation.json','r+') as file2: \n",
    "    \n",
    "            data2 = json.load(file2)\n",
    "            data2.update(po1)\n",
    "            file2.seek(0)\n",
    "            json.dump(data2, file2)      \n",
    "        \n",
    "    \n",
    "    \n",
    "    link1=\"http://127.0.0.1:5504/?drone1x=\"+str(ref_loc[0][0])+\"&drone1y=\"+str(ref_loc[1][0])+\"&drone2x=\"+str(ref_loc[0][1])+\"&drone2y=\"+str(ref_loc[1][1])+\"&drone3x=\"+str(ref_loc[0][2])+\"&drone3y=\"+str(ref_loc[1][2])+\"&drone4x=\"+str(ref_loc[0][3])+\"&drone4y=\"+str(ref_loc[1][3])+\"&drone5x=\"+str(ref_loc[0][4])+\"&drone5y=\"+str(ref_loc[1][4])+\"&drone6x=\"+str(ref_loc[0][5])+\"&drone6y=\"+str(ref_loc[1][5])+\"&drone7x=\"+str(ref_loc[0][6])+\"&drone7y=\"+str(ref_loc[1][6])+\"&drone8x=\"+str(ref_loc[0][7])+\"&drone8y=\"+str(ref_loc[1][7])+\"&drone9x=\"+str(ref_loc[0][8])+\"&drone9y=\"+str(ref_loc[1][8])+\"&drone10x=\"+str(ref_loc[0][9])+\"&drone10y=\"+str(ref_loc[1][9])+\"&personx=\"+str(person[0])+\"&persony=\"+str(person[1])+\"&personorient=\"+str(personorientation)+\"&filename=\"+('Waypoint'+str(step_count))+\"&xlist=\"+(treex)+\"&ylist=\"+(treey)+\"&prevdrone1x=\"+str(prevwaypoints[0][0])+\"&prevdrone1y=\"+str(prevwaypoints[1][0])+\"&prevdrone2x=\"+str(prevwaypoints[0][1])+\"&prevdrone2y=\"+str(prevwaypoints[1][1])+\"&prevdrone3x=\"+str(prevwaypoints[0][2])+\"&prevdrone3y=\"+str(prevwaypoints[1][2])+\"&prevdrone4x=\"+str(prevwaypoints[0][3])+\"&prevdrone4y=\"+str(prevwaypoints[1][3])+\"&prevdrone5x=\"+str(prevwaypoints[0][4])+\"&prevdrone5y=\"+str(prevwaypoints[1][4])+\"&prevdrone6x=\"+str(prevwaypoints[0][5])+\"&prevdrone6y=\"+str(prevwaypoints[1][5])+\"&prevdrone7x=\"+str(prevwaypoints[0][6])+\"&prevdrone7y=\"+str(prevwaypoints[1][6])+\"&prevdrone8x=\"+str(prevwaypoints[0][7])+\"&prevdrone8y=\"+str(prevwaypoints[1][7])+\"&prevdrone9x=\"+str(prevwaypoints[0][8])+\"&prevdrone9y=\"+str(prevwaypoints[1][8])+\"&prevdrone10x=\"+str(prevwaypoints[0][9])+\"&prevdrone10y=\"+str(prevwaypoints[1][9])+\"&altd1=\"+str(altitude_list[0])+\"&altd2=\"+str(altitude_list[1])+\"&altd3=\"+str(altitude_list[2])+\"&altd4=\"+str(altitude_list[3])+\"&altd5=\"+str(altitude_list[4])+\"&altd6=\"+str(altitude_list[5])+\"&altd7=\"+str(altitude_list[6])+\"&altd8=\"+str(altitude_list[7])+\"&altd9=\"+str(altitude_list[8])+\"&altd10=\"+str(altitude_list[9])+\"&leader=\"+str(new_leader_index)\n",
    "    #print(link1)\n",
    "    Saved_Img_Location = \"Waypoint\"+ str(step_count) + '.'+'zip'\n",
    "   # print(Saved_Img_Location)\n",
    "    #print(os.path.splitext(Saved_Img_Location)[0])\n",
    "    Current_Waypoint_Images_Loc = os.path.join(Download_Location,'images', os.path.splitext(Saved_Img_Location)[0])\n",
    "    os.mkdir(Current_Waypoint_Images_Loc)\n",
    "    Current_Path = os.path.join(Download_Location,Saved_Img_Location)\n",
    "    #print(Current_Path)\n",
    "    #############################Create Poses for Initial Positions###############################################################\n",
    "    #############################Create Poses for Initial Positions###############################################################\n",
    "    site_poses = []\n",
    "    for i in range(NumberofDrones):\n",
    "        EastCentered = (ref_loc[0][i] - 0.0) #Get MeanEast and Set MeanEast\n",
    "        NorthCentered = (0.0 - ref_loc[1][i]) #Get MeanNorth and Set MeanNorth\n",
    "        Alt = dem_height\n",
    "        M = createviewmateuler(np.array([0.0, 0.0, 0.0]),np.array( [ref_loc[0][i], ref_loc[1][i], 35 - altitude_list[i]] ))\n",
    "        ViewMatrix = np.vstack((M, np.array([0.0,0.0,0.0,1.0],dtype=np.float32)))\n",
    "        camerapose = np.asarray(ViewMatrix.transpose(),dtype=np.float32)\n",
    "        site_poses.append(camerapose)\n",
    "    #############################Send the Link to Simulator to generate the images###############################################################\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    driver.get(link1)\n",
    "    driver.maximize_window()\n",
    "    time.sleep(10)\n",
    "    while not os.path.exists(Current_Path):\n",
    "        time.sleep(1)\n",
    "\n",
    "    if os.path.isfile(Current_Path):\n",
    "        #print(\"read file\")\n",
    "        with ZipFile(Current_Path,'r') as zipObj:\n",
    "            zipObj.extractall(path=Current_Path.split(\".\")[0])\n",
    "    else:\n",
    "        print('error')\n",
    "    Current_Path = os.path.join(Download_Location,os.path.splitext(Saved_Img_Location)[0])\n",
    "    #############################Read the generated images###############################################################\n",
    "    #imagelist = [os.path.basename(x) for x in sorted(glob.glob(os.path.join(top_path, '*.png')))]\n",
    "    single_images = []\n",
    "    \n",
    "    for i in range(NumberofDrones):\n",
    "        image_name = [os.path.basename(x) for x in sorted(glob.glob(os.path.join(Current_Path, drone_names[i], 'camera', '*.png')))]\n",
    "        g_1 = cv2.imread(os.path.join(Current_Path, drone_names[i], 'camera',image_name[0]))\n",
    "        g_2 = cv2.imread(os.path.join(Current_Path, drone_names[i], 'camera',image_name[1]),cv2.IMREAD_GRAYSCALE)\n",
    "        result = np.dstack((g_1, g_2))\n",
    "        #print('result: ', result.shape)\n",
    "        #os.remove(os.path.join(Current_Path, drone_names[i], 'camera',image_name[0])) \n",
    "        #os.remove(os.path.join(Current_Path, drone_names[i], 'camera',image_name[1])) \n",
    "        cv2.imwrite(os.path.join(Current_Path, drone_names[i], 'camera','test'+str(i)+'.png'),result)\n",
    "    \n",
    "    for i in range(NumberofDrones):\n",
    "        image_name = [os.path.basename(x) for x in sorted(glob.glob(os.path.join(Current_Path, drone_names[i], 'camera', '*.png')))]\n",
    "        # print(Current_Path)\n",
    "        # print(drone_names[i])\n",
    "        # print('camera',image_name[0]) \n",
    "        # print(Current_Waypoint_Images_Loc)\n",
    "        # print(os.path.join(Current_Path, drone_names[i], 'camera',image_name[0]))\n",
    "        shutil.copy2(os.path.join(Current_Path, drone_names[i], 'camera',image_name[2]), os.path.join(Current_Waypoint_Images_Loc,image_name[2]))\n",
    "        shutil.copy2(os.path.join(Current_Path, drone_names[i], 'camera',image_name[1]), os.path.join(Current_Waypoint_Images_Loc,image_name[1]))\n",
    "        img = cv2.imread(os.path.join(Current_Path, drone_names[i], 'camera',image_name[2]),cv2.IMREAD_UNCHANGED)\n",
    "        single_images.append(img)\n",
    "    #print(os.path.splitext(Saved_Img_Location)[0])\n",
    "    shutil.copy2(os.path.join(Current_Path, 'stage', 'cropped_image.png'), os.path.join(Stages_Path,os.path.splitext(Saved_Img_Location)[0]+'.png'))\n",
    "    #############################For the First Step ---- Compute the Blob Threshold###############################################################\n",
    "    x_axis_mean = np.mean(np.asarray(ref_loc[0][:]))\n",
    "    y_axis_mean = np.mean(np.asarray(ref_loc[1][:]))\n",
    "    Alts = dem_height\n",
    "\n",
    "    #############################For the First Step ---- Get the Next Locations###############################################################            \n",
    "    center_EastCentered = (x_axis_mean - 0.0) #Get MeanEast and Set MeanEast\n",
    "    center_NorthCentered = (0.0 - y_axis_mean) #Get MeanNorth and Set MeanNorth\n",
    "    #center_M = createviewmateuler(np.array([(0.0), 0, 0]),np.array( [center_EastCentered, center_NorthCentered, -Alts] ))\n",
    "    center_M = createviewmateuler(np.array([0.0, 0.0, 0.0]),np.array( [x_axis_mean, y_axis_mean, 0.0] ))\n",
    "    center_ViewMatrix = np.vstack((center_M, np.array([0.0,0.0,0.0,1.0],dtype=np.float32)))\n",
    "    center_camerapose = np.asarray(center_ViewMatrix.transpose(),dtype=np.float32)\n",
    "\n",
    "    newgps, newloc, new_integral_image, new_leader_contour,new_leader_index,metric_area,cameraid,leader_blob_image, leader_rx_image,gen_integral_blob_img,rect,personorientation,blobposition = test_drone_pso.get_waypoints_with_pso_motion(single_images,site_poses,center_camerapose) ## Change Virtual Camera Pose to Center Position   #new_integral_img use this\n",
    "    #print(newloc)\n",
    "    \n",
    "    ################################################################################motion################################################################3\n",
    "    # if new_leader_contour > emptyblobthreshold:\n",
    "    #     previous_blob_personposition = blob_personposition \n",
    "    #     coverage = 2*altitude_list[new_leader_index]*np.tan(np.deg2rad(25))\n",
    "    #     resolution = 512\n",
    "    #     metretopixels = coverage/resolution\n",
    "    #     blob_posx = rect[0] + rect[2]/2\n",
    "    #     blob_posy = rect[1] + rect[3]/2\n",
    "    #     blob_posxinpixels = blob_posx * metretopixels\n",
    "    #     blob_posyinpixels = blob_posy * metretopixels\n",
    "    #     blobposition = [blob_posxinpixels,blob_posyinpixels]\n",
    "    #     integralposition_centre = [ref_loc[0][new_leader_index], ref_loc[1][new_leader_index]]\n",
    "    #     integral_startposition = [integralposition_centre[0] - coverage/2, integralposition_centre[1] - coverage/2]\n",
    "    #     blob_personposition = [blobposition[0] - abs(integral_startposition[0]), blobposition[1] - abs(integral_startposition[1])]\n",
    "\n",
    "    #     dronemeanx=(np.mean(ref_loc[0]))\n",
    "    #     dronemeany=(np.mean(ref_loc[1]))\n",
    "    #     dronemeanpos = [dronemeanx,dronemeany]\n",
    "    #     dy = (-blob_personposition[1]-(-dronemeany))\n",
    "    #     dx = (blob_personposition[0]-dronemeanx)\n",
    "\n",
    "    #     Scanning_direction = np.arctan2(dy,dx)\n",
    "    #     Scanning_direction = ((np.degrees(Scanning_direction))%360)+90\n",
    "    #     print(Scanning_direction)\n",
    "    #     if Scanning_direction == 0 or Scanning_direction>=360 :\n",
    "    #         Scanning_direction = 0                             #need to switch sign of yaxis positive is down and negative is up\n",
    "    #         print(Scanning_direction)\n",
    "\n",
    "\n",
    "        \n",
    "    #     dyp = (-blob_personposition[1]-(-previous_blob_personposition[1]))\n",
    "    #     dxp = (blob_personposition[0]-previous_blob_personposition[0])\n",
    "    #     personorientation = np.arctan2(dyp,dxp)\n",
    "    #     personorientation = ((np.degrees(personorientation))%360)+90\n",
    "    #     print(personorientation)\n",
    "    #     if personorientation == 0 or personorientation>=360 :\n",
    "    #         personorientation = 0                             #need to switch sign of yaxis positive is down and negative is up\n",
    "    #         print(personorientation)\n",
    "        \n",
    "    #     delta = 0.2\n",
    "    #     person_distance = math.sqrt( (blob_personposition[0] - previous_blob_personposition[0] )**2 + (blob_personposition[1] - previous_blob_personposition[1])**2 )\n",
    "    #     person_time = drone_totaltime\n",
    "    #     person_calculatedspeed = person_distance/person_time\n",
    "    #     person_simspeed = 3    \n",
    "    #     c3 = person_calculatedspeed *  person_time # to be updated\n",
    "    #     Scanning_direction_Waypoint_Distance = c3 + delta #c3   \n",
    "\n",
    "    #     print(\"simulated_personposition\",person)\n",
    "    #     print(\"previous_blob_personposition\",previous_blob_personposition)\n",
    "    #     print(\"coverage\",coverage)\n",
    "    #     print(\"new_leader_index\",new_leader_index)\n",
    "    #     print(\"blobposition\",blobposition)\n",
    "    #     print(\"integralposition_centre\",integralposition_centre)\n",
    "    #     print(\"integral_startposition\",integral_startposition)\n",
    "    #     print(\"currentblob_personposition\",blob_personposition)\n",
    "    #     print(\"dronemeanpos\",dronemeanpos)\n",
    "    #     print(\"Scanning_direction\",Scanning_direction)\n",
    "    #     print(\"personorientation\",personorientation)\n",
    "    #     print(\"timeforcurrentiteration\",person_time)\n",
    "    #     print(\"Distancetravelledbyperson\",person_distance)\n",
    "    #     print(\"c3\",Scanning_direction_Waypoint_Distance)\n",
    "        \n",
    "        \n",
    "    #     motion = []\n",
    "    #     motion.append('Waypoint ' + str(iter) + ' \\n')\n",
    "    #     motion.append('person ' + str(person) + ' \\n')\n",
    "    #     motion.append('previous_blob_personposition ' + str(previous_blob_personposition) + ' \\n')\n",
    "    #     motion.append('coverage ' + str(coverage) + ' \\n')\n",
    "    #     motion.append('new_leader_index ' + str(new_leader_index) + ' \\n')\n",
    "    #     motion.append('blobposition ' + str(blobposition) + ' \\n')\n",
    "    #     motion.append('integralposition_centre ' + str(integralposition_centre) + ' \\n')\n",
    "    #     motion.append('integral_startposition ' + str(integral_startposition) + ' \\n')\n",
    "    #     motion.append('currentblob_personposition ' + str(blob_personposition) + ' \\n')\n",
    "    #     motion.append('dronemeanpos ' + str(dronemeanpos) + ' \\n')\n",
    "    #     motion.append('Scanning_direction ' + str(Scanning_direction) + ' \\n')\n",
    "    #     motion.append('personorientation ' + str(personorientation) + ' \\n')\n",
    "    #     motion.append('timeforcurrentiteration ' + str(person_time) + ' \\n')\n",
    "    #     motion.append('Distancetravelledbyperson ' + str(person_distance) + ' \\n')\n",
    "    #     motion.append('Scanning_direction_Waypoint_Distance_c3 ' + str(Scanning_direction_Waypoint_Distance) + ' \\n')\n",
    "    # else:\n",
    "    #     motion.append('Waypoint ' + str(iter) + ' \\n')\n",
    "    #     motion.append('No convergence'  + ' \\n') \n",
    "    #     motion.append('person ' + str(person) + ' \\n')\n",
    "    #     motion.append('No convergence'  + ' \\n')  \n",
    "    #     motion.append('Scanning_direction ' + str(Scanning_direction) + ' \\n')\n",
    "    #     motion.append('personorientation ' + str(personorientation) + ' \\n')\n",
    "        \n",
    "    #     motion.append('Distancetravelledbyperson ' + str(person_distance) + ' \\n')\n",
    "    #     motion.append('Scanning_direction_Waypoint_Distance_c3 ' + str(Scanning_direction_Waypoint_Distance) + ' \\n')\n",
    "        \n",
    "    # with open(os.path.join(Live_Debug_Path,'motion.txt'), 'a') as f:\n",
    "    #     f.writelines('\\n'.join(motion))\n",
    "\n",
    "\n",
    "    ####################################################################motion##############################################################################\n",
    "    \n",
    "   \n",
    "    \n",
    "    gen_integral_blob_img_bw = gen_integral_blob_img > 1\n",
    "    leader_blob_image_bw = leader_blob_image > 1 \n",
    "    cv2.imwrite(os.path.join( leader_blob_image_folder,  str(s+1)+ 'leader_blob_image.png'), np.asarray(leader_blob_image_bw*255,dtype=np.uint8))\n",
    "    cv2.imwrite(os.path.join( leader_rx_image_folder,  str(s+1)+ 'leader_rx_image.png'), leader_rx_image)\n",
    "    cv2.imwrite(os.path.join( gen_integral_blob_img_folder,  str(s+1)+ 'gen_integral_blob_img.png'), np.asarray(gen_integral_blob_img_bw*255,dtype=np.uint8))\n",
    "    xafter.append(ref_loc)\n",
    "    yafter.append(ref_loc)\n",
    "    xbefore.append(prevwaypoints)\n",
    "    ybefore.append(prevwaypoints)\n",
    "    cameralist.append(cameraid)\n",
    "    #####################################3 following change to cameraid or new_leader_index \n",
    "    leaderlist.append(cameraid)\n",
    "    \n",
    "    \n",
    "    xcameraafter.append(ref_loc[0][cameraid])\n",
    "    ycameraafter.append(ref_loc[1][cameraid])\n",
    "    xcamerabefore.append(prevwaypoints[0][cameraid])\n",
    "    ycamerabefore.append(prevwaypoints[1][cameraid])\n",
    "    ############################################ for means centre of the pack\n",
    "    \n",
    "    currentmeanx.append(np.mean(ref_loc[0]))\n",
    "    currentmeany.append(np.mean(ref_loc[1]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #########################################\n",
    "    \n",
    "    prevwaypoints = ref_loc\n",
    "    #print(prevwaypoints)\n",
    "    print(new_leader_index, cameraid)\n",
    "    print(new_leader_contour)\n",
    "    print(metric_area)\n",
    "    drawing_leader_index = cameraid\n",
    "   \n",
    "    v16 = {\n",
    "         o-1:new_leader_index,\n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    with open(r'C:\\Users\\Rakesh\\Downloads\\leader.json' , 'r+') as file:\n",
    "            data1 = json.load(file)\n",
    "            data1.update(v16)\n",
    "            file.seek(0)\n",
    "            json.dump(data1, file)      \n",
    "            \n",
    "    v17 = {\n",
    "         o-1:cameraid,\n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    with open(r'C:\\Users\\Rakesh\\Downloads\\cameraid.json' , 'r+') as file:\n",
    "            data2 = json.load(file)\n",
    "            data2.update(v17)\n",
    "            file.seek(0)\n",
    "            json.dump(data2, file)      \n",
    "            \n",
    "            \n",
    "    v18 = {\n",
    "         o-1:metric_area,\n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    with open(r'C:\\Users\\Rakesh\\Downloads\\metric_area.json' , 'r+') as file:\n",
    "            data3 = json.load(file)\n",
    "            data3.update(v18)\n",
    "            file.seek(0)\n",
    "            json.dump(data3, file)              \n",
    "                          \n",
    "                          \n",
    "    v19 = {\n",
    "         o-1:new_leader_contour,\n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    with open(r'C:\\Users\\Rakesh\\Downloads\\new_leader_contour.json' , 'r+') as file:\n",
    "            data4 = json.load(file)\n",
    "            data4.update(v19)\n",
    "            file.seek(0)\n",
    "            json.dump(data4, file)                \n",
    "            \n",
    "    \n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    \n",
    "    \n",
    "    metric_list.append(metric_area)\n",
    "    iter_list.append(iter)\n",
    "    print(metric_list)\n",
    "    \n",
    "\n",
    "    time_taken = (new_max_distance/drone_speed)\n",
    "    previous_time = previous_time + time_taken\n",
    "    time_list.append(previous_time)\n",
    "    \n",
    "    v20 = {\n",
    "         o-1:previous_time,\n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    with open(r'C:\\Users\\Rakesh\\Downloads\\time_taken.json' , 'r+') as file:\n",
    "            data5 = json.load(file)\n",
    "            data5.update(v20)\n",
    "            file.seek(0)\n",
    "            json.dump(data5, file)   \n",
    "    \n",
    "    #plt.axis([-10, 200, -40, 1500])\n",
    "    plt.axis([-0.5, 120, -40, 1500])\n",
    "    #plt.xlabel(\"Iteration\", fontsize=14)\n",
    "    plt.xlabel(\"Time (seconds)\", fontsize=14)\n",
    "    plt.ylabel(\"Metric\", fontsize=14)\n",
    "    plt.plot(time_list, metric_list,'xb-',markersize = 6)\n",
    "    \n",
    "    print(time_taken)\n",
    "    print(time_list)\n",
    "    print(metric_list)\n",
    "\n",
    "    \n",
    "\n",
    "    #plt.show()\n",
    "    save_results_to = r'C:/Users/Rakesh/Downloads/plots/'\n",
    "\n",
    "    plt.savefig(save_results_to +  'image' + str(iter-1) + '.png')\n",
    "    print(metric_list)\n",
    "    \n",
    "    aos.clearViews();\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    #############################For the Second Step ---- Generate the link from the new locations############################################################### \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    import os\n",
    "    \n",
    "\n",
    "\n",
    "    stageimg = cv2.imread( r'C:\\Users\\Rakesh\\Downloads\\stages\\Waypoint' + str(iter) + '.png')\n",
    "\n",
    "    img_folder = os.path.join( r'C:\\Users\\Rakesh\\Downloads\\images\\Waypoint' + str(iter))\n",
    "    #print(img_folder)\n",
    "    import re\n",
    "\n",
    "    numbers = re.compile(r'(\\d+)')\n",
    "    def numericalSort(value):\n",
    "        parts = numbers.split(value)\n",
    "        parts[1::2] = map(int, parts[1::2])\n",
    "        return parts\n",
    "\n",
    "    imagelist = []\n",
    "\n",
    "    import glob\n",
    "\n",
    "    for img in sorted(glob.glob(r'C:\\Users\\Rakesh\\Downloads\\images\\Waypoint' + str(iter) + '/*.png'),key=numericalSort):\n",
    "        n= cv2.imread(img)\n",
    "        imagelist.append(n)\n",
    "        \n",
    "\n",
    "    #print(imagelist[0])\n",
    "\n",
    "    integral = []\n",
    "    integral_img = os.path.join(r'C:\\Users\\Rakesh\\Downloads\\integrals')\n",
    "    for imges in sorted(glob.glob(r'C:\\Users\\Rakesh\\Downloads\\integrals' + '/*.png'),key=numericalSort):\n",
    "        r= cv2.imread(imges)\n",
    "        integral.append(r)\n",
    "        #print('Image Dimensions :', r.shape)\n",
    "        \n",
    "        \n",
    "    thermal_dimension = round((2*(altitude_list[drawing_leader_index])*0.4663*9.33))     # Fov is 50 so theta by 2 is 25  \n",
    "\n",
    "    print(thermal_dimension)\n",
    "\n",
    "    mask = np.ones((thermal_dimension,thermal_dimension,3), np.uint8)   #(should be changed based on the leader)\n",
    "    h, w , k = mask.shape\n",
    "    print(drawing_current_location[0][drawing_leader_index])\n",
    "    xoff = round((467 + 33 + (9.33 * drawing_current_location[0][drawing_leader_index]) - (thermal_dimension /2)))  # leader x position instead of 18\n",
    "    yoff = round((467 + 31 + (9.33 * drawing_current_location[1][drawing_leader_index]) - (thermal_dimension /2)))   # leader y position instead of zero\n",
    "    result = stageimg.copy()\n",
    "    result[yoff:yoff+h, xoff:xoff+w] = mask    \n",
    "\n",
    "    final = result.copy()\n",
    "    dim = (thermal_dimension,thermal_dimension)  #(should be changed based on the leader)\n",
    "    thermalresizeimg = cv2.resize(integral[(iter*3)+(iter-1)], dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    h1, w1, k1 = thermalresizeimg.shape\n",
    "    print('resiyedimage',h1,w1,k1)\n",
    "    final[yoff:yoff+h1, xoff:xoff+w1] = thermalresizeimg\n",
    "    \n",
    "    # if s >= 2:\n",
    "    #     a = 0\n",
    "        \n",
    "    #     for m in range (len(xbefore) - 1):\n",
    "    #         for k in range (10):      #remove this\n",
    "                        \n",
    "    #             x_1 = round(467 + 33 + ((275/(275-(altitude_list[k])))*9.33*xafter[a][0][k]))   # k replace with a number as index for a drone \n",
    "    #             y_1 = round(467 + 31 + ((275/(275-(altitude_list[k])))*9.33*yafter[a][1][k]))\n",
    "    #             x_0 = round(467 + 33 + ((275/(275-(altitude_list[k])))*9.33*xbefore[a][0][k]))\n",
    "    #             y_0 = round(467 + 31 + ((275/(275-(altitude_list[k])))*9.33*ybefore[a][1][k]))\n",
    "                \n",
    "                    \n",
    "                \n",
    "\n",
    "    \n",
    "    #             cv2.line(final,(x_0,y_0),(x_1,y_1),(255,0,0),2)\n",
    "    #         a = a+1  #keep this\n",
    "    \n",
    "    if s>=2:    \n",
    "        \n",
    "        g = 2   \n",
    "        h = 1 \n",
    "        for m in range (len(xbefore) - 1):\n",
    "                \n",
    "            #for k in range (10):      #remove this\n",
    "                        \n",
    "                # x_1 = round(467 + 33 + ((275/(275-(altitude_list[leaderlist[1]])))*9.33*xcameraafter[h]))   # k replace with a number as index for a drone \n",
    "                # y_1 = round(467 + 31 + ((275/(275-(altitude_list[leaderlist[1]])))*9.33*ycameraafter[h]))\n",
    "                # x_0 = round(467 + 33 + ((275/(275-(altitude_list[leaderlist[0]])))*9.33*xcameraafter[h-1]))\n",
    "                # y_0 = round(467 + 31 + ((275/(275-(altitude_list[leaderlist[0]])))*9.33*ycameraafter[h-1]))\n",
    "                # cv2.line(final,(x_0,y_0),(x_1,y_1),(255,0,0),2)\n",
    "                \n",
    "                x_1 = round(467 + 33 + ((275/(275-(np.mean(altitude_list))))*9.33*currentmeanx[h]))   # k replace with a number as index for a drone \n",
    "                y_1 = round(467 + 31 + ((275/(275-(np.mean(altitude_list))))*9.33*currentmeany[h]))\n",
    "                x_0 = round(467 + 33 + ((275/(275-(np.mean(altitude_list))))*9.33*currentmeanx[h-1]))\n",
    "                y_0 = round(467 + 31 + ((275/(275-(np.mean(altitude_list))))*9.33*currentmeany[h-1]))\n",
    "                cv2.line(final,(x_0,y_0),(x_1,y_1),(255,0,0),2)\n",
    "                \n",
    "                \n",
    "        for m in range (len(xbefore)  - 1 ):        \n",
    "            if ((len(xbefore)) >=3  and  g < (len(xbefore))):\n",
    "                    \n",
    "                    # x_1 = round(467 + 33 + ((275/(275-(altitude_list[leaderlist[g]])))*9.33*xcameraafter[g]))   # k replace with a number as index for a drone \n",
    "                    # y_1 = round(467 + 31 + ((275/(275-(altitude_list[leaderlist[g]])))*9.33*ycameraafter[g]))\n",
    "                    # x_0 = round(467 + 33 + ((275/(275-(altitude_list[leaderlist[g-1]])))*9.33*xcameraafter[g-1]))\n",
    "                    # y_0 = round(467 + 31 + ((275/(275-(altitude_list[leaderlist[g-1]])))*9.33*ycameraafter[g-1]))\n",
    "                    # g = g + 1\n",
    "                    \n",
    "                    x_1 = round(467 + 33 + ((275/(275-(np.mean(altitude_list))))*9.33*currentmeanx[g]))   # k replace with a number as index for a drone \n",
    "                    y_1 = round(467 + 31 + ((275/(275-(np.mean(altitude_list))))*9.33*currentmeany[g]))\n",
    "                    x_0 = round(467 + 33 + ((275/(275-(np.mean(altitude_list))))*9.33*currentmeanx[g-1]))\n",
    "                    y_0 = round(467 + 31 + ((275/(275-(np.mean(altitude_list))))*9.33*currentmeany[g-1]))\n",
    "                    g = g + 1\n",
    "\n",
    "    \n",
    "                    cv2.line(final,(x_0,y_0),(x_1,y_1),(255,0,0),2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for k in range (NumberofDrones):\n",
    "        x_currentposition = round(467 + 33 + ((275/(275-(altitude_list[k])))*9.33*drawing_current_location[0][k]))\n",
    "        y_currentposition = round(467 + 31 + ((275/(275-(altitude_list[k])))*9.33*drawing_current_location[1][k]))\n",
    "        x_previousposition = round(467 + 33 + ((275/(275-(altitude_list[k])))*9.33*drawing_previous_location[0][k]))\n",
    "        y_previousposition = round(467 + 31 + ((275/(275-(altitude_list[k])))*9.33*drawing_previous_location[1][k]))\n",
    "\n",
    "\n",
    "        cv2.circle(final, (x_currentposition, y_currentposition), 6, (255, 191, 0), -1)    # dimensions to be changed\n",
    "        \n",
    "        # dimensions to be changed\n",
    "\n",
    "        leaderx_currentposition = round(467 + 33 + ((275/(275-(altitude_list[new_leader_index])))*9.33*drawing_current_location[0][new_leader_index]))\n",
    "        leadery_currentposition = round(467 + 31 + ((275/(275-(altitude_list[new_leader_index])))*9.33*drawing_current_location[1][new_leader_index]))    \n",
    "        cv2.circle(final, (leaderx_currentposition, leadery_currentposition), 6, (0, 255, 255), -1)   \n",
    "        \n",
    "        if (math.sqrt((x_previousposition-x_currentposition)**2 + (y_previousposition-y_currentposition)**2)) == 0 :\n",
    "            \n",
    "            division  = 0.1\n",
    "        else:\n",
    "            division  = (math.sqrt((x_previousposition-x_currentposition)**2 + (y_previousposition-y_currentposition)**2))  \n",
    "            \n",
    "       \n",
    "        cv2.arrowedLine(final, (x_previousposition, y_previousposition), (x_currentposition, y_currentposition), (255,255,255), 3, tipLength= 10/division)    \n",
    "        \n",
    "    # if s >= 2:\n",
    "    #     a = 0\n",
    "        \n",
    "    #     for m in range (len(xbefore) - 1):\n",
    "    #         for k in range (10):      #remove this\n",
    "                        \n",
    "    #             x_1 = round(467 + 33 + ((275/(275-(altitude_list[k])))*9.33*xafter[a][0][k]))   # k replace with a number as index for a drone \n",
    "    #             y_1 = round(467 + 31 + ((275/(275-(altitude_list[k])))*9.33*yafter[a][1][k]))\n",
    "    #             x_0 = round(467 + 33 + ((275/(275-(altitude_list[k])))*9.33*xbefore[a][0][k]))\n",
    "    #             y_0 = round(467 + 31 + ((275/(275-(altitude_list[k])))*9.33*ybefore[a][1][k]))\n",
    "                \n",
    "                    \n",
    "                \n",
    "\n",
    "    \n",
    "    #             cv2.line(final,(x_0,y_0),(x_1,y_1),(255,0,0),2)\n",
    "    #         a = a+1  #keep this\n",
    "    # if s>=2:    \n",
    "        \n",
    "    #     g = 2   \n",
    "    #     h = 1 \n",
    "    #     for m in range (len(xbefore) - 1):\n",
    "                \n",
    "    #         #for k in range (10):      #remove this\n",
    "                        \n",
    "    #             x_1 = round(467 + 33 + ((275/(275-(altitude_list[leaderlist[1]])))*9.33*xcameraafter[h]))   # k replace with a number as index for a drone \n",
    "    #             y_1 = round(467 + 31 + ((275/(275-(altitude_list[leaderlist[1]])))*9.33*ycameraafter[h]))\n",
    "    #             x_0 = round(467 + 33 + ((275/(275-(altitude_list[leaderlist[0]])))*9.33*xcameraafter[h-1]))\n",
    "    #             y_0 = round(467 + 31 + ((275/(275-(altitude_list[leaderlist[0]])))*9.33*ycameraafter[h-1]))\n",
    "    #             cv2.line(final,(x_0,y_0),(x_1,y_1),(255,0,0),2)\n",
    "                \n",
    "    #     for m in range (len(xbefore)  - 1 ):        \n",
    "    #         if ((len(xbefore)) >=3  and  g < (len(xbefore))):\n",
    "                    \n",
    "    #                 x_1 = round(467 + 33 + ((275/(275-(altitude_list[leaderlist[g]])))*9.33*xcameraafter[g]))   # k replace with a number as index for a drone \n",
    "    #                 y_1 = round(467 + 31 + ((275/(275-(altitude_list[leaderlist[g]])))*9.33*ycameraafter[g]))\n",
    "    #                 x_0 = round(467 + 33 + ((275/(275-(altitude_list[leaderlist[g-1]])))*9.33*xcameraafter[g-1]))\n",
    "    #                 y_0 = round(467 + 31 + ((275/(275-(altitude_list[leaderlist[g-1]])))*9.33*ycameraafter[g-1]))\n",
    "    #                 g = g + 1\n",
    "\n",
    "    \n",
    "    #                 cv2.line(final,(x_0,y_0),(x_1,y_1),(255,0,0),2)\n",
    "               \n",
    "            \n",
    "            \n",
    "    integral_metric = []\n",
    "    integral_metric_img = os.path.join(r'C:\\Users\\Rakesh\\Downloads\\plots')\n",
    "    for imges1 in sorted(glob.glob(r'C:\\Users\\Rakesh\\Downloads\\plots' + '/*.png'),key=numericalSort):\n",
    "        r1= cv2.imread(imges1)\n",
    "        integral_metric.append(r1)\n",
    "        #print('Image Dimensions :', r1.shape)  \n",
    "        \n",
    "    leader_blob_image_list = []\n",
    "\n",
    "    for imges in sorted(glob.glob(r'C:\\Users\\Rakesh\\Downloads\\leader_blob_image' + '/*.png'),key=numericalSort):\n",
    "        r2= cv2.imread(imges)\n",
    "        leader_blob_image_list.append(r2)\n",
    "        \n",
    "    leader_rx_image_list = []\n",
    "\n",
    "    for imges in sorted(glob.glob(r'C:\\Users\\Rakesh\\Downloads\\leader_rx_image' + '/*.png'),key=numericalSort):\n",
    "        r3= cv2.imread(imges)\n",
    "        leader_rx_image_list.append(r3)    \n",
    "        \n",
    "    gen_integral_blob_img_list = []\n",
    "\n",
    "    for imges in sorted(glob.glob(r'C:\\Users\\Rakesh\\Downloads\\gen_integral_blob_img' + '/*.png'),key=numericalSort):\n",
    "        r4= cv2.imread(imges)\n",
    "        gen_integral_blob_img_list.append(r4)       \n",
    "\n",
    "\n",
    "    #print(integral[iter])\n",
    "    dim = (1536,1542)\n",
    "    dim1 =(256,256)\n",
    "    dim2 =(512,512)\n",
    "    white = [255,255,0]\n",
    "    rgbimg1= cv2.copyMakeBorder(imagelist[10],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    rgbimg6= cv2.copyMakeBorder(imagelist[15],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    stimg= cv2.copyMakeBorder(final,1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    therimg1= cv2.copyMakeBorder(imagelist[0],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    therimg2= cv2.copyMakeBorder(imagelist[1],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    therimg3= cv2.copyMakeBorder(imagelist[2],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    therimg4= cv2.copyMakeBorder(imagelist[3],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    therimg5= cv2.copyMakeBorder(imagelist[4],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    therimg6= cv2.copyMakeBorder(imagelist[5],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    therimg7= cv2.copyMakeBorder(imagelist[6],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    therimg8= cv2.copyMakeBorder(imagelist[7],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    therimg9= cv2.copyMakeBorder(imagelist[8],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    therimg10= cv2.copyMakeBorder(imagelist[9],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    rgbimg2= cv2.copyMakeBorder(imagelist[11],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    rgbimg3= cv2.copyMakeBorder(imagelist[12],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    rgbimg4= cv2.copyMakeBorder(imagelist[13],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    rgbimg5= cv2.copyMakeBorder(imagelist[14],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    rgbimg7= cv2.copyMakeBorder(imagelist[16],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    rgbimg8= cv2.copyMakeBorder(imagelist[17],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    rgbimg9= cv2.copyMakeBorder(imagelist[18],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    rgbimg10= cv2.copyMakeBorder(imagelist[19],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    irgb1= cv2.copyMakeBorder(integral[(iter*3)+(iter-2)],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    it1= cv2.copyMakeBorder(integral[(iter*3)+(iter-1)],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    met1= cv2.copyMakeBorder(integral_metric[iter-1],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    a1 = cv2.copyMakeBorder(leader_blob_image_list[s],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    a2 = cv2.copyMakeBorder(leader_rx_image_list[s],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    a3 = cv2.copyMakeBorder(gen_integral_blob_img_list[s],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    # img5= cv2.copyMakeBorder(imagelist[4],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    # img6= cv2.copyMakeBorder(imagelist[5],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    # img7= cv2.copyMakeBorder(imagelist[6],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    # img8= cv2.copyMakeBorder(imagelist[7],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    # img9= cv2.copyMakeBorder(imagelist[8],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    # img10= cv2.copyMakeBorder(imagelist[9],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "\n",
    "\n",
    "    # stage_img = cv2.resize(stageimg, dim, interpolation = cv2.INTER_AREA)\n",
    "    rgbimg1 = cv2.resize(rgbimg1, dim1, interpolation = cv2.INTER_AREA)\n",
    "    rgbimg6 = cv2.resize(rgbimg6, dim1, interpolation = cv2.INTER_AREA)\n",
    "    stimg = cv2.resize(stimg, dim, interpolation = cv2.INTER_AREA)\n",
    "    therimg1 = cv2.resize(therimg1, dim1, interpolation = cv2.INTER_AREA)\n",
    "    therimg2 = cv2.resize(therimg2, dim1, interpolation = cv2.INTER_AREA)\n",
    "    therimg3 = cv2.resize(therimg3, dim1, interpolation = cv2.INTER_AREA)\n",
    "    therimg4 = cv2.resize(therimg4, dim1, interpolation = cv2.INTER_AREA)\n",
    "    therimg5 = cv2.resize(therimg5, dim1, interpolation = cv2.INTER_AREA)\n",
    "    therimg6 = cv2.resize(therimg6, dim1, interpolation = cv2.INTER_AREA)\n",
    "    therimg7 = cv2.resize(therimg7, dim1, interpolation = cv2.INTER_AREA)\n",
    "    therimg8 = cv2.resize(therimg8, dim1, interpolation = cv2.INTER_AREA)\n",
    "    therimg9 = cv2.resize(therimg9, dim1, interpolation = cv2.INTER_AREA)\n",
    "    therimg10 = cv2.resize(therimg10, dim1, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    rgbimg2 = cv2.resize(rgbimg2, dim1, interpolation = cv2.INTER_AREA)\n",
    "    rgbimg3 = cv2.resize(rgbimg3, dim1, interpolation = cv2.INTER_AREA)\n",
    "    rgbimg4 = cv2.resize(rgbimg4, dim1, interpolation = cv2.INTER_AREA)\n",
    "    rgbimg5 = cv2.resize(rgbimg5, dim1, interpolation = cv2.INTER_AREA)\n",
    "    rgbimg7 = cv2.resize(rgbimg7, dim1, interpolation = cv2.INTER_AREA)\n",
    "    rgbimg8 = cv2.resize(rgbimg8, dim1, interpolation = cv2.INTER_AREA)\n",
    "    rgbimg9 = cv2.resize(rgbimg9, dim1, interpolation = cv2.INTER_AREA)\n",
    "    rgbimg10 = cv2.resize(rgbimg10, dim1, interpolation = cv2.INTER_AREA)\n",
    "    irgb1 = cv2.resize(irgb1, dim2, interpolation = cv2.INTER_AREA)\n",
    "    it1 = cv2.resize(it1, dim2, interpolation = cv2.INTER_AREA)\n",
    "    met1 = cv2.resize(met1, dim2, interpolation = cv2.INTER_AREA)\n",
    "    a1 = cv2.resize(a1, dim1, interpolation = cv2.INTER_AREA)\n",
    "    a2 = cv2.resize(a2, dim1, interpolation = cv2.INTER_AREA)\n",
    "    a3 = cv2.resize(a3, dim1, interpolation = cv2.INTER_AREA)\n",
    "    # img2 = cv2.resize(img2, dim1, interpolation = cv2.INTER_AREA)\n",
    "    # img3 = cv2.resize(img3, dim1, interpolation = cv2.INTER_AREA)\n",
    "    # img4 = cv2.resize(img4, dim1, interpolation = cv2.INTER_AREA)\n",
    "    # img5 = cv2.resize(img5, dim1, interpolation = cv2.INTER_AREA)\n",
    "    # img6 = cv2.resize(img6, dim1, interpolation = cv2.INTER_AREA)\n",
    "    # img7 = cv2.resize(img7, dim1, interpolation = cv2.INTER_AREA)\n",
    "    # img8 = cv2.resize(img8, dim1, interpolation = cv2.INTER_AREA)\n",
    "    # img9 = cv2.resize(img9, dim1, interpolation = cv2.INTER_AREA)\n",
    "    # img10 = cv2.resize(img10, dim1, interpolation = cv2.INTER_AREA)\n",
    "    # img11 = cv2.resize(integral_metric[k], dim1, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "    h1, w1 = rgbimg1.shape[:2]\n",
    "    h6, w6 = rgbimg6.shape[:2]\n",
    "    sh1, sw1 = stimg.shape[:2]\n",
    "    h11, w11 = therimg1.shape[:2]\n",
    "    h12, w12 = therimg2.shape[:2]\n",
    "    h13, w13 = therimg3.shape[:2]\n",
    "    h14, w14 = therimg4.shape[:2]\n",
    "    h15, w15 = therimg5.shape[:2]\n",
    "    h16, w16 = therimg6.shape[:2]\n",
    "    h17, w17 = therimg7.shape[:2]\n",
    "    h18, w18 = therimg8.shape[:2]\n",
    "    h19, w19 = therimg9.shape[:2]\n",
    "    h20, w20 = therimg10.shape[:2]\n",
    "    h2, w2 = rgbimg2.shape[:2]\n",
    "    h3, w3 = rgbimg3.shape[:2]\n",
    "    h4, w4 = rgbimg4.shape[:2]\n",
    "    h5, w5 = rgbimg5.shape[:2]\n",
    "    h7, w7 = rgbimg7.shape[:2]\n",
    "    h8, w8 = rgbimg8.shape[:2]\n",
    "    h9, w9 = rgbimg9.shape[:2]\n",
    "    h10, w10 = rgbimg10.shape[:2]\n",
    "    ih1, iw1 = irgb1.shape[:2]\n",
    "    ith1, itw1 = it1.shape[:2]\n",
    "    meth1, metw1 = met1.shape[:2]\n",
    "    a1h, a1w = a1.shape[:2]\n",
    "    a2h, a2w = a2.shape[:2]\n",
    "    a3h, a3w = a3.shape[:2]\n",
    "\n",
    "    # h1, w1 = stage_img.shape[:2]\n",
    "    # h2, w2 = integral[iter].shape[:2]\n",
    "    # h3, w3 = img1.shape[:2]\n",
    "    # h4, w4 = img2.shape[:2]\n",
    "    # h5, w5 = img3.shape[:2]\n",
    "    # h6, w6 = img4.shape[:2]\n",
    "    # h7, w7 = img5.shape[:2]\n",
    "    # h8, w8 = img6.shape[:2]\n",
    "    # h9, w9 = img7.shape[:2]\n",
    "    # h10, w10 = img8.shape[:2]\n",
    "    # h11, w11 = img9.shape[:2]\n",
    "    # h12, w12 = img10.shape[:2]\n",
    "    # h13,w13 = img11.shape[:2]\n",
    "    # print(h12, w12)\n",
    "\n",
    "    img_3 = np.zeros((1542,3084,3), dtype=np.uint8)\n",
    "    # print(img_3[:h1, :w1,:3].shape)\n",
    "    # print(img_3[:h2, w1:w1+w2,:3].shape)\n",
    "    img_3[:h1, :w1,:3] = rgbimg1\n",
    "    img_3[:h1, w1:w1+w6,:3] = rgbimg6\n",
    "    img_3[:h6+h1+sh1, w1+w6:w1+w6+sw1 ,:3] = stimg\n",
    "    img_3[:h1, w1+w6+sw1:w1+w6+sw1+w11 ,:3] = therimg1\n",
    "    img_3[h1:h1+h2, w1+w6+sw1:w1+w6+sw1+w11 ,:3] = therimg2\n",
    "    img_3[h1+h2:h1+h2+h3, w1+w6+sw1:w1+w6+sw1+w11 ,:3] = therimg3\n",
    "    img_3[h1+h2+h3:h1+h2+h3+h4, w1+w6+sw1:w1+w6+sw1+w11 ,:3] = therimg4\n",
    "    img_3[h1+h2+h3+h4:h1+h2+h3+h4+h5, w1+w6+sw1:w1+w6+sw1+w11 ,:3] = therimg5\n",
    "    img_3[h1+h2+h3+h4+h5:h1+h2+h3+h4+h5+a1h, w1+w6+sw1:w1+w6+sw1+w11 ,:3] = a1\n",
    "    img_3[:h1, w1+w6+sw1+w11:w1+w6+sw1+w11+w16 ,:3] = therimg6\n",
    "    img_3[h1:h1+h2, w1+w6+sw1+w11:w1+w6+sw1+w11+w16 ,:3] = therimg7\n",
    "    img_3[h1+h2:h1+h2+h3, w1+w6+sw1+w11:w1+w6+sw1+w11+w16 ,:3] = therimg8\n",
    "    img_3[h1+h2+h3:h1+h2+h3+h4, w1+w6+sw1+w11:w1+w6+sw1+w11+w16 ,:3] = therimg9\n",
    "    img_3[h1+h2+h3+h4:h1+h2+h3+h4+h5, w1+w6+sw1+w11:w1+w6+sw1+w11+w16 ,:3] = therimg10\n",
    "    img_3[h1+h2+h3+h4+h5:h1+h2+h3+h4+h5+a3h, w1+w6+sw1+w11:w1+w6+sw1+w11+w16 ,:3] = a3\n",
    "    img_3[h1:h1+h2, :w2,:3] = rgbimg2\n",
    "    img_3[h1+h2:h1+h2+h3, :w3,:3] = rgbimg3\n",
    "    img_3[h1+h2+h3:h1+h2+h3+h4, :w2,:3] = rgbimg4\n",
    "    img_3[h1+h2+h3+h4:h1+h2+h3+h4+h5, :w2,:3] = rgbimg5\n",
    "    #img_3[h1+h2+h3+h4+h5:h1+h2+h3+h4+h5+a2h, :w2,:3] = a2\n",
    "    img_3[h1:h1+h2, w1:w1+w7,:3] = rgbimg7\n",
    "    img_3[h1+h2:h1+h2+h3, w1:w1+w8,:3] = rgbimg8\n",
    "    img_3[h1+h2+h3:h1+h2+h3+h4, w1:w1+w9,:3] = rgbimg9\n",
    "    img_3[h1+h2+h3+h4:h1+h2+h3+h4+h5, w1:w1+w10,:3] = rgbimg10\n",
    "    img_3[:h1+h6, w1+w6+sw1+w11+w16:w1+w6+sw1+w11+w16+iw1,:3] = irgb1\n",
    "    img_3[h1+h2:h1+h6+ith1, w1+w6+sw1+w11+w16:w1+w6+sw1+w11+w16+iw1,:3] = it1\n",
    "    img_3[h1+h2+ith1:h1+h6+ith1+meth1, w1+w6+sw1+w11+w16:w1+w6+sw1+w11+w16+iw1,:3] = met1\n",
    "    # img_3[:h2, w1:w1+w2,:3] = integral[iter]\n",
    "\n",
    "    # img_3[h1:h1+h3, :w3,:3] = img1\n",
    "    # img_3[h1:h1+h3, w3:w3+w4,:3] = img2\n",
    "    # img_3[h1:h1+h3, w2:w3+w4+w5,:3] = img3\n",
    "    # img_3[h1:h1+h3, w1:w3+w4+w5+w6,:3] = img4\n",
    "    # img_3[h1:h1+h3, w1+w3:w3+w4+w5+w6+w7,:3] = img5\n",
    "    # img_3[h1+h3:h1+h3+h4, :w8,:3] = img6\n",
    "    # img_3[h1+h3:h1+h3+h4, w8:w8+w9,:3] = img7\n",
    "    # img_3[h1+h3:h1+h3+h4, w8+w7:w8+w9+w10,:3] = img8\n",
    "    # img_3[h1+h3:h1+h3+h4, w8+w7+w9:w8+w9+w10+w11,:3] = img9\n",
    "    # img_3[h1+h3:h1+h3+h4, w8+w7+w9+w10:w8+w9+w10+w11+w12,:3] = img10\n",
    "    # img_3[h2:h2+h13, w1:w1+w13,:3] = img11\n",
    "\n",
    "\n",
    "    # #cv2.putText(img_3,\"Metric:\" + str(new_leader_contour), (830,615), cv2.FONT_HERSHEY_SIMPLEX, 1, 255)\n",
    "    # #cv2.putText(img_3,\"Leader_index:\" + str(new_leader_index), (820,660), cv2.FONT_HERSHEY_SIMPLEX, 1, 255)\n",
    "\n",
    "    # # print(img_3.shape)\n",
    "\n",
    "    # th = 0.1 # defines the value below which a pixel is considered \"black\"\n",
    "    # black_pixels = np.where(\n",
    "    #     (img_3[:, :, 0] < th) & \n",
    "    #     (img_3[:, :, 1] < th) & \n",
    "    #     (img_3[:, :, 2] < th)\n",
    "    # )\n",
    "    # img_3[black_pixels] = [255, 255, 255]\n",
    "\n",
    "    cv2.imwrite(os.path.join(r'C:\\Users\\Rakesh\\Downloads\\Final_result', ('stage_' + str(iter) + '.png')),img_3)\n",
    "    s = s+1\n",
    "    o = o+2\n",
    "    p = p+2\n",
    "    #person = person\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open(r'C:\\Users\\Rakesh\\Downloads\\values.txt', 'a') as f:\n",
    "        f.write('NumberofDrones'+ ' '+str(NumberofDrones))\n",
    "        f.write('\\n')\n",
    "        f.write('fov'+ ' '+str(fov))\n",
    "        f.write('\\n')\n",
    "        f.write('rxthreshold'+ ' '+str(rxthreshold))\n",
    "        f.write('\\n')\n",
    "        f.write('dem_height'+ ' '+str(dem_height))\n",
    "        f.write('\\n')\n",
    "        f.write('distance_btwn_drones'+ ' '+str(distance_btwn_drones))\n",
    "        f.write('\\n')\n",
    "        f.write('Scanning_direction'+ ' '+str(Scanning_direction))\n",
    "        f.write('\\n')\n",
    "        f.write('Scanning_direction_Waypoint_Distance_c3'+ ' '+str(Scanning_direction_Waypoint_Distance))\n",
    "        f.write('\\n')\n",
    "        f.write('emptyblobthreshold'+ ' '+str(emptyblobthreshold))\n",
    "        f.write('\\n')\n",
    "        f.write('changing_to_linear_speed_c5'+ ' '+str(changing_to_linear_speed))\n",
    "        f.write('\\n')\n",
    "        f.write('local_fac_c1'+ ' '+str(local_fac))\n",
    "        f.write('\\n')\n",
    "        f.write('global_fac_c2'+ ' '+str(global_fac))\n",
    "        f.write('\\n')\n",
    "        f.write('minimum_distance_btwn_drone_c4'+ ' '+str(minimum_distance_btwn_drone))\n",
    "        f.write('\\n')\n",
    "        f.write('person'+ ' '+str(person))\n",
    "        f.write('\\n')\n",
    "        f.write('blobthreshold'+ ' '+str(emptyblobthreshold))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utm\n",
    "print(utm.from_latlon(48.335836, 14.326644))\n",
    "print(np.arange(-(int)((10-1)/2),(int)((10+2)/2),1) * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leader_blob_image_list = []\n",
    "\n",
    "for imges in sorted(glob.glob(r'C:\\Users\\Rakesh\\Downloads\\leader_blob_image' + '/*.png'),key=numericalSort):\n",
    "    r2= cv2.imread(imges)\n",
    "    leader_blob_image_list.append(r2)\n",
    "    \n",
    "print(leader_blob_image_list)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "altitude_list = [35,36,37,38,39,40,41,42,43,44]\n",
    "print(np.mean(altitude_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "currentblob_personposition = [0.5429264720709099, 10.267435782509374] \n",
    "dronemeanpos = [0.185841061162089, 0.15672915154027667] \n",
    "import numpy as np\n",
    "import math\n",
    "angle = np.arctan2(dronemeanpos[1]-currentblob_personposition[1],dronemeanpos[0]-currentblob_personposition[0])\n",
    "angle = ((np.degrees(angle))%360)+90\n",
    "print(angle)\n",
    "if angle == 0 or angle==360 :\n",
    "    angle = 0                             #need to switch sign of yaxis positive is down and negative is up\n",
    "    print(angle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "coverage = 2*35*np.tan(25)\n",
    "print(np.tan(np.deg2rad(25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = 2*35*np.tan(np.deg2rad(25))\n",
    "print(coverage)\n",
    "rect = [274,401,29,29]\n",
    "resolution = 512\n",
    "metretopixels = coverage/resolution\n",
    "print(metretopixels)\n",
    "blob_posx = rect[0] + rect[2]/2\n",
    "blob_posy = rect[1] + rect[3]/2\n",
    "blob_posxinpixels = blob_posx * metretopixels\n",
    "blob_posyinpixels = blob_posy * metretopixels\n",
    "blobposition = [blob_posxinpixels,blob_posyinpixels]\n",
    "print(blobposition)\n",
    "integralposition_centre = [-2, 0]\n",
    "print(integralposition_centre)\n",
    "integral_startposition = [integralposition_centre[0] - coverage/2, integralposition_centre[1] - coverage/2]\n",
    "print(integral_startposition)\n",
    "blob_personposition = [blobposition[0] - abs(integral_startposition[0]), blobposition[1] - abs(integral_startposition[1])]\n",
    "print(blob_personposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = (0,0)\n",
    "p2 = (0,10)\n",
    "\n",
    "# Difference in x coordinates\n",
    "dx = p2[0] - p1[0]\n",
    "\n",
    "# Difference in y coordinates\n",
    "dy = p2[1] - p1[1]\n",
    "\n",
    "# Angle between p1 and p2 in radians\n",
    "theta = math.atan2(dy, dx)\n",
    "print(math.degrees(theta))\n",
    "print([np.sin(np.deg2rad( 0)), np.cos(np.deg2rad(0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "print((math.sin(np.deg2rad(90))))\n",
    "print((math.cos(np.deg2rad(90))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "person = [22.739795414685666, -4.612425475682947]\n",
    "new_person= [23.15644494871208, -5.577736082168631]\n",
    "dx = new_person[0] - person[0]\n",
    "\n",
    "    # Difference in y coordinates\n",
    "dy = (-new_person[1] + person[1])\n",
    "\n",
    "# Angle between p1 and p2 in radians\n",
    "personorientation = np.arctan2(dy, dx)\n",
    "personorientation = ((np.degrees(personorientation))%360)+90\n",
    "print(personorientation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import required libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# create a black image\n",
    "img = np.zeros((256, 256, 4), dtype = np.uint8)\n",
    "\n",
    "# display the image using opencv\n",
    "#cv2.imshow('black image', img)\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "borderoutput = cv2.copyMakeBorder(\n",
    "    img, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=[0, 0, 255])\n",
    "\n",
    "borderoutput[:,:,3] = borderoutput[:,:,2] \n",
    " \n",
    "# showing the image with border\n",
    "\n",
    "\n",
    "cv2.imwrite(os.path.join(r'C:\\Users\\Rakesh\\Downloads', ('blackupdated.png')),borderoutput)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0546a8624a4a236bae0f9fea37c96b2936c9ad1821cd89b71f7783537db0568"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
