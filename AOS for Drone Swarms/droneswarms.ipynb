{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import matplotlib as plt\n",
    "import math\n",
    "import utm\n",
    "from pyaos.LFR_utils import read_poses_and_images,pose_to_virtualcamera, init_aos, init_window\n",
    "import pyaos.LFR_utils as utils\n",
    "from pathlib import Path\n",
    "import pyaos.lfr as LFR\n",
    "from PIL import Image\n",
    "import glm\n",
    "from datetime import datetime\n",
    "import importlib\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from scipy import interpolate\n",
    "import spectral\n",
    "from skimage import img_as_float\n",
    "import scipy.interpolate\n",
    "from zipfile import ZipFile\n",
    "import glob\n",
    "import shutil\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "Download_Location = r'Enter the path to your downloads directory'     \n",
    "print(Download_Location)\n",
    "Images_Path = os.path.join(Download_Location,'images')   # RGB and Thermal images\n",
    "os.mkdir(Images_Path)\n",
    "Stages_Path = os.path.join(Download_Location,'stages')   # simulation environment\n",
    "os.mkdir(Stages_Path)\n",
    "Integral_Path = os.path.join(Download_Location,'integrals')  # RGB integral, Thermal integral,RGB integral(with_history), Thermal integral(with_history)\n",
    "os.mkdir(Integral_Path)\n",
    "Live_Debug_Path = os.path.join(Download_Location,'live_debug') # For debugging\n",
    "os.mkdir(Live_Debug_Path)\n",
    "Final_result = os.path.join(Download_Location,'Final_result')  # result\n",
    "os.mkdir(Final_result)\n",
    "plots = os.path.join(Download_Location,'plots')  # Time(seconds) vs metric plots\n",
    "os.mkdir(plots)\n",
    "leader_blob_image_folder = os.path.join(Download_Location,'leader_blob_image')  # masked integral\n",
    "os.mkdir(leader_blob_image_folder)\n",
    "leader_rx_image_folder = os.path.join(Download_Location,'leader_rx_image')\n",
    "os.mkdir(leader_rx_image_folder)\n",
    "gen_integral_blob_img_folder = os.path.join(Download_Location,'gen_integral_blob_img') # masked integral(with history)\n",
    "os.mkdir(gen_integral_blob_img_folder)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################Definations defined above###############################################################\n",
    "#############################Start the Chrome Browser###############################################################\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "options = Options()\n",
    "\n",
    "\n",
    "options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "options.add_experimental_option(\"excludeSwitches\",[\"enable-automation\"])\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "#############################Start the AOS Renderer###############################################################\n",
    "treex = str(0)\n",
    "treey = str(0)\n",
    "w,h,fovDegrees = 512, 512, 50 # # resolution and field of view\n",
    "render_fov = 50\n",
    "\n",
    "if 'window' not in locals() or window == None:\n",
    "                                    \n",
    "    window = LFR.PyGlfwWindow( w, h, 'AOS' )  \n",
    "     \n",
    "aos = LFR.PyAOS(w,h,fovDegrees) \n",
    "\n",
    "\n",
    "set_folder = r'Enter path to the LFR folder'\n",
    "aos.loadDEM( os.path.join(set_folder,'zero_plane.obj'))\n",
    "\n",
    "###################### set the following parameters & hyperparameters before running the next steps ################################\n",
    "altitude_list = [43,41,39,37,35,36,38,40,42,44]\n",
    "drone_speed = 10\n",
    "NumberofDrones = 10  #(1 to 10)\n",
    "fov = 50\n",
    "rxthreshold = 0.9998\n",
    "dem_height = 33\n",
    "Scanning_direction = 0\n",
    "Scanning_direction_Waypoint_Distance = 2.0 #c3\n",
    "emptyblobthreshold = 0.0\n",
    "changing_to_linear_speed = 0.3 #c5\n",
    "local_fac = 1.0   #c1\n",
    "global_fac = 2.0   #c2  \n",
    "minimum_distance_btwn_drone = 4.2 #c4 \n",
    "distance_btwn_drones = minimum_distance_btwn_drone\n",
    "person=[0,10]  \n",
    "personorientation = 100\n",
    "compasscorrection = 0\n",
    "\n",
    "###### set the threshold before running the next steps###################################\n",
    "emptyblobthreshold = 220 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class evaluate_metric:\n",
    "    _aos = None\n",
    "    _fov = 22.815436217896945\n",
    "    _rx_threshold = 0.999\n",
    "    _debug = False\n",
    "    _x_off = 0.0\n",
    "    _y_off = 0.0\n",
    "    _f_ = None\n",
    "    _focalplane_height = 0.0\n",
    "    _compass_correction = 0.0\n",
    "    _integration_count = 0\n",
    "    _previous_img_mask = None\n",
    "    _previous_detection_pose = None\n",
    "    _prev_images = []\n",
    "    _prev_thermal_images = []\n",
    "    _current_thermal_images_list = []\n",
    "    _current_RGB_images_list = []\n",
    "    _current_center_camera_id = None\n",
    "    _current_leader_contour_area = None\n",
    "    \n",
    "    _calc_leader_current_integral = True\n",
    "\n",
    "    _prev_images_poses = []\n",
    "    _prev_blob_images = []\n",
    "\n",
    "    def __init__(self,aos_ptr,fieldofview,rx_threshold, dem_height, compasscorrection, debug_mode = False):\n",
    "        self._aos = aos_ptr\n",
    "        self._fov = fieldofview\n",
    "        self._rx_threshold = rx_threshold\n",
    "        self._focalplane_height = dem_height\n",
    "        self._compass_correction = compasscorrection\n",
    "        self._debug = debug_mode\n",
    "        self._integration_count = 0\n",
    "        if self._debug:\n",
    "            # build random function\n",
    "            xc, yc = self.get_mesh()\n",
    "            #np.random.seed(100)#int(time.time())\n",
    "            np.random.seed(int(time.time()))\n",
    "            z = np.random.rand(*xc.shape)*30-15 # -15...15\n",
    "            self._x_off = self._y_off = 0.0\n",
    "            # define the objective function\n",
    "            self._f_ = interpolate.RBFInterpolator(self.to_linear(xc, yc), z.ravel())\n",
    "\n",
    "    def set_rx_threshold(self, rx_threshold):\n",
    "        self._rx_threshold = rx_threshold\n",
    "\n",
    "    def get_rx_threshold(self):\n",
    "        return self._rx_threshold\n",
    "    \n",
    "    def set_focalplane_height(self, dem_height):\n",
    "        self._focalplane_height = dem_height\n",
    "\n",
    "    def get_focalplane_height(self):\n",
    "        return self._focalplane_height\n",
    "    \n",
    "    def set_fov(self, fieldofview):\n",
    "        self._fov = fieldofview\n",
    "\n",
    "    def get_fov(self):\n",
    "        return self._fov\n",
    "    \n",
    "    def set_compass_correction(self, compasscorrection):\n",
    "        self._compass_correction = compasscorrection\n",
    "\n",
    "    def get_compass_correction(self):\n",
    "        return self._compass_correction\n",
    "    \n",
    "\n",
    "\n",
    "    def f(self, x,y):\n",
    "        #global x_off,y_off\n",
    "        s=np.reshape(self._f_(np.stack([x.ravel(),y.ravel()], -1)), x.shape)\n",
    "        m=np.sin((x/50)* (3.14/2))*np.sin((y/50)* (3.14/2))\n",
    "        m[m < 0.8] = 0\n",
    "        m[m > 0.8] = 1\n",
    "        s=s*m\n",
    "        s[s == 0] = -15\n",
    "        return s     \n",
    "    def get_mesh(self,n=20): # meshsize\n",
    "        return np.meshgrid(np.linspace(0, 100, n),\n",
    "                       np.linspace(0, 100, n + 1))\n",
    "\n",
    "    def to_linear(self,x, y): \n",
    "        return np.stack([x.ravel(), y.ravel()], -1)\n",
    "\n",
    "    def divide_by_alpha(self,rimg2):\n",
    "        a = np.stack((rimg2[:,:,3],rimg2[:,:,3],rimg2[:,:,3]),axis=-1)\n",
    "        return rimg2[:,:,:3]/a\n",
    "\n",
    "    def pose_to_virtualcamera(self, vpose ):\n",
    "        vp = glm.mat4(*np.array(vpose).transpose().flatten())\n",
    "        #vp = vpose.copy()\n",
    "        ivp = glm.inverse(glm.transpose(vp))\n",
    "        #ivp = glm.inverse(vpose)\n",
    "        Posvec = glm.vec3(ivp[3])\n",
    "        Upvec = glm.vec3(ivp[1])\n",
    "        FrontVec = glm.vec3(ivp[2])\n",
    "        lookAt = glm.lookAt(Posvec, Posvec + FrontVec, Upvec)\n",
    "        cameraviewarr = np.asarray(lookAt)\n",
    "        #print(cameraviewarr)\n",
    "        return cameraviewarr\n",
    "\n",
    "    def detect_anomaly(self,single_images, confCoefficient):\n",
    "        bw_images_list = []\n",
    "        rx_images_list = []\n",
    "        print(\"confCoefficient\", confCoefficient)\n",
    "        for i in range(len(single_images)):\n",
    "            RGB_image = single_images[i]\n",
    "            rxScore = spectral.rx(RGB_image)\n",
    "            min_rx_score = np.min(rxScore)\n",
    "            max_rx_score = np.max(rxScore)\n",
    "            rxScore = img_as_float(rxScore)\n",
    "            rescaled_rx_score = ((rxScore - min_rx_score) / (max_rx_score - min_rx_score))\n",
    "            rescaled_rx_score_int = np.asarray(rescaled_rx_score*255,dtype=np.uint8)\n",
    "            count, bins_count = np.histogram(rescaled_rx_score_int, bins = 256)\n",
    "            # finding the PDF of the histogram using count values\n",
    "            pdf = count / np.prod(np.size(rescaled_rx_score_int)) \n",
    "            # using numpy np.cumsum to calculate the CDF\n",
    "            # We can also find using the PDF values by looping and adding\n",
    "            cdf = np.cumsum(pdf)\n",
    "            rxThreshold = [ n for n,i in enumerate(cdf) if i>confCoefficient ][1]\n",
    "            print ('RX Threshold: ' , rxThreshold)\n",
    "            rx_images_list.append(rxScore)\n",
    "            bw = rescaled_rx_score_int > rxThreshold\n",
    "            cv_bw = np.asarray(bw*255,dtype=np.uint8)\n",
    "            img = np.zeros((cv_bw.shape[0],cv_bw.shape[1],3),dtype=RGB_image.dtype)\n",
    "            img[:,:,0] = cv_bw\n",
    "            img[:,:,1] = cv_bw\n",
    "            img[:,:,2] = cv_bw\n",
    "            bw_images_list.append(img)\n",
    "        return bw_images_list,rx_images_list\n",
    "    \n",
    "    def project_images_to_all(self,aos, img_list, pose_list,fov,center_camera_index = None, project_images = False):\n",
    "        aos.clearViews()\n",
    "        proj_img_list = []\n",
    "        for i in range(len(img_list)):\n",
    "            aos.addView(img_list[i], pose_list[i], \"DEM BlobTrack\")\n",
    "        aos.setDEMTransform([0,0,self._focalplane_height])\n",
    "        for i in range(len(img_list)):\n",
    "            renderering_ids = []\n",
    "            if project_images:\n",
    "                renderering_ids.append(i)\n",
    "                if center_camera_index == None:\n",
    "                    for j in range(len(img_list)):\n",
    "                        cmr_proj = []\n",
    "                        img_renderering_ids = []\n",
    "                        img_renderering_ids.append(j)\n",
    "                        #proj_img = aos.render(self.pose_to_virtualcamera(aos.getPose(i)), fov, img_renderering_ids)\n",
    "                        proj_img = aos.render(self.pose_to_virtualcamera(pose_list[i]), fov, img_renderering_ids)\n",
    "                        tmp = self.divide_by_alpha(proj_img)\n",
    "                        cmr_proj.append(tmp)\n",
    "                    proj_img_list.append(cmr_proj)\n",
    "                else:\n",
    "                    proj_img = aos.render(self.pose_to_virtualcamera(pose_list[center_camera_index]), fov, renderering_ids)\n",
    "                    tmp = self.divide_by_alpha(proj_img)\n",
    "                    proj_img_list.append(tmp)\n",
    "            else:\n",
    "                if center_camera_index == None:\n",
    "                    proj_img = aos.render(self.pose_to_virtualcamera(pose_list[i]), fov, renderering_ids)\n",
    "                    tmp = self.divide_by_alpha(proj_img)\n",
    "                    proj_img_list.append(tmp)\n",
    "                else:\n",
    "                    if i == center_camera_index:\n",
    "                        proj_img = aos.render(self.pose_to_virtualcamera(pose_list[center_camera_index]), fov, renderering_ids)\n",
    "                        tmp = self.divide_by_alpha(proj_img)\n",
    "                        proj_img_list.append(tmp)\n",
    "        return proj_img_list\n",
    "\n",
    "    def find_center_camera_highest_projection(self,image_list):\n",
    "        max_contour_img_id = None\n",
    "        max_countour_list = []\n",
    "        max_countour_center_list = []\n",
    "        max_contour_bounding_rect_list = []\n",
    "        contour_img = np.zeros((image_list[0].shape[0],image_list[0].shape[1]))\n",
    "        ################For all Images calculate contours and find max###########################################\n",
    "        #######################contour in each images######################################################\n",
    "        for i in range(len(image_list)):\n",
    "            contours,hierarchy  = cv2.findContours(np.asarray(image_list[i][:,:,0],dtype=np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            max_countour = 0\n",
    "            max_countour_center = ()\n",
    "            max_contour_bounding_rect = ()\n",
    "            #print(i,len(contours))\n",
    "            for k in range(len(contours)):\n",
    "                contour_area = cv2.contourArea(contours[k])\n",
    "                x,y,w,h = cv2.boundingRect(contours[k])\n",
    "                #contour_area_list.append(contour_area)\n",
    "                if contour_area > max_countour:\n",
    "                    max_countour = contour_area\n",
    "                    M = cv2.moments(contours[k])\n",
    "                    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                    max_countour_center = (cX,cY)\n",
    "                    max_contour_bounding_rect = (x,y,w,h)\n",
    "            max_countour_list.append(max_countour)\n",
    "            max_countour_center_list.append(max_countour_center)\n",
    "            max_contour_bounding_rect_list.append(max_contour_bounding_rect)\n",
    "        ################For Image Indices with Highest Contour###########################################\n",
    "        #################If Two Image has same Contour length######################################################\n",
    "        #################than select one where blob is closer to center######################################################\n",
    "        print(\"Integral max_countour_list\", max_countour_list)\n",
    "        print(\"Integral max_countour_list\", max_countour_center_list)\n",
    "        max_indices = [index for index, item in enumerate(max_countour_list) if item == max(max_countour_list)]\n",
    "        if len(max_indices) > 1:\n",
    "            distance_center = 10000000\n",
    "            for i in range(len(max_indices)):\n",
    "                distance = math.sqrt(math.pow((max_countour_center_list[i][0] - 512),2)+ math.pow((max_countour_center_list[i][1] - 512),2))\n",
    "                if distance < distance_center:\n",
    "                    max_contour_img_id = max_indices[i]\n",
    "                    distance_center  = distance\n",
    "        else:\n",
    "            max_contour_img_id = max_indices[0]\n",
    "        ################Get Bounding box location of contour and create###########################################\n",
    "        ######################mask image with rect set to 255######################################################\n",
    "        rect = max_contour_bounding_rect_list[max_contour_img_id]\n",
    "        print(\"max_contour_img_id\", max_contour_img_id)\n",
    "        print(\"rect of bounding box\", rect)\n",
    "        contour_img[rect[1]:rect[1]+rect[3],rect[0]:rect[0]+rect[2]] = 255\n",
    "        center_img_max_contour  = max_countour_list[max_contour_img_id]\n",
    "        ################return center image with highest contour and ###########################################\n",
    "        ######################its corresponding mask image and ######################################################\n",
    "        ######################its corresponding contour area######################################################\n",
    "        return max_contour_img_id, contour_img, center_img_max_contour,rect\n",
    "    \n",
    "    def find_leader(self,single_proj_img, mask_img):\n",
    "        max_contour = 0\n",
    "        leader_id = None\n",
    "        ################For all Images calculate contours within the mask###########################################\n",
    "        #######################and find image with maximum contour######################################################\n",
    "        for i in range(len(single_proj_img)):\n",
    "            img = single_proj_img[i]\n",
    "            tmp_img = np.asarray(img[:,:,0],dtype=np.uint8)\n",
    "            tmp_mask_img = np.asarray(mask_img,dtype=np.uint8)\n",
    "            cnt_tmp_img = np.zeros((single_proj_img[i].shape[0],single_proj_img[i].shape[1]),dtype=np.uint8)\n",
    "            cv2.bitwise_and(tmp_img, tmp_mask_img, cnt_tmp_img)\n",
    "            contours,hierarchy  = cv2.findContours(np.asarray(cnt_tmp_img[:,:],dtype=np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            curr_img_max_contour = 0\n",
    "            for k in range(len(contours)):\n",
    "                contour_area = cv2.contourArea(contours[k])\n",
    "                if contour_area > curr_img_max_contour:\n",
    "                    curr_img_max_contour = contour_area\n",
    "            print(\"Single curr_img_max_contour\", i, curr_img_max_contour)\n",
    "            if curr_img_max_contour > max_contour:\n",
    "                max_contour = curr_img_max_contour\n",
    "                leader_id = i\n",
    "        ################return leader index and maximum contour size within the leader###########################################\n",
    "        #######################and find image with maximum contour######################################################\n",
    "        return leader_id, max_contour\n",
    "    \n",
    "    def find_leader_within_images(self,single_images,site_poses, fov = None, rxthreshold =  None, dem_height = None, compasscorrection = None ,pos = None):\n",
    "        if fov == None:\n",
    "            fov = self._fov\n",
    "        else:\n",
    "            self._fov = fov\n",
    "        if rxthreshold == None:\n",
    "            rxthreshold = self._rx_threshold\n",
    "        else:\n",
    "            self._rx_threshold = rxthreshold\n",
    "        if dem_height == None:\n",
    "            dem_height = self._focalplane_height\n",
    "        else :\n",
    "            self._focalplane_height = dem_height\n",
    "        if compasscorrection == None:\n",
    "            compasscorrection = self._compass_correction\n",
    "        else :\n",
    "            self._compass_correction = compasscorrection\n",
    "        if self._debug:\n",
    "            obj = self.f(pos[0], pos[1])\n",
    "            Leader_index = obj.argmax()\n",
    "            leader_contour = obj[Leader_index]\n",
    "        else :\n",
    "            self._current_thermal_images_list = []\n",
    "            self._current_RGB_images_list = []\n",
    "            if len(single_images)>=1:\n",
    "                no_channels = single_images[0].shape[2]\n",
    "                if no_channels > 3:\n",
    "                    for i in range(len(single_images)):\n",
    "                        img = single_images[i]\n",
    "                        rgb_img = img[:,:,0:3]\n",
    "                        thermal_img = np.zeros(rgb_img.shape,dtype = rgb_img.dtype)\n",
    "                        thermal_img[:,:,0] = img[:,:,3]\n",
    "                        thermal_img[:,:,1] = img[:,:,3]\n",
    "                        thermal_img[:,:,2] = img[:,:,3]\n",
    "                        self._current_RGB_images_list.append(rgb_img)\n",
    "                        self._current_thermal_images_list.append(thermal_img)\n",
    "                elif no_channels == 3:\n",
    "                    for i in range(len(single_images)):\n",
    "                        img = single_images[i]\n",
    "                        self._current_RGB_images_list.append(rgb_img)\n",
    "  \n",
    "            rgb_integral_images = self.project_images_to_all(self._aos, self._current_RGB_images_list, site_poses,fov,center_camera_index=None,project_images=False)\n",
    "            if len(self._current_thermal_images_list)>= 1:\n",
    "                thermal_integral_images = self.project_images_to_all(self._aos, self._current_thermal_images_list, site_poses,fov,center_camera_index=None,project_images=False)\n",
    "            ################################################################\n",
    "            ##############After Generating Blob Images############################\n",
    "            #########Set Each camera as virtual camera and ####################\n",
    "            ##############project all Rx_bw images###########################\n",
    "            #print(\"len of single images\", len(single_images))\n",
    "            #########First do Blob detection on all Single Images###########\n",
    "            blob_images,rx_images = self.detect_anomaly(single_images, confCoefficient = rxthreshold)\n",
    "            ###############REquired Images##########################################\n",
    "            tmp_blob_images = blob_images\n",
    "            tmp_rx_images = rx_images\n",
    "            ##############After Generating Blob Images############################\n",
    "            #########Set Each camera as virtual camera and ####################\n",
    "            ##############project all Rx_bw images###########################\n",
    "            proj_images = self.project_images_to_all(self._aos, blob_images, site_poses,fov,center_camera_index=None,project_images=False)\n",
    "            ##############After Generating integrated Blob Images############################\n",
    "            #########Find Which Image contains the Maximum Contour ####################\n",
    "            ##########and generate a Mask Image with the maximum contour###########################\n",
    "            center_camera_id, mask_img, center_camera_max_contour_area,rect = self.find_center_camera_highest_projection(proj_images)\n",
    "            self._current_center_camera_id = center_camera_id\n",
    "            #print(center_camera_id)  //debug\n",
    "            if self._calc_leader_current_integral == False:\n",
    "                #######################################################################\n",
    "                ##############After Finding the Center Camera############################\n",
    "                #########Find Projection of All images to this Camera####################\n",
    "                ########################################################################\n",
    "                single_proj_images = self.project_images_to_all(self._aos, blob_images, site_poses,fov,center_camera_index=center_camera_id,project_images=True)\n",
    "                ################################################################\n",
    "                ##############Now Find Leader############################\n",
    "                #########By Finding largest Contour in this Image####################\n",
    "                ###################################################################\n",
    "                Leader_index, leader_contour = self.find_leader(single_proj_images,mask_img)\n",
    "                leader_blob_image = tmp_blob_images[Leader_index]\n",
    "            else:\n",
    "                Leader_index = center_camera_id\n",
    "                leader_contour = center_camera_max_contour_area\n",
    "                leader_blob_image = proj_images[Leader_index]\n",
    "            \n",
    "            leader_rx_image = tmp_rx_images[Leader_index]\n",
    "            self._current_leader_contour_area = leader_contour\n",
    "            center_rx_integral_image  = np.asarray(proj_images[center_camera_id],dtype=np.uint8)\n",
    "            center_rgb_integral_image  = np.asarray(rgb_integral_images[center_camera_id],dtype=np.uint8)\n",
    "           \n",
    "            leader_unprojected_rx_image = np.asarray(blob_images[Leader_index],dtype=np.uint8)\n",
    "            center_thermal_integral_image = np.zeros((single_images[0].shape[0],single_images[0].shape[1],single_images[0].shape[2]),dtype=np.uint8)\n",
    "            if len(self._current_thermal_images_list)>= 1:\n",
    "                center_thermal_integral_image = np.asarray(thermal_integral_images[center_camera_id],dtype=np.uint8)\n",
    "                cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_thermal_integral.png'), center_thermal_integral_image)\n",
    "                cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_thermal_integral.png'), center_thermal_integral_image)\n",
    "          \n",
    "            cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+'_'+str(int(Leader_index))+'_'+str(rxthreshold)+ '_rxunprojected.png'), leader_unprojected_rx_image);  \n",
    "            cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_integral.png'), center_rgb_integral_image)\n",
    "            cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+'_'+str(int(center_camera_id))+'_'+str(int(center_camera_max_contour_area))+ '_rxintegral.png'), center_rx_integral_image)\n",
    "            cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_integral.png'), center_rgb_integral_image)\n",
    "            center_mask_img = np.asarray(mask_img,dtype=np.uint8)\n",
    "            cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+'_'+str(int(Leader_index))+'_'+str(int(leader_contour))+ '_rxintegralmask.png'), center_mask_img)\n",
    "        return Leader_index, leader_contour, center_mask_img, center_camera_id,leader_blob_image, leader_rx_image,rect\n",
    "    \n",
    "    def get_relevent_info(self,single_images,site_poses, fov = None, rxthreshold =  None, dem_height = None, compasscorrection = None , pos = None):\n",
    "        if fov == None:\n",
    "            fov = self._fov\n",
    "        else:\n",
    "            self._fov = fov\n",
    "        if rxthreshold == None:\n",
    "            rxthreshold = self._rx_threshold\n",
    "        else:\n",
    "            self._rx_threshold = rxthreshold\n",
    "        if dem_height == None:\n",
    "            dem_height = self._focalplane_height\n",
    "        else :\n",
    "            self._focalplane_height = dem_height\n",
    "        if compasscorrection == None:\n",
    "            compasscorrection = self._compass_correction\n",
    "        else :\n",
    "            self._compass_correction = compasscorrection\n",
    "        ################################################################\n",
    "        ##############After Generating Blob Images############################\n",
    "        #########Set Each camera as virtual camera and ####################\n",
    "        ##############project all Rx_bw images###########################\n",
    "        print(\"len of single images\", len(single_images))\n",
    "        rgb_integral_images = self.project_images_to_all(self._aos, single_images, site_poses,fov,center_camera_index=None,project_images=False)\n",
    "        #########First do Blob detection on all Single Images###########\n",
    "        blob_images,rx_images = self.detect_anomaly(single_images, confCoefficient = rxthreshold)\n",
    "        print(\"len of blob images\", len(blob_images))\n",
    "        for i in range(len(blob_images)):\n",
    "            cv2.imwrite(os.path.join( Live_Debug_Path,  str(i)+ '_blobimages_debug_blobthreshold.png'), np.asarray(blob_images[i],dtype=np.uint8))\n",
    "        ##############After Generating Blob Images############################\n",
    "        #########Set Each camera as virtual camera and ####################\n",
    "        ##############project all Rx_bw images###########################\n",
    "        proj_images = self.project_images_to_all(self._aos, blob_images, site_poses,fov,center_camera_index=None,project_images=False)\n",
    "        print(\"len of proj images\", len(proj_images))\n",
    "        for i in range(len(proj_images)):\n",
    "            cv2.imwrite(os.path.join( Live_Debug_Path,  str(i)+ '_integral_debug_blobthreshold.png'), np.asarray(proj_images[i],dtype=np.uint8))\n",
    "        ##############After Generating integrated Blob Images############################\n",
    "        #########Find Which Image contains the Maximum Contour ####################\n",
    "        ##########and generate a Mask Image with the maximum contour###########################\n",
    "        center_camera_id, mask_img, center_camera_max_contour_area,rect = self.find_center_camera_highest_projection(proj_images)\n",
    "        #print(center_camera_id)  //debug\n",
    "        if self._calc_leader_current_integral == False:\n",
    "            #######################################################################\n",
    "            ##############After Finding the Center Camera############################\n",
    "            #########Find Projection of All images to this Camera####################\n",
    "            ########################################################################\n",
    "            single_proj_images = self.project_images_to_all(self._aos, blob_images, site_poses,fov,center_camera_index=center_camera_id,project_images=True)\n",
    "            ################################################################\n",
    "            ##############Now Find Leader############################\n",
    "            #########By Finding largest Contour in this Image####################\n",
    "            ###################################################################\n",
    "            Leader_index, leader_contour = self.find_leader(single_proj_images,mask_img)\n",
    "            leader_rx_image = np.asarray(single_proj_images[Leader_index],dtype=np.uint8)\n",
    "        else:\n",
    "            Leader_index = center_camera_id\n",
    "            leader_contour = center_camera_max_contour_area\n",
    "            leader_rx_image = np.asarray(proj_images[Leader_index],dtype=np.uint8)\n",
    "\n",
    "\n",
    "        center_rgb_integral_image  = np.asarray(rgb_integral_images[center_camera_id],dtype=np.uint8)\n",
    "        \n",
    "        return center_rgb_integral_image, leader_rx_image, Leader_index, leader_contour\n",
    "        \n",
    "    \n",
    "    def should_add_image_integral(self,aos,integral_img,single_img,img_poses,fov = 22.815436217896945,rx_threshold = 0.998):\n",
    "        #########First do Blob detection on all Integral Image###########\n",
    "        blob_images,rx_images = self.detect_anomaly(integral_img, confCoefficient = rx_threshold)\n",
    "        ##############After Generating integrated Blob Images############################\n",
    "        #########Find Which Image contains the Maximum Contour ####################\n",
    "        ##########and generate a Mask Image with the maximum contour###########################\n",
    "        center_camera_id, mask_img, center_camera_max_contour_area,rect = self.find_center_camera_highest_projection(blob_images)\n",
    "        #print(center_camera_id)  //debug\n",
    "        future_integaral_img_list = []\n",
    "        future_integaral_img_list.append(integral_img)\n",
    "        future_integaral_img_list.append(single_img)\n",
    "        #######################################################################\n",
    "        ##############After Finding the Center Camera############################\n",
    "        #########Find Projection of All images to this Camera####################\n",
    "        ########################################################################\n",
    "        future_integaral_img = self.project_images_to_all(self._aos, future_integaral_img_list, img_poses,fov,center_camera_index=0,project_images=False)\n",
    "        ################################################################\n",
    "        ##############Now Find Leader############################\n",
    "        #########By Finding largest Contour in this Image####################\n",
    "        ###################################################################\n",
    "        center_camera_id, mask_img, future_integaral_img_max_contour_area = self.find_center_camera_highest_projection(future_integaral_img)\n",
    "        if (center_camera_max_contour_area >= future_integaral_img_max_contour_area ):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def integrate_informative_images_removefirst(self, single_images, single_poses, virtual_camera_pose, detection_mask = None, detection_pose = None):  #working use this\n",
    "        ############generate blob images --- can be optimized later to remove anomaly detection again and again####################################\n",
    "        blob_images,rx_images = self.detect_anomaly(single_images, confCoefficient = self._rx_threshold)\n",
    "        self._aos.clearViews()\n",
    "        prev_img_max_contour = 0\n",
    "        gen_integral_blob_img = np.zeros((blob_images[0].shape[0],blob_images[0].shape[1]),dtype=np.uint8)\n",
    "        ##########################Check if previous mask is there if not if there is new mask use it########################################\n",
    "        if detection_mask is None:\n",
    "            current_detection_mask = self._previous_img_mask\n",
    "            current_detection_pose = self._previous_detection_pose\n",
    "        else:\n",
    "            current_detection_mask = detection_mask\n",
    "            current_detection_pose = detection_pose\n",
    "            self._previous_img_mask = detection_mask\n",
    "            self._previous_detection_pose = detection_pose\n",
    "        if type(current_detection_mask) is np.ndarray :\n",
    "            ##########################Project the mask to current virtual camera########################################\n",
    "            self._aos.addView(current_detection_mask, current_detection_pose, \"Detection Mask\")\n",
    "            img_renderering_ids = []\n",
    "            self._aos.setDEMTransform([0,0,self._focalplane_height])\n",
    "            #aos.setPoseCorrectionall(1,[0,0,0], [0,0, self._compass_correction])\n",
    "            tmp_projected_detection_mask = self._aos.render(self.pose_to_virtualcamera(single_poses[self._current_center_camera_id]), self._fov, img_renderering_ids)\n",
    "            projected_detection_mask = self.divide_by_alpha(tmp_projected_detection_mask)\n",
    "            self._aos.clearViews()\n",
    "            prev_img_max_contour = 0\n",
    "            for i in range(len(single_images)):\n",
    "                self._aos.addView(blob_images[i], single_poses[i], \"DEM BlobTrack\")\n",
    "            img_renderering_ids = []\n",
    "            self._aos.setDEMTransform([0,0,self._focalplane_height])\n",
    "            #aos.setPoseCorrectionall(len(self._prev_blob_images),[0,0,0], [0,0, self._compass_correction])\n",
    "            tmp_integ__blob_img = self._aos.render(self.pose_to_virtualcamera(single_poses[self._current_center_camera_id]), self._fov, img_renderering_ids)\n",
    "            integ__blob_img = self.divide_by_alpha(tmp_integ__blob_img)\n",
    "            tmp_img = np.asarray(integ__blob_img[:,:,0],dtype=np.uint8)\n",
    "            tmp_mask_img = np.asarray(projected_detection_mask[:,:,0],dtype=np.uint8)\n",
    "            curr_tmp_img = np.zeros((tmp_img.shape[0],tmp_img.shape[1]),dtype=np.uint8)\n",
    "            cv2.bitwise_and(tmp_img, tmp_mask_img, curr_tmp_img)\n",
    "            gen_integral_blob_img = np.asarray(curr_tmp_img[:,:],dtype=np.uint8)\n",
    "            contours,hierarchy  = cv2.findContours(np.asarray(curr_tmp_img[:,:],dtype=np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            for k in range(len(contours)):\n",
    "                contour_area = cv2.contourArea(contours[k])\n",
    "                if contour_area > prev_img_max_contour:\n",
    "                    prev_img_max_contour = contour_area\n",
    "            print(\"prev_contour_area with current n images\",prev_img_max_contour)\n",
    "            self._aos.clearViews()\n",
    "            for i in range(len(single_images)):\n",
    "                self._prev_blob_images.append(blob_images[i])\n",
    "                self._prev_images.append(self._current_RGB_images_list[i])\n",
    "                if len(self._current_thermal_images_list)>= 1:\n",
    "                    self._prev_thermal_images.append(self._current_thermal_images_list[i])\n",
    "                self._prev_images_poses.append(single_poses[i])\n",
    "            ##########################If previous images exist than find best contour of prev integral using previous blob images########################################\n",
    "            if len(self._prev_images) != 0:\n",
    "                img_renderering_ids = []\n",
    "                for i in range(len(self._prev_images)):\n",
    "                    self._aos.addView(self._prev_blob_images[i], self._prev_images_poses[i], \"DEM BlobTrack\")\n",
    "                    img_renderering_ids.append(i)\n",
    "                self._aos.setDEMTransform([0,0,self._focalplane_height])\n",
    "                #aos.setPoseCorrectionall(len(self._prev_blob_images),[0,0,0], [0,0, self._compass_correction])\n",
    "                tmp_prev_integ__blob_img = self._aos.render(self.pose_to_virtualcamera(single_poses[self._current_center_camera_id]), self._fov, img_renderering_ids)\n",
    "                prev_integ__blob_img = self.divide_by_alpha(tmp_prev_integ__blob_img)\n",
    "                tmp_img = np.asarray(prev_integ__blob_img[:,:,0],dtype=np.uint8)\n",
    "                tmp_mask_img = np.asarray(projected_detection_mask[:,:,0],dtype=np.uint8)\n",
    "                prev_tmp_img = np.zeros((tmp_img.shape[0],tmp_img.shape[1]),dtype=np.uint8)\n",
    "                cv2.bitwise_and(tmp_img, tmp_mask_img, prev_tmp_img)\n",
    "                #gen_integral_blob_img = np.asarray(prev_tmp_img[:,:],dtype=np.uint8)\n",
    "                contours,hierarchy  = cv2.findContours(np.asarray(prev_tmp_img[:,:],dtype=np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                for k in range(len(contours)):\n",
    "                    contour_area = cv2.contourArea(contours[k])\n",
    "                    print(\"contour_area_with All images\",contour_area)\n",
    "                    if contour_area > prev_img_max_contour:\n",
    "                        prev_img_max_contour = contour_area\n",
    "            print(\"prev_contour_area\",prev_img_max_contour)\n",
    "            ##########################Check if adding image to the rendering improve integral or not########################################\n",
    "            added_prev_img = True\n",
    "            remove_list = []\n",
    "            for i in range(len(self._prev_images)):\n",
    "                img_renderering_ids = []\n",
    "                for j in range(len(self._prev_images)):\n",
    "                    if j in remove_list:\n",
    "                        k = 10\n",
    "                    else:\n",
    "                        if j == i:\n",
    "                            k = 10\n",
    "                        else:\n",
    "                            img_renderering_ids.append(j)\n",
    "                self._aos.setDEMTransform([0,0,self._focalplane_height])\n",
    "                #aos.setPoseCorrectionall(self._aos.getViews(),[0,0,0], [0,0, self._compass_correction])\n",
    "                tmp_tmp_integral_img = self._aos.render(self.pose_to_virtualcamera(single_poses[self._current_center_camera_id]), self._fov, img_renderering_ids)\n",
    "                tmp_integral_img = self.divide_by_alpha(tmp_tmp_integral_img)\n",
    "                tmp_img = np.asarray(tmp_integral_img[:,:,0],dtype=np.uint8)\n",
    "                tmp_mask_img = np.asarray(projected_detection_mask[:,:,0],dtype=np.uint8)\n",
    "                curr_tmp_img = np.zeros((tmp_img.shape[0],tmp_img.shape[1]),dtype=np.uint8)\n",
    "                cv2.bitwise_and(tmp_img, tmp_mask_img, curr_tmp_img)\n",
    "                contours,hierarchy  = cv2.findContours(np.asarray(curr_tmp_img[:,:],dtype=np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                remove_img = False\n",
    "                current_max_contour = 0\n",
    "                for k in range(len(contours)):\n",
    "                    contour_area = cv2.contourArea(contours[k])\n",
    "                    #print(\"curr_contour_area and Image Added\",prev_img_max_contour)\n",
    "                    if contour_area > current_max_contour:\n",
    "                        current_max_contour = contour_area\n",
    "                        #print(\"curr_contour_area and Image Added\",prev_img_max_contour)\n",
    "                if current_max_contour < prev_img_max_contour:\n",
    "                    remove_img = False\n",
    "                else:\n",
    "                    remove_img = True\n",
    "                if remove_img:\n",
    "                    print(\"removed images\")\n",
    "                    added_prev_img = True\n",
    "                    remove_list.append(i)\n",
    "                    #gen_integral_blob_img = np.asarray(curr_tmp_img[:,:],dtype=np.uint8)\n",
    "                else :\n",
    "                    print(\"Do not remove images\")\n",
    "                    added_prev_img = False       \n",
    "        else:\n",
    "            print(\"same as integral image\")\n",
    "            rgb_integral_images = self.project_images_to_all(self._aos, self._current_RGB_images_list, single_poses,self._fov,center_camera_index=None,project_images=False)\n",
    "            if len(self._current_thermal_images_list)>= 1:\n",
    "                thermal_integral_images = self.project_images_to_all(self._aos, self._current_thermal_images_list, single_poses,self._fov,center_camera_index=None,project_images=False)\n",
    "                thermal_integral_img = np.asarray(thermal_integral_images[self._current_center_camera_id],dtype=np.uint8)\n",
    "                cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_gen_thermal_integral.png'), thermal_integral_img)\n",
    "                cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_thermal_integral.png'), thermal_integral_img)\n",
    "            rgb_integral_img  = np.asarray(rgb_integral_images[self._current_center_camera_id],dtype=np.uint8)\n",
    "            cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_gen_integral.png'), rgb_integral_img)  \n",
    "            cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_integral.png'), rgb_integral_img) \n",
    "\n",
    "        self._aos.clearViews()\n",
    "        len_info = []\n",
    "        len_info.append(str(len(self._prev_images)-len(remove_list)) + '\\n')\n",
    "        with open(os.path.join(Live_Debug_Path,'History_Info.txt'), 'a') as f:\n",
    "            f.writelines('\\n'.join(len_info))\n",
    "        \n",
    "        print(len(self._prev_images))\n",
    "        print(len(remove_list))\n",
    "        print(remove_list)\n",
    "        if len(self._prev_images) :\n",
    "            for i in range(len(self._prev_images)):\n",
    "                if i in remove_list:\n",
    "                    k = 10\n",
    "                else:\n",
    "                    self._aos.addView(self._prev_blob_images[i], self._prev_images_poses[i], \"DEM BlobTrack\")\n",
    "            img_renderering_ids = []\n",
    "            self._aos.setDEMTransform([0,0,self._focalplane_height])\n",
    "            tmp_tmp_integral_img = self._aos.render(self.pose_to_virtualcamera(single_poses[self._current_center_camera_id]), self._fov, img_renderering_ids)\n",
    "            tmp_integral_img = self.divide_by_alpha(tmp_tmp_integral_img)\n",
    "            tmp_img = np.asarray(tmp_integral_img[:,:,0],dtype=np.uint8)\n",
    "            tmp_mask_img = np.asarray(projected_detection_mask[:,:,0],dtype=np.uint8)\n",
    "            curr_tmp_img = np.zeros((tmp_img.shape[0],tmp_img.shape[1]),dtype=np.uint8)\n",
    "            cv2.bitwise_and(tmp_img, tmp_mask_img, curr_tmp_img)\n",
    "            gen_integral_blob_img = np.asarray(curr_tmp_img[:,:],dtype=np.uint8)\n",
    "            contours,hierarchy  = cv2.findContours(np.asarray(curr_tmp_img[:,:],dtype=np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            current_max_contour = 0\n",
    "            for k in range(len(contours)):\n",
    "                contour_area = cv2.contourArea(contours[k])\n",
    "                if contour_area > current_max_contour:\n",
    "                    current_max_contour = contour_area\n",
    "            print(\"curr_contour_area after removing images\",current_max_contour)\n",
    "            #aos.setPoseCorrectionall(len(self._prev_blob_images),[0,0,0], [0,0, self._compass_correction])\n",
    "            #tmp_rgb_integral_img = self._aos.render(self.pose_to_virtualcamera(virtual_camera_pose), self._fov, img_renderering_ids) ## edited in oct\n",
    "            # tmp_rgb_integral_img = self._aos.render(self.pose_to_virtualcamera(single_poses[self._current_center_camera_id]), self._fov, img_renderering_ids)\n",
    "            # rgb_integral_img = self.divide_by_alpha(tmp_rgb_integral_img)\n",
    "            self._aos.clearViews()\n",
    "            for i in range(len(self._prev_images)):\n",
    "                if i in remove_list:\n",
    "                    k = 10\n",
    "                else:\n",
    "                    self._aos.addView(self._prev_images[i], self._prev_images_poses[i], \"DEM BlobTrack\")\n",
    "            img_renderering_ids = []\n",
    "            self._aos.setDEMTransform([0,0,self._focalplane_height])\n",
    "            #aos.setPoseCorrectionall(len(self._prev_blob_images),[0,0,0], [0,0, self._compass_correction])\n",
    "            #tmp_rgb_integral_img = self._aos.render(self.pose_to_virtualcamera(virtual_camera_pose), self._fov, img_renderering_ids) ## edited in oct\n",
    "            tmp_rgb_integral_img = self._aos.render(self.pose_to_virtualcamera(single_poses[self._current_center_camera_id]), self._fov, img_renderering_ids)\n",
    "            rgb_integral_img = self.divide_by_alpha(tmp_rgb_integral_img)\n",
    "            #datasets_folder_live_debug= os.path.join( r\"E:\\Droneswarms_Feb_clientserverdevelopment\\live_debug\" )\n",
    "            #cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_integral.jpg'), rgb_integral_img);\n",
    "            cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_gen_integral.png'), rgb_integral_img)\n",
    "            cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_integral.png'), rgb_integral_img)\n",
    "            if len(self._current_thermal_images_list)>= 1:\n",
    "                self._aos.clearViews()\n",
    "                for i in range(len(self._prev_thermal_images)):\n",
    "                    if i in remove_list:\n",
    "                        k = 10\n",
    "                    else:\n",
    "                        self._aos.addView(self._prev_thermal_images[i], self._prev_images_poses[i], \"DEM BlobTrack\")\n",
    "                img_renderering_ids = []\n",
    "                self._aos.setDEMTransform([0,0,self._focalplane_height])\n",
    "                ##tmp_thermal_integral_img = self._aos.render(self.pose_to_virtualcamera(virtual_camera_pose), self._fov, img_renderering_ids) ##edited in oct\n",
    "                tmp_thermal_integral_img = self._aos.render(self.pose_to_virtualcamera(single_poses[self._current_center_camera_id]), self._fov, img_renderering_ids)\n",
    "                thermal_integral_img = self.divide_by_alpha(tmp_thermal_integral_img)\n",
    "                #cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_integral.jpg'), rgb_integral_img);\n",
    "                cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_gen_thermal_integral.png'), thermal_integral_img)\n",
    "                cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_thermal_integral.png'), thermal_integral_img)\n",
    "        else :\n",
    "            print(\"same as integral image\")\n",
    "            rgb_integral_images = self.project_images_to_all(self._aos, self._current_RGB_images_list, single_poses,self._fov,center_camera_index=None,project_images=False)\n",
    "            if len(self._current_thermal_images_list)>= 1:\n",
    "                thermal_integral_images = self.project_images_to_all(self._aos, self._current_thermal_images_list, single_poses,self._fov,center_camera_index=None,project_images=False)\n",
    "                thermal_integral_img = np.asarray(thermal_integral_images[self._current_center_camera_id],dtype=np.uint8)\n",
    "                cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_gen_thermal_integral.png'), thermal_integral_img)\n",
    "                cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_thermal_integral.png'), thermal_integral_img)\n",
    "            rgb_integral_img  = np.asarray(rgb_integral_images[self._current_center_camera_id],dtype=np.uint8)\n",
    "            cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_gen_integral.png'), rgb_integral_img) \n",
    "            cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_integral.png'), rgb_integral_img) \n",
    "        self._integration_count = self._integration_count + 1\n",
    "        return rgb_integral_img, prev_img_max_contour,gen_integral_blob_img\n",
    "\n",
    "    def integrate_informative_images_all(self, single_images, single_poses, virtual_camera_pose, detection_mask = None, detection_pose = None):\n",
    "        ############generate blob images --- can be optimized later to remove anomaly detection again and again####################################\n",
    "        blob_images,rx_images = self.detect_anomaly(single_images, confCoefficient = self._rx_threshold)\n",
    "        self._aos.clearViews()\n",
    "        prev_img_max_contour = 0\n",
    "        gen_integral_blob_img = np.zeros((blob_images[0].shape[0],blob_images[0].shape[1]),dtype=np.uint8)\n",
    "        integrate_rgb_images = []\n",
    "        integrate_thermal_images = []\n",
    "        integrate_blob_images = []\n",
    "        integrate_poses = []\n",
    "        ##########################Check if previous mask is there if not if there is new mask use it########################################\n",
    "        if detection_mask is None:\n",
    "            current_detection_mask = self._previous_img_mask\n",
    "            current_detection_pose = self._previous_detection_pose\n",
    "        else:\n",
    "            current_detection_mask = detection_mask\n",
    "            current_detection_pose = detection_pose\n",
    "            self._previous_img_mask = detection_mask\n",
    "            self._previous_detection_pose = detection_pose\n",
    "        if type(current_detection_mask) is np.ndarray :\n",
    "            ##########################Project the mask to current virtual camera########################################\n",
    "            self._aos.addView(current_detection_mask, current_detection_pose, \"Detection Mask\")\n",
    "            img_renderering_ids = []\n",
    "            self._aos.setDEMTransform([0,0,self._focalplane_height])\n",
    "            tmp_projected_detection_mask = self._aos.render(self.pose_to_virtualcamera(single_poses[self._current_center_camera_id]), self._fov, img_renderering_ids)\n",
    "            projected_detection_mask = self.divide_by_alpha(tmp_projected_detection_mask)\n",
    "            self._aos.clearViews()\n",
    "            prev_img_max_contour = 0\n",
    "            # ##########################If previous images exist than find best contour of prev integral using previous blob images########################################\n",
    "            # if len(self._prev_images) != 0:\n",
    "            #     for i in range(len(self._prev_images)):\n",
    "            #         self._aos.addView(self._prev_blob_images[i], self._prev_images_poses[i], \"DEM BlobTrack\")\n",
    "            #     img_renderering_ids = []\n",
    "            #     self._aos.setDEMTransform([0,0,self._focalplane_height])\n",
    "            #     tmp_prev_integ__blob_img = self._aos.render(self.pose_to_virtualcamera(single_poses[self._current_center_camera_id]), self._fov, img_renderering_ids)\n",
    "            #     prev_integ__blob_img = self.divide_by_alpha(tmp_prev_integ__blob_img)\n",
    "            #     tmp_img = np.asarray(prev_integ__blob_img[:,:,0],dtype=np.uint8)\n",
    "            #     tmp_mask_img = np.asarray(projected_detection_mask[:,:,0],dtype=np.uint8)\n",
    "            #     prev_tmp_img = np.zeros((tmp_img.shape[0],tmp_img.shape[1]),dtype=np.uint8)\n",
    "            #     cv2.bitwise_and(tmp_img, tmp_mask_img, prev_tmp_img)\n",
    "            #     gen_integral_blob_img = np.asarray(prev_tmp_img[:,:],dtype=np.uint8)\n",
    "            #     contours,hierarchy  = cv2.findContours(np.asarray(prev_tmp_img[:,:],dtype=np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            #     for k in range(len(contours)):\n",
    "            #         contour_area = cv2.contourArea(contours[k])\n",
    "            #         if contour_area > prev_img_max_contour:\n",
    "            #             prev_img_max_contour = contour_area\n",
    "            # print(\"prev_contour_area\",prev_img_max_contour)\n",
    "            if len(self._prev_images) != 0:\n",
    "                for i in range(len(single_images)):\n",
    "                    self._prev_blob_images.append(blob_images[i])\n",
    "                    self._prev_images.append(self._current_RGB_images_list[i])\n",
    "                    if len(self._current_thermal_images_list)>= 1:\n",
    "                        self._prev_thermal_images.append(self._current_thermal_images_list[i])\n",
    "                    self._prev_images_poses.append(single_poses[i])\n",
    "            ##########################Check if adding image to the rendering improve integral or not########################################\n",
    "            added_prev_img = True\n",
    "            for i in range(len(self._prev_images)):\n",
    "                if added_prev_img:\n",
    "                    print(\"Added View\")\n",
    "                    self._aos.addView(self._prev_blob_images[i], self._prev_images_poses[i], \"DEM BlobTrack\")\n",
    "                else:\n",
    "                    print(\"Replaced View\")\n",
    "                    self._aos.replaceView(self._aos.getViews()-1,self._prev_blob_images[i], self._prev_images_poses[i], \"DEM BlobTrack\")\n",
    "                img_renderering_ids = []\n",
    "                self._aos.setDEMTransform([0,0,self._focalplane_height])\n",
    "                #aos.setPoseCorrectionall(self._aos.getViews(),[0,0,0], [0,0, self._compass_correction])\n",
    "                tmp_tmp_integral_img = self._aos.render(self.pose_to_virtualcamera(single_poses[self._current_center_camera_id]), self._fov, img_renderering_ids)\n",
    "                tmp_integral_img = self.divide_by_alpha(tmp_tmp_integral_img)\n",
    "                tmp_img = np.asarray(tmp_integral_img[:,:,0],dtype=np.uint8)\n",
    "                tmp_mask_img = np.asarray(projected_detection_mask[:,:,0],dtype=np.uint8)\n",
    "                curr_tmp_img = np.zeros((tmp_img.shape[0],tmp_img.shape[1]),dtype=np.uint8)\n",
    "                cv2.bitwise_and(tmp_img, tmp_mask_img, curr_tmp_img)\n",
    "                contours,hierarchy  = cv2.findContours(np.asarray(curr_tmp_img[:,:],dtype=np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                add_img = False\n",
    "                for k in range(len(contours)):\n",
    "                    contour_area = cv2.contourArea(contours[k])\n",
    "                    print(\"curr_contour_area and Image Added\",prev_img_max_contour)\n",
    "                    if contour_area > prev_img_max_contour:\n",
    "                        prev_img_max_contour = contour_area\n",
    "                        print(\"curr_contour_area and Image Added\",prev_img_max_contour)\n",
    "                        add_img = True\n",
    "                if add_img:\n",
    "                    print(\"Added to Prev List\")\n",
    "                    added_prev_img = True\n",
    "                    gen_integral_blob_img = np.asarray(curr_tmp_img[:,:],dtype=np.uint8)\n",
    "                    integrate_blob_images.append(self._prev_blob_images[i])\n",
    "                    integrate_rgb_images.append(self._prev_images[i])\n",
    "                    if len(self._current_thermal_images_list)>= 1:\n",
    "                        integrate_thermal_images.append(self._prev_thermal_images[i])\n",
    "                    integrate_poses.append(self._prev_images_poses[i])\n",
    "                else :\n",
    "                    print(\"Do not Add to Prev List\")\n",
    "                    added_prev_img = False       \n",
    "        else:\n",
    "            print(\"same as integral image\")\n",
    "            rgb_integral_images = self.project_images_to_all(self._aos, self._current_RGB_images_list, single_poses,self._fov,center_camera_index=None,project_images=False)\n",
    "            if len(self._current_thermal_images_list)>= 1:\n",
    "                thermal_integral_images = self.project_images_to_all(self._aos, self._current_thermal_images_list, single_poses,self._fov,center_camera_index=None,project_images=False)\n",
    "                thermal_integral_img = np.asarray(thermal_integral_images[self._current_center_camera_id],dtype=np.uint8)\n",
    "                cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_gen_thermal_integral.png'), thermal_integral_img)\n",
    "                cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_thermal_integral.png'), thermal_integral_img)\n",
    "            rgb_integral_img  = np.asarray(rgb_integral_images[self._current_center_camera_id],dtype=np.uint8)\n",
    "            cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_gen_integral.png'), rgb_integral_img)  \n",
    "            cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_integral.png'), rgb_integral_img) \n",
    "        if self._current_leader_contour_area > prev_img_max_contour:\n",
    "            integrate_rgb_images = []\n",
    "            integrate_thermal_images = []\n",
    "            integrate_blob_images = []\n",
    "            integrate_poses = []\n",
    "            for i in range(len(single_images)):\n",
    "                integrate_blob_images.append(blob_images[i])\n",
    "                integrate_rgb_images.append(self._current_RGB_images_list[i])\n",
    "                if len(self._current_thermal_images_list)>= 1:\n",
    "                    integrate_thermal_images.append(self._current_thermal_images_list[i])\n",
    "                integrate_poses.append(single_poses[i])\n",
    "\n",
    "\n",
    "        self._aos.clearViews()\n",
    "        len_info = []\n",
    "        len_info.append(str(len(integrate_rgb_images)) + '\\n')\n",
    "        with open(os.path.join(Live_Debug_Path,'History_Info.txt'), 'a') as f:\n",
    "            f.writelines('\\n'.join(len_info))\n",
    "        \n",
    "        print(len(integrate_rgb_images))\n",
    "        if len(integrate_rgb_images) :\n",
    "            for i in range(len(integrate_rgb_images)):\n",
    "                    self._aos.addView(integrate_rgb_images[i], integrate_poses[i], \"DEM BlobTrack\")\n",
    "            img_renderering_ids = []\n",
    "            self._aos.setDEMTransform([0,0,self._focalplane_height])\n",
    "            tmp_rgb_integral_img = self._aos.render(self.pose_to_virtualcamera(single_poses[self._current_center_camera_id]), self._fov, img_renderering_ids)\n",
    "            rgb_integral_img = self.divide_by_alpha(tmp_rgb_integral_img)\n",
    "            cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_gen_integral.png'), rgb_integral_img)\n",
    "            cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_integral.png'), rgb_integral_img)\n",
    "            if len(self._current_thermal_images_list)>= 1:\n",
    "                self._aos.clearViews()\n",
    "                for i in range(len(integrate_thermal_images)):\n",
    "                    self._aos.addView(integrate_thermal_images[i], integrate_poses[i], \"DEM BlobTrack\")\n",
    "                img_renderering_ids = []\n",
    "                self._aos.setDEMTransform([0,0,self._focalplane_height])\n",
    "                tmp_thermal_integral_img = self._aos.render(self.pose_to_virtualcamera(single_poses[self._current_center_camera_id]), self._fov, img_renderering_ids)\n",
    "                thermal_integral_img = self.divide_by_alpha(tmp_thermal_integral_img)\n",
    "                cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_gen_thermal_integral.png'), thermal_integral_img)\n",
    "                cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_thermal_integral.png'), thermal_integral_img)\n",
    "            self._aos.clearViews()\n",
    "            for i in range(len(integrate_blob_images)):\n",
    "                self._aos.addView(integrate_blob_images[i], integrate_poses[i], \"DEM BlobTrack\")\n",
    "            img_renderering_ids = []\n",
    "            self._aos.setDEMTransform([0,0,self._focalplane_height])\n",
    "            #aos.setPoseCorrectionall(self._aos.getViews(),[0,0,0], [0,0, self._compass_correction])\n",
    "            tmp_tmp_integral_img = self._aos.render(self.pose_to_virtualcamera(single_poses[self._current_center_camera_id]), self._fov, img_renderering_ids)\n",
    "            tmp_integral_img = self.divide_by_alpha(tmp_tmp_integral_img)\n",
    "            tmp_img = np.asarray(tmp_integral_img[:,:,0],dtype=np.uint8)\n",
    "            tmp_mask_img = np.asarray(projected_detection_mask[:,:,0],dtype=np.uint8)\n",
    "            curr_tmp_img = np.zeros((tmp_img.shape[0],tmp_img.shape[1]),dtype=np.uint8)\n",
    "            cv2.bitwise_and(tmp_img, tmp_mask_img, curr_tmp_img)\n",
    "            gen_integral_blob_img = np.asarray(curr_tmp_img[:,:],dtype=np.uint8)\n",
    "        else :\n",
    "            print(\"same as integral image\")\n",
    "            rgb_integral_images = self.project_images_to_all(self._aos, self._current_RGB_images_list, single_poses,self._fov,center_camera_index=None,project_images=False)\n",
    "            if len(self._current_thermal_images_list)>= 1:\n",
    "                thermal_integral_images = self.project_images_to_all(self._aos, self._current_thermal_images_list, single_poses,self._fov,center_camera_index=None,project_images=False)\n",
    "                thermal_integral_img = np.asarray(thermal_integral_images[self._current_center_camera_id],dtype=np.uint8)\n",
    "                cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_gen_thermal_integral.png'), thermal_integral_img)\n",
    "                cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_thermal_integral.png'), thermal_integral_img)\n",
    "            rgb_integral_img  = np.asarray(rgb_integral_images[self._current_center_camera_id],dtype=np.uint8)\n",
    "            cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_gen_integral.png'), rgb_integral_img) \n",
    "            cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_integral.png'), rgb_integral_img) \n",
    "        self._integration_count = self._integration_count + 1\n",
    "        return rgb_integral_img, prev_img_max_contour,gen_integral_blob_img\n",
    "\n",
    "    def integrate_informative_images(self, single_images, single_poses, virtual_camera_pose, detection_mask = None, detection_pose = None):\n",
    "        ############generate blob images --- can be optimized later to remove anomaly detection again and again####################################\n",
    "        blob_images,rx_images = self.detect_anomaly(single_images, confCoefficient = self._rx_threshold)\n",
    "        self._aos.clearViews()\n",
    "        prev_img_max_contour = 0\n",
    "        gen_integral_blob_img = np.zeros((blob_images[0].shape[0],blob_images[0].shape[1]),dtype=np.uint8)\n",
    "        ##########################Check if previous mask is there if not if there is new mask use it########################################\n",
    "        if detection_mask is None:\n",
    "            current_detection_mask = self._previous_img_mask\n",
    "            current_detection_pose = self._previous_detection_pose\n",
    "        else:\n",
    "            current_detection_mask = detection_mask\n",
    "            current_detection_pose = detection_pose\n",
    "            self._previous_img_mask = detection_mask\n",
    "            self._previous_detection_pose = detection_pose\n",
    "        if type(current_detection_mask) is np.ndarray :\n",
    "            ##########################Project the mask to current virtual camera########################################\n",
    "            self._aos.addView(current_detection_mask, current_detection_pose, \"Detection Mask\")\n",
    "            img_renderering_ids = []\n",
    "            self._aos.setDEMTransform([0,0,self._focalplane_height])\n",
    "            tmp_projected_detection_mask = self._aos.render(self.pose_to_virtualcamera(single_poses[self._current_center_camera_id]), self._fov, img_renderering_ids)\n",
    "            projected_detection_mask = self.divide_by_alpha(tmp_projected_detection_mask)\n",
    "            self._aos.clearViews()\n",
    "            prev_img_max_contour = 0\n",
    "            ##########################If previous images exist than find best contour of prev integral using previous blob images########################################\n",
    "            if len(self._prev_images) != 0:\n",
    "                for i in range(len(self._prev_images)):\n",
    "                    self._aos.addView(self._prev_blob_images[i], self._prev_images_poses[i], \"DEM BlobTrack\")\n",
    "                img_renderering_ids = []\n",
    "                self._aos.setDEMTransform([0,0,self._focalplane_height])\n",
    "                tmp_prev_integ__blob_img = self._aos.render(self.pose_to_virtualcamera(single_poses[self._current_center_camera_id]), self._fov, img_renderering_ids)\n",
    "                prev_integ__blob_img = self.divide_by_alpha(tmp_prev_integ__blob_img)\n",
    "                tmp_img = np.asarray(prev_integ__blob_img[:,:,0],dtype=np.uint8)\n",
    "                tmp_mask_img = np.asarray(projected_detection_mask[:,:,0],dtype=np.uint8)\n",
    "                prev_tmp_img = np.zeros((tmp_img.shape[0],tmp_img.shape[1]),dtype=np.uint8)\n",
    "                cv2.bitwise_and(tmp_img, tmp_mask_img, prev_tmp_img)\n",
    "                gen_integral_blob_img = np.asarray(prev_tmp_img[:,:],dtype=np.uint8)\n",
    "                contours,hierarchy  = cv2.findContours(np.asarray(prev_tmp_img[:,:],dtype=np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                for k in range(len(contours)):\n",
    "                    contour_area = cv2.contourArea(contours[k])\n",
    "                    if contour_area > prev_img_max_contour:\n",
    "                        prev_img_max_contour = contour_area\n",
    "            print(\"prev_contour_area\",prev_img_max_contour)\n",
    "            ##########################Check if adding image to the rendering improve integral or not########################################\n",
    "            added_prev_img = True\n",
    "            for i in range(len(single_images)):\n",
    "                if added_prev_img:\n",
    "                    print(\"Added View\")\n",
    "                    self._aos.addView(blob_images[i], single_poses[i], \"DEM BlobTrack\")\n",
    "                else:\n",
    "                    print(\"Replaced View\")\n",
    "                    self._aos.replaceView(self._aos.getViews()-1,blob_images[i], single_poses[i], \"DEM BlobTrack\")\n",
    "                img_renderering_ids = []\n",
    "                self._aos.setDEMTransform([0,0,self._focalplane_height])\n",
    "                #aos.setPoseCorrectionall(self._aos.getViews(),[0,0,0], [0,0, self._compass_correction])\n",
    "                tmp_tmp_integral_img = self._aos.render(self.pose_to_virtualcamera(single_poses[self._current_center_camera_id]), self._fov, img_renderering_ids)\n",
    "                tmp_integral_img = self.divide_by_alpha(tmp_tmp_integral_img)\n",
    "                tmp_img = np.asarray(tmp_integral_img[:,:,0],dtype=np.uint8)\n",
    "                tmp_mask_img = np.asarray(projected_detection_mask[:,:,0],dtype=np.uint8)\n",
    "                curr_tmp_img = np.zeros((tmp_img.shape[0],tmp_img.shape[1]),dtype=np.uint8)\n",
    "                cv2.bitwise_and(tmp_img, tmp_mask_img, curr_tmp_img)\n",
    "                contours,hierarchy  = cv2.findContours(np.asarray(curr_tmp_img[:,:],dtype=np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                add_img = False\n",
    "                for k in range(len(contours)):\n",
    "                    contour_area = cv2.contourArea(contours[k])\n",
    "                    print(\"curr_contour_area and Image Added\",prev_img_max_contour)\n",
    "                    if contour_area > prev_img_max_contour:\n",
    "                        prev_img_max_contour = contour_area\n",
    "                        print(\"curr_contour_area and Image Added\",prev_img_max_contour)\n",
    "                        add_img = True\n",
    "                if add_img:\n",
    "                    print(\"Added to Prev List\")\n",
    "                    added_prev_img = True\n",
    "                    self._prev_blob_images.append(blob_images[i])\n",
    "                    self._prev_images.append(self._current_RGB_images_list[i])\n",
    "                    if len(self._current_thermal_images_list)>= 1:\n",
    "                        self._prev_thermal_images.append(self._current_thermal_images_list[i])\n",
    "                    self._prev_images_poses.append(single_poses[i])\n",
    "                    gen_integral_blob_img = np.asarray(curr_tmp_img[:,:],dtype=np.uint8)\n",
    "                else :\n",
    "                    print(\"Do not Add to Prev List\")\n",
    "                    added_prev_img = False       \n",
    "        else:\n",
    "            print(\"same as integral image\")\n",
    "            rgb_integral_images = self.project_images_to_all(self._aos, self._current_RGB_images_list, single_poses,self._fov,center_camera_index=None,project_images=False)\n",
    "            if len(self._current_thermal_images_list)>= 1:\n",
    "                thermal_integral_images = self.project_images_to_all(self._aos, self._current_thermal_images_list, single_poses,self._fov,center_camera_index=None,project_images=False)\n",
    "                thermal_integral_img = np.asarray(thermal_integral_images[self._current_center_camera_id],dtype=np.uint8)\n",
    "                cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_gen_thermal_integral.png'), thermal_integral_img)\n",
    "                cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_thermal_integral.png'), thermal_integral_img)\n",
    "            rgb_integral_img  = np.asarray(rgb_integral_images[self._current_center_camera_id],dtype=np.uint8)\n",
    "            cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_gen_integral.png'), rgb_integral_img)  \n",
    "            cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_integral.png'), rgb_integral_img) \n",
    "\n",
    "        self._aos.clearViews()\n",
    "        len_info = []\n",
    "        len_info.append(str(len(self._prev_images)) + '\\n')\n",
    "        with open(os.path.join(Live_Debug_Path,'History_Info.txt'), 'a') as f:\n",
    "            f.writelines('\\n'.join(len_info))\n",
    "        \n",
    "        print(len(self._prev_images))\n",
    "        if len(self._prev_images) :\n",
    "            for i in range(len(self._prev_images)):\n",
    "                    self._aos.addView(self._prev_images[i], self._prev_images_poses[i], \"DEM BlobTrack\")\n",
    "            img_renderering_ids = []\n",
    "            self._aos.setDEMTransform([0,0,self._focalplane_height])\n",
    "            tmp_rgb_integral_img = self._aos.render(self.pose_to_virtualcamera(single_poses[self._current_center_camera_id]), self._fov, img_renderering_ids)\n",
    "            rgb_integral_img = self.divide_by_alpha(tmp_rgb_integral_img)\n",
    "            cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_gen_integral.png'), rgb_integral_img)\n",
    "            cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_integral.png'), rgb_integral_img)\n",
    "            if len(self._current_thermal_images_list)>= 1:\n",
    "                self._aos.clearViews()\n",
    "                for i in range(len(self._prev_thermal_images)):\n",
    "                    self._aos.addView(self._prev_thermal_images[i], self._prev_images_poses[i], \"DEM BlobTrack\")\n",
    "                img_renderering_ids = []\n",
    "                self._aos.setDEMTransform([0,0,self._focalplane_height])\n",
    "                tmp_thermal_integral_img = self._aos.render(self.pose_to_virtualcamera(single_poses[self._current_center_camera_id]), self._fov, img_renderering_ids)\n",
    "                thermal_integral_img = self.divide_by_alpha(tmp_thermal_integral_img)\n",
    "                cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_gen_thermal_integral.png'), thermal_integral_img)\n",
    "                cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_thermal_integral.png'), thermal_integral_img)\n",
    "        else :\n",
    "            print(\"same as integral image\")\n",
    "            rgb_integral_images = self.project_images_to_all(self._aos, self._current_RGB_images_list, single_poses,self._fov,center_camera_index=None,project_images=False)\n",
    "            if len(self._current_thermal_images_list)>= 1:\n",
    "                thermal_integral_images = self.project_images_to_all(self._aos, self._current_thermal_images_list, single_poses,self._fov,center_camera_index=None,project_images=False)\n",
    "                thermal_integral_img = np.asarray(thermal_integral_images[self._current_center_camera_id],dtype=np.uint8)\n",
    "                cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_gen_thermal_integral.png'), thermal_integral_img)\n",
    "                cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_thermal_integral.png'), thermal_integral_img)\n",
    "            rgb_integral_img  = np.asarray(rgb_integral_images[self._current_center_camera_id],dtype=np.uint8)\n",
    "            cv2.imwrite(os.path.join( Live_Debug_Path,  str(self._integration_count)+ '_gen_integral.png'), rgb_integral_img) \n",
    "            cv2.imwrite(os.path.join( Integral_Path,  str(self._integration_count)+ '_gen_integral.png'), rgb_integral_img) \n",
    "        self._integration_count = self._integration_count + 1\n",
    "        return rgb_integral_img, prev_img_max_contour,gen_integral_blob_img\n",
    "\n",
    "        \n",
    "class drone_pso:\n",
    "    _fov = 45\n",
    "    _rx_threshold = 0.999\n",
    "    _no_of_drones = 10\n",
    "    _distance_factor = 2.0\n",
    "    _scanning_bearing = 0.0\n",
    "    _empty_scene_rx_blob_size_threshold = 500.0\n",
    "    _scandirec_waypoint_distance = 3.0\n",
    "    _init = True\n",
    "    _aos = None\n",
    "    _images = None\n",
    "    _poses = None\n",
    "    _previous_drone_pos = None\n",
    "    _center_waypoint = None\n",
    "    _changing_back_speed = 2.0\n",
    "    _cognitive_local_fac = 0.2\n",
    "    _social_global_fac = 0.2\n",
    "    _minimum_drone_distance = _distance_factor\n",
    "    _metric_cal = None\n",
    "    _debug = False\n",
    "    _current_gps_waypoints = None\n",
    "    _waypoint_count = 0\n",
    "    \n",
    "    def __init__(self,aos_ptr,no_drones,fieldofview,rxthreshold,distancebtwndrones,scanningdirection,scanning_direction_waypoint_distance,emptysceneblobthreshold, starting_loc_gps, changingtolinearspeed, localfac, globalfac, minimumdistancebetweendrone, debug_mode = False):\n",
    "        \n",
    "        self._aos = aos_ptr\n",
    "        self._no_of_drones = no_drones\n",
    "        self._fov = fieldofview\n",
    "        self._rx_threshold = rxthreshold\n",
    "        self._distance_factor = distancebtwndrones\n",
    "        self._scanning_bearing = scanningdirection\n",
    "        self._empty_scene_rx_blob_size_threshold = emptysceneblobthreshold\n",
    "        self._center_waypoint = starting_loc_gps\n",
    "        self._changing_back_speed = changingtolinearspeed\n",
    "        self._cognitive_local_fac = localfac\n",
    "        self._social_global_fac = globalfac\n",
    "        self._minimum_drone_distance = minimumdistancebetweendrone\n",
    "        self._metric_cal = evaluate_metric(self._aos, self._fov,self._rx_threshold, dem_height= 0.0,compasscorrection=0.0,debug_mode=debug_mode)\n",
    "        self._debug = debug_mode\n",
    "        self._scandirec_waypoint_distance = scanning_direction_waypoint_distance\n",
    "        self._waypoint_count = 0\n",
    "        self._continous_converging = 0\n",
    "        self._startingcentreposition = [0,-12] \n",
    "        self._blob_person_position = [0,10]\n",
    "        self._current_blob_position = [0,10]\n",
    "\n",
    "        \n",
    "        if self._debug:\n",
    "            np.random.seed(100)\n",
    "        self._centered_drone_array = np.arange(-(int)((self._no_of_drones-1)/2),(int)((self._no_of_drones+2)/2),1) * self._distance_factor\n",
    "        if self._debug:\n",
    "            self._direction_vector = [3.0,3.0]\n",
    "        else :\n",
    "            self._direction_vector = [np.sin(np.deg2rad( self._scanning_bearing)), np.cos(np.deg2rad( self._scanning_bearing))]\n",
    "        self._center_east,self._center_north,self._zone_number, self._zone_letter = utm.from_latlon(self._center_waypoint[0],self._center_waypoint[1])\n",
    "        \n",
    "        self._vec_perpend_to_scan_dir = self.perpendicular(self.normalize(self._direction_vector))\n",
    "        print(self._vec_perpend_to_scan_dir)\n",
    "        print(self._direction_vector)\n",
    "        self._rel_drone_pos = np.transpose(np.array(list(tuple(self._vec_perpend_to_scan_dir* drone_pos_to_center) for drone_pos_to_center in self._centered_drone_array)))\n",
    "        print(self._rel_drone_pos.shape)\n",
    "        print(self._centered_drone_array)\n",
    "        print(self._rel_drone_pos.shape)\n",
    "        print(self._rel_drone_pos)\n",
    "        self._mean_drone_pos = np.mean(self._rel_drone_pos,1).reshape(2,1)\n",
    "        self._rel_drone_pos = self._rel_drone_pos - np.repeat(self._mean_drone_pos,self._no_of_drones,axis = 1)\n",
    "        self._rand_velocity_vec = self._scanning_dir_vec = np.random.randn(2, self._no_of_drones) * 0.1\n",
    "        normalized_scan_vec = self.normalize(self._direction_vector)\n",
    "        \n",
    "        for i in range(self._no_of_drones):\n",
    "            \n",
    "            self._scanning_dir_vec[:,i] = (normalized_scan_vec[0]*self._scandirec_waypoint_distance,normalized_scan_vec[1]*self._scandirec_waypoint_distance)\n",
    "\n",
    "        drones_next_east_loc = self._rel_drone_pos[0,:] + self._center_east\n",
    "        drones_next_north_loc = self._rel_drone_pos[1,:] + self._center_north\n",
    "        drones_next_lat,drones_next_lon = utm.to_latlon(drones_next_east_loc, drones_next_north_loc, self._zone_number, self._zone_letter)\n",
    "        drones_next_loc = list(zip(drones_next_lat, drones_next_lon))\n",
    "        self._previous_drone_pos = self._rel_drone_pos + (np.transpose(np.tile(np.array(self._startingcentreposition),(self._no_of_drones,1))))  \n",
    "        self._current_gps_waypoints = drones_next_loc\n",
    "        \n",
    "       \n",
    "    def set_scanning_direction(self, scanning_bearing):\n",
    "        self._scanning_bearing = scanning_bearing\n",
    "        if self._debug:\n",
    "            self._direction_vector = [3.0,3.0]\n",
    "        else :\n",
    "            self._direction_vector = [np.sin(np.deg2rad( self._scanning_bearing)), np.cos(np.deg2rad( self._scanning_bearing))]\n",
    "  \n",
    "        self._vec_perpend_to_scan_dir = self.perpendicular(self.normalize(self._direction_vector))\n",
    "        print(self._vec_perpend_to_scan_dir)\n",
    "        print(self._direction_vector)\n",
    "        \n",
    "        self._rel_drone_pos = np.transpose(np.array(list(tuple(self._vec_perpend_to_scan_dir* drone_pos_to_center) for drone_pos_to_center in self._centered_drone_array)))\n",
    "        print(self._rel_drone_pos.shape)\n",
    "      \n",
    "        \n",
    "        print(self._centered_drone_array)\n",
    "        print(self._rel_drone_pos.shape)\n",
    "        print(self._rel_drone_pos)\n",
    "    \n",
    "        self._mean_drone_pos = np.mean(self._rel_drone_pos,1).reshape(2,1)\n",
    "        self._rel_drone_pos = self._rel_drone_pos - np.repeat(self._mean_drone_pos,self._no_of_drones,axis = 1)\n",
    "        \n",
    "\n",
    "        normalized_scan_vec = self.normalize(self._direction_vector)\n",
    "        for i in range(self._no_of_drones):\n",
    "            self._scanning_dir_vec[:,i] = (normalized_scan_vec[0]*self._scandirec_waypoint_distance,normalized_scan_vec[1]*self._scandirec_waypoint_distance)\n",
    "\n",
    "    def set_scan_direction_distance(self,scanning_direction_waypoint_distance):\n",
    "        self._scandirec_waypoint_distance = scanning_direction_waypoint_distance\n",
    "        normalized_scan_vec = self.normalize(self._direction_vector)\n",
    "        for i in range(self._no_of_drones):\n",
    "            self._scanning_dir_vec[:,i] = (normalized_scan_vec[0]*self._scandirec_waypoint_distance,normalized_scan_vec[1]*self._scandirec_waypoint_distance)\n",
    "\n",
    "    def set_emptyblob_threshold(self, contour_area_threshold):\n",
    "        self._empty_scene_rx_blob_size_threshold = contour_area_threshold\n",
    "\n",
    "    def get_rx_threshold(self):\n",
    "        return self._empty_scene_rx_blob_size_threshold\n",
    "    \n",
    "    def determine_emptyblob_threshold(self,single_images,site_poses, fov = None, rxthreshold =  None, dem_height = None, compasscorrection = None , pos = None):\n",
    "        center_rgb_integral_image, leader_rx_image, Leader_index, leader_contour = self._metric_cal.get_relevent_info(single_images,site_poses, fov, rxthreshold, dem_height, compasscorrection, pos)\n",
    "        return center_rgb_integral_image, leader_rx_image, Leader_index, leader_contour\n",
    "        \n",
    "    def get_current_waypoints(self):\n",
    "        return self._current_gps_waypoints, self._previous_drone_pos\n",
    "\n",
    "    def get_leader_info(self, images, poses):\n",
    "        position = self._previous_drone_pos\n",
    "        leader_index, leader_contour_area, mask_img, camera_id,leader_blob_image, leader_rx_image,rect = self._metric_cal.find_leader_within_images(images, poses, self._fov, rxthreshold=None, pos = position)\n",
    "\n",
    "    def get_waypoints_with_pso(self,images, poses, virtual_camera_pose):\n",
    "        \n",
    "        self._waypoint_count = self._waypoint_count + 1\n",
    "        position = self._previous_drone_pos\n",
    "       \n",
    "        leader_index, leader_contour_area, mask_img, camera_id,leader_blob_image, leader_rx_image,rect = self._metric_cal.find_leader_within_images(images, poses, self._fov, rxthreshold=None, pos = position)\n",
    "        integral_image, prev_contour_area, gen_integral_blob_img = self._metric_cal.integrate_informative_images(images, poses, virtual_camera_pose, mask_img, poses[camera_id])\n",
    "        # if (leader_contour_area < self._empty_scene_rx_blob_size_threshold):\n",
    "            \n",
    "        #     integral_image, prev_contour_area, gen_integral_blob_img = self._metric_cal.integrate_informative_images(images, poses, virtual_camera_pose, None, None)\n",
    "            \n",
    "        # else :\n",
    "            \n",
    "        #     integral_image, prev_contour_area, gen_integral_blob_img = self._metric_cal.integrate_informative_images(images, poses, virtual_camera_pose, mask_img, poses[camera_id])\n",
    "        info = []\n",
    "        info.append('WayPoint_Count ' + str(self._waypoint_count) + ' \\n')\n",
    "        info.append('Leader Index ' + str(leader_index) + ' \\n')\n",
    "        info.append('Leader Contour ' + str(leader_contour_area) + ' \\n')\n",
    "        info.append('Contour Threshold ' + str(self._empty_scene_rx_blob_size_threshold) + ' \\n')\n",
    "        \n",
    "        # if (leader_contour_area < self._empty_scene_rx_blob_size_threshold):\n",
    "        if (prev_contour_area < self._empty_scene_rx_blob_size_threshold): \n",
    "            self._continous_converging = 0\n",
    "            curr_drone_rel_pos = np.repeat(np.mean(self._previous_drone_pos,1).reshape(2,1),self._no_of_drones,axis = 1) + self._rel_drone_pos #line formation around center of gravety of previous swarm position\n",
    "            info.append('Previous Drone Positions ' + str(self._previous_drone_pos[0,:]) + '_' +  str(self._previous_drone_pos[1,:])+ ' \\n')\n",
    "            info.append('Mean Previous Drone Positions ' + str(np.repeat(np.mean(self._previous_drone_pos,1).reshape(2,1),self._no_of_drones,axis = 1)[0,:]) + '_' +  str(np.repeat(np.mean(self._previous_drone_pos,1).reshape(2,1),self._no_of_drones,axis = 1)[1,:])+ ' \\n')\n",
    "            info.append('relative Drone Positions ' + str(self._rel_drone_pos[0,:]) + '_' +  str(self._rel_drone_pos[1,:])+ ' \\n')\n",
    "            info.append('current starting Drone Positions ' + str(curr_drone_rel_pos[0,:]) + '_' +  str(curr_drone_rel_pos[1,:])+ ' \\n')\n",
    "            \n",
    "            velocity_vec = self._scanning_dir_vec + self._changing_back_speed * (curr_drone_rel_pos - self._previous_drone_pos)\n",
    "\n",
    "            info.append('scanning direction vector ' + str(self._scanning_dir_vec[0,:]) + '_' +  str(self._scanning_dir_vec[1,:])+ ' \\n')\n",
    "            info.append('changing back speed ' + str(self._changing_back_speed) + ' \\n')\n",
    "            info.append('velocity vector ' + str(velocity_vec[0,:]) + '_' +  str(velocity_vec[1,:])+ ' \\n')\n",
    "           \n",
    "            new_drone_rel_pos = self._previous_drone_pos + velocity_vec\n",
    "            self._previous_drone_pos = new_drone_rel_pos\n",
    "            info.append('Moving Straight ' + str(new_drone_rel_pos[0,:]) + '_' +  str(new_drone_rel_pos[1,:])+ ' \\n')\n",
    "        else :\n",
    "            self._continous_converging = self._continous_converging + 1\n",
    "            if self._debug:\n",
    "                np.random.seed(100)\n",
    "            rand_mov_vec = np.random.rand(2, self._no_of_drones)*2 - np.ones(2*self._no_of_drones).reshape(2, self._no_of_drones)\n",
    "            \n",
    "            resp_vel_vec = self._cognitive_local_fac * self.normalize_vectors(rand_mov_vec) + self._social_global_fac * self.normalize_vectors((self._previous_drone_pos[:,leader_index].reshape(-1,1) - self._previous_drone_pos))\n",
    "           \n",
    "            new_drone_rel_pos = self._previous_drone_pos + resp_vel_vec\n",
    "            info.append('Converging Before Rutherford Scattering ' + str(new_drone_rel_pos[0,:]) + '_' +  str(new_drone_rel_pos[1,:])+ ' \\n')\n",
    "           \n",
    "            new_drone_rel_pos = self.rutherford_scattering(new_drone_rel_pos,self._no_of_drones,self._minimum_drone_distance) # minimal distance constraint (Rutherford Scattering)\n",
    "          \n",
    "            self._previous_drone_pos = new_drone_rel_pos\n",
    "            info.append('Minimum Distance Within Rutherford Scattering ' + str(self._minimum_drone_distance) + ' \\n')\n",
    "            info.append('Converging After Rutherford Scattering ' + str(new_drone_rel_pos[0,:]) + '_' + str(new_drone_rel_pos[1,:])+ ' \\n')\n",
    "            \n",
    "\n",
    "        drones_next_east_loc = new_drone_rel_pos[0,:] + self._center_east\n",
    "        drones_next_north_loc = new_drone_rel_pos[1,:] + self._center_north\n",
    "\n",
    "        drones_next_lat,drones_next_lon = utm.to_latlon(drones_next_east_loc,drones_next_north_loc, self._zone_number, self._zone_letter)\n",
    "        info.append('drones next lat ' + str(drones_next_lat) + ' drones next lon ' + str(drones_next_lon)+ ' \\n')\n",
    "        drones_next_loc = zip(drones_next_lat, drones_next_lon)\n",
    "       \n",
    "        self._current_gps_waypoints = drones_next_loc\n",
    "        with open(os.path.join(Live_Debug_Path,'WayPoint_Info.txt'), 'a') as f:\n",
    "            f.writelines('\\n'.join(info))\n",
    "        return drones_next_loc, self._previous_drone_pos, integral_image,leader_contour_area, leader_index, prev_contour_area,camera_id,leader_blob_image, leader_rx_image,gen_integral_blob_img,rect\n",
    "    \n",
    "    def get_waypoints_with_pso_motion(self,images, poses, virtual_camera_pose):\n",
    "        \n",
    "        self._waypoint_count = self._waypoint_count + 1\n",
    "        position = self._previous_drone_pos\n",
    "        \n",
    "        leader_index, leader_contour_area, mask_img, camera_id,leader_blob_image, leader_rx_image,rect = self._metric_cal.find_leader_within_images(images, poses, self._fov, rxthreshold=None, pos = position)\n",
    "        integral_image, prev_contour_area, gen_integral_blob_img = self._metric_cal.integrate_informative_images(images, poses, virtual_camera_pose, mask_img, poses[camera_id])    \n",
    "        info = []\n",
    "        info.append('WayPoint_Count ' + str(self._waypoint_count) + ' \\n')\n",
    "        info.append('Leader Index ' + str(leader_index) + ' \\n')\n",
    "        info.append('Leader Contour ' + str(leader_contour_area) + ' \\n')\n",
    "        info.append('Contour Threshold ' + str(self._empty_scene_rx_blob_size_threshold) + ' \\n')\n",
    "        # if (leader_contour_area < self._empty_scene_rx_blob_size_threshold):\n",
    "        if (prev_contour_area < self._empty_scene_rx_blob_size_threshold): \n",
    "\n",
    "        \n",
    "            curr_drone_rel_pos = np.repeat(np.mean(self._previous_drone_pos,1).reshape(2,1),self._no_of_drones,axis = 1) + self._rel_drone_pos #line formation around center of gravety of previous swarm position\n",
    "            info.append('Previous Drone Positions ' + str(self._previous_drone_pos[0,:]) + '_' +  str(self._previous_drone_pos[1,:])+ ' \\n')\n",
    "            info.append('Mean Previous Drone Positions ' + str(np.repeat(np.mean(self._previous_drone_pos,1).reshape(2,1),self._no_of_drones,axis = 1)[0,:]) + '_' +  str(np.repeat(np.mean(self._previous_drone_pos,1).reshape(2,1),self._no_of_drones,axis = 1)[1,:])+ ' \\n')\n",
    "            info.append('relative Drone Positions ' + str(self._rel_drone_pos[0,:]) + '_' +  str(self._rel_drone_pos[1,:])+ ' \\n')\n",
    "            info.append('current starting Drone Positions ' + str(curr_drone_rel_pos[0,:]) + '_' +  str(curr_drone_rel_pos[1,:])+ ' \\n')\n",
    "            info.append('Mean Current Drone Positions ' + str(np.repeat(np.mean(curr_drone_rel_pos,1).reshape(2,1),self._no_of_drones,axis = 1)[0,:]) + '_' +  str(np.repeat(np.mean(curr_drone_rel_pos,1).reshape(2,1),self._no_of_drones,axis = 1)[1,:])+ ' \\n')\n",
    "\n",
    "            velocity_vec = self._scanning_dir_vec + self._changing_back_speed * (curr_drone_rel_pos - self._previous_drone_pos)\n",
    "\n",
    "            info.append('scanning direction vector ' + str(self._scanning_dir_vec[0,:]) + '_' +  str(self._scanning_dir_vec[1,:])+ ' \\n')\n",
    "            info.append('changing back speed ' + str(self._changing_back_speed) + ' \\n')\n",
    "            info.append('velocity vector ' + str(velocity_vec[0,:]) + '_' +  str(velocity_vec[1,:])+ ' \\n')\n",
    "       \n",
    "            new_drone_rel_pos = self._previous_drone_pos + velocity_vec\n",
    "            ###############xxxxxxxxxxxxxxxCurrent iteration ref loc = new_drone_rel_pos and previous loc = self._previous_drone_posxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "            self._previous_drone_pos = new_drone_rel_pos\n",
    "            info.append('Moving Straight ' + str(new_drone_rel_pos[0,:]) + '_' +  str(new_drone_rel_pos[1,:])+ ' \\n')\n",
    "            self._continous_converging = 0\n",
    "            \n",
    "            motion = []\n",
    "            motion.append('Waypoint ' + str(self._waypoint_count) + ' \\n')\n",
    "            motion.append('No convergence'  + ' \\n') \n",
    "            motion.append('Scanning_direction_Waypoint_Distance_c3 ' + str(self._scandirec_waypoint_distance) + ' \\n')\n",
    "               \n",
    "            positiondummy = [60,60]  # dummy number when no convergence\n",
    "            rectdummy = [59,59,2,2]  # dummy number when no convergence\n",
    "            import json\n",
    "            blobpositionsloc = os.path.join(Download_Location,'blobpositions.json')\n",
    "\n",
    "            bd ={\n",
    "                    self._waypoint_count:positiondummy,\n",
    "                    \n",
    "                }\n",
    "\n",
    "            with open(blobpositionsloc,'r+') as file4:\n",
    "           \n",
    "                data4 = json.load(file4)\n",
    "                data4.update(bd)\n",
    "                file4.seek(0)\n",
    "                json.dump(data4, file4)\n",
    "            rectpositionsloc = os.path.join(Download_Location,'rectpositions.json')\n",
    "                  \n",
    "            rt9 ={\n",
    "                    self._waypoint_count:rectdummy,\n",
    "                    \n",
    "                }\n",
    "\n",
    "            with open(rectpositionsloc,'r+') as file10:\n",
    "            \n",
    "                    data10 = json.load(file10)\n",
    "                    data10.update(rt9)\n",
    "                    file10.seek(0)\n",
    "                    json.dump(data10, file10)  \n",
    "            sdloc = os.path.join(Download_Location,'scanningwaypointdistance.json')\n",
    "                             \n",
    "            sd14 ={\n",
    "                    self._waypoint_count:self._scandirec_waypoint_distance,\n",
    "                    \n",
    "                }\n",
    "\n",
    "            with open(sdloc,'r+') as file14:\n",
    "            \n",
    "                    data14 = json.load(file14)\n",
    "                    data14.update(sd14)\n",
    "                    file14.seek(0)\n",
    "                    json.dump(data14, file14)  \n",
    "        \n",
    "        else :\n",
    "            if self._debug:\n",
    "                np.random.seed(100)\n",
    "            rand_mov_vec = np.random.rand(2, self._no_of_drones)*2 - np.ones(2*self._no_of_drones).reshape(2, self._no_of_drones)\n",
    "            resp_vel_vec = self._cognitive_local_fac * self.normalize_vectors(rand_mov_vec) + self._social_global_fac * self.normalize_vectors((self._previous_drone_pos[:,leader_index].reshape(-1,1) - self._previous_drone_pos))\n",
    "          \n",
    "            new_drone_rel_pos = self._previous_drone_pos + resp_vel_vec\n",
    "            info.append('Converging Before Rutherford Scattering ' + str(new_drone_rel_pos[0,:]) + '_' +  str(new_drone_rel_pos[1,:])+ ' \\n')\n",
    "         \n",
    "            new_drone_rel_pos = self.rutherford_scattering(new_drone_rel_pos,self._no_of_drones,self._minimum_drone_distance) # minimal distance constraint (Rutherford Scattering)\n",
    "           \n",
    "            ###############xxxxxxxxxxxxxxxCurrent iteration ref loc = new_drone_rel_pos and previous loc = self._previous_drone_posxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "            \n",
    "            currentdronepos = new_drone_rel_pos\n",
    "            previousdronepos = self._previous_drone_pos\n",
    "            self._previous_drone_pos = new_drone_rel_pos\n",
    "            info.append('Minimum Distance Within Rutherford Scattering ' + str(self._minimum_drone_distance) + ' \\n')\n",
    "            info.append('Converging After Rutherford Scattering ' + str(new_drone_rel_pos[0,:]) + '_' + str(new_drone_rel_pos[1,:])+ ' \\n')\n",
    "            self._continous_converging = self._continous_converging + 1\n",
    "           \n",
    "            # integral_image, prev_contour_area, gen_integral_blob_img = self._metric_cal.integrate_informative_images(images, poses, virtual_camera_pose, mask_img, poses[camera_id])\n",
    "            previous_blob_personposition = self._blob_person_position \n",
    "            \n",
    "            \n",
    "            \n",
    "            new_leader_index = leader_index\n",
    "            coverage = 2*altitude_list[new_leader_index]*np.tan(np.deg2rad(25))\n",
    "            resolution = 512\n",
    "            metretopixels = coverage/resolution\n",
    "            blob_posx = rect[0] + rect[2]/2\n",
    "            blob_posy = rect[1] + rect[3]/2\n",
    "            blob_posxinpixels = blob_posx * metretopixels\n",
    "            blob_posyinpixels = blob_posy * metretopixels\n",
    "            blobposition = [blob_posxinpixels,blob_posyinpixels]\n",
    "            ref_loc = previousdronepos\n",
    "            integralposition_centre = [ref_loc[0][new_leader_index], ref_loc[1][new_leader_index]]\n",
    "            integral_startposition = [integralposition_centre[0] - coverage/2, integralposition_centre[1] - coverage/2]\n",
    "            blob_personposition = [blobposition[0] +(integral_startposition[0]), blobposition[1] + (integral_startposition[1])]\n",
    "            \n",
    "\n",
    "            dronemeanx=(np.mean(ref_loc[0]))\n",
    "            dronemeany=(np.mean(ref_loc[1]))\n",
    "            dronemeanpos = [dronemeanx,dronemeany]\n",
    "            dy = (-blob_personposition[1]-(-dronemeany))\n",
    "            dx = (blob_personposition[0]-dronemeanx)\n",
    "\n",
    "            Scanning_direction = np.arctan2(dy,dx)\n",
    "            Scanning_direction = ((np.degrees(Scanning_direction))%360)+90\n",
    "            print(Scanning_direction)\n",
    "            if Scanning_direction >=360 :\n",
    "                Scanning_direction =  Scanning_direction - 360                             \n",
    "                print(Scanning_direction)\n",
    "\n",
    "            c = []\n",
    "            for i in range (0, 10):\n",
    "                distancedrone = math.sqrt( ((currentdronepos[0][i]-previousdronepos[0][i])**2)+((currentdronepos[1][i]-previousdronepos[1][i])**2) )\n",
    "                c.append(distancedrone)\n",
    "                \n",
    "            print(c)\n",
    "            new_max_distance =  max(c)    \n",
    "            print(max(c))\n",
    "            drone_totaltime = (new_max_distance/drone_speed)\n",
    "            delta = 1 * drone_totaltime\n",
    "            person_distance = math.sqrt( (blob_personposition[0] - previous_blob_personposition[0] )**2 + (blob_personposition[1] - previous_blob_personposition[1])**2 )\n",
    "        \n",
    "            c3 = person_distance \n",
    "            Scanning_direction_Waypoint_Distance = c3 + delta \n",
    "            if self._continous_converging > 1:\n",
    "                self.set_scan_direction_distance(Scanning_direction_Waypoint_Distance)\n",
    "                \n",
    "            import json\n",
    "            blobpositionsloc = os.path.join(Download_Location,'blobpositions.json')\n",
    "\n",
    "            bd ={\n",
    "                    self._waypoint_count:blob_personposition,\n",
    "                    \n",
    "                }\n",
    "           \n",
    "            with open(blobpositionsloc,'r+') as file3:\n",
    "            \n",
    "                    data3 = json.load(file3)\n",
    "                    data3.update(bd)\n",
    "                    file3.seek(0)\n",
    "                    json.dump(data3, file3)  \n",
    "                    \n",
    "            rectpositionsloc = os.path.join(Download_Location,'rectpositions.json')\n",
    "        \n",
    "            import json\n",
    "            rt ={\n",
    "                    self._waypoint_count:rect,\n",
    "                    \n",
    "                }\n",
    "\n",
    "            with open(rectpositionsloc,'r+') as file6:\n",
    "            \n",
    "                    data6 = json.load(file6)\n",
    "                    data6.update(rt)\n",
    "                    file6.seek(0)\n",
    "                    json.dump(data6, file6)   \n",
    "                    \n",
    "                    \n",
    "            import json\n",
    "            sdloc = os.path.join(Download_Location,'scanningwaypointdistance.json')\n",
    "\n",
    "            sd1 ={\n",
    "                    self._waypoint_count:Scanning_direction_Waypoint_Distance,\n",
    "                    \n",
    "                }\n",
    "\n",
    "            with open(sdloc,'r+') as file11:\n",
    "            \n",
    "                    data11 = json.load(file11)\n",
    "                    data11.update(sd1)\n",
    "                    file11.seek(0)\n",
    "                    json.dump(data11, file11)          \n",
    "\n",
    "            motion = []\n",
    "            motion.append('Waypoint ' + str(self._waypoint_count) + ' \\n')\n",
    "            motion.append('rect ' + str(rect) + ' \\n')\n",
    "            motion.append('previous_blob_personposition ' + str(previous_blob_personposition) + ' \\n')\n",
    "            motion.append('coverage ' + str(coverage) + ' \\n')\n",
    "            motion.append('new_leader_index ' + str(new_leader_index) + ' \\n')\n",
    "            motion.append('blobposition ' + str(blobposition) + ' \\n')\n",
    "            motion.append('integralposition_centre ' + str(integralposition_centre) + ' \\n')\n",
    "            motion.append('integral_startposition ' + str(integral_startposition) + ' \\n')\n",
    "            motion.append('currentblob_personposition ' + str(blob_personposition) + ' \\n')\n",
    "            motion.append('dronemeanpos ' + str(dronemeanpos) + ' \\n')\n",
    "            motion.append('Scanning_direction ' + str(Scanning_direction) + ' \\n')\n",
    "            motion.append('Distancetravelledbyperson ' + str(person_distance) + ' \\n')\n",
    "            motion.append('Scanning_direction_Waypoint_Distance_c3 ' + str(Scanning_direction_Waypoint_Distance) + ' \\n')\n",
    "            self.set_scanning_direction(Scanning_direction)\n",
    "            \n",
    "            self._blob_person_position = blob_personposition\n",
    "\n",
    "        with open(os.path.join(Live_Debug_Path,'motion.txt'), 'a') as f:\n",
    "            f.writelines('\\n'.join(motion))\n",
    "            \n",
    "\n",
    "        drones_next_east_loc = new_drone_rel_pos[0,:] + self._center_east\n",
    "        drones_next_north_loc = new_drone_rel_pos[1,:] + self._center_north\n",
    "\n",
    "        drones_next_lat,drones_next_lon = utm.to_latlon(drones_next_east_loc,drones_next_north_loc, self._zone_number, self._zone_letter)\n",
    "        info.append('drones next lat ' + str(drones_next_lat) + ' drones next lon ' + str(drones_next_lon)+ ' \\n')\n",
    "        drones_next_loc = zip(drones_next_lat, drones_next_lon)\n",
    "        self._current_gps_waypoints = drones_next_loc\n",
    "        with open(os.path.join(Live_Debug_Path,'WayPoint_Info.txt'), 'a') as f:\n",
    "            f.writelines('\\n'.join(info))\n",
    "        return drones_next_loc, self._previous_drone_pos, integral_image,leader_contour_area, leader_index, prev_contour_area,camera_id,leader_blob_image, leader_rx_image,gen_integral_blob_img,rect,personorientation,self._blob_person_position\n",
    "\n",
    "    def euclidean_distance_sqr(self,point1, point2):\n",
    "        \"\"\" euclidean_distance_sqr([1,2],[2,4])\n",
    "        5\n",
    "        \"\"\"\n",
    "        return (point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2\n",
    "\n",
    "\n",
    "    def column_based_sort(self,array, column=0):\n",
    "        \"\"\"\n",
    "        column_based_sort([(5, 1), (4, 2), (3, 0)], 1)\n",
    "        [(3, 0), (5, 1), (4, 2)]\n",
    "        \"\"\"\n",
    "        return sorted(array, key=lambda x: x[column])\n",
    "\n",
    "\n",
    "    def dis_between_closest_pair(self,points, points_counts, min_dis=float(\"inf\")):\n",
    "        \"\"\"\n",
    "        brute force approach to find distance between closest pair points\n",
    "\n",
    "        Parameters :\n",
    "        points, points_count, min_dis (list(tuple(int, int)), int, int)\n",
    "\n",
    "        Returns :\n",
    "        min_dis (float):  distance between closest pair of points\n",
    "\n",
    "        dis_between_closest_pair([[1,2],[2,4],[5,7],[8,9],[11,0]],5)\n",
    "        5\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        for i in range(points_counts - 1):\n",
    "            for j in range(i + 1, points_counts):\n",
    "                current_dis = self.euclidean_distance_sqr(points[i], points[j])\n",
    "                if current_dis < min_dis:\n",
    "                    min_dis = current_dis\n",
    "        return min_dis\n",
    "\n",
    "\n",
    "    def dis_between_closest_in_strip(self,points, points_counts, min_dis=float(\"inf\")):\n",
    "        \"\"\"\n",
    "        closest pair of points in strip\n",
    "\n",
    "        Parameters :\n",
    "        points, points_count, min_dis (list(tuple(int, int)), int, int)\n",
    "\n",
    "        Returns :\n",
    "        min_dis (float):  distance btw closest pair of points in the strip (< min_dis)\n",
    "\n",
    "        dis_between_closest_in_strip([[1,2],[2,4],[5,7],[8,9],[11,0]],5)\n",
    "        85\n",
    "        \"\"\"\n",
    "\n",
    "        for i in range(min(6, points_counts - 1), points_counts):\n",
    "            for j in range(max(0, i - 6), i):\n",
    "                current_dis = self.euclidean_distance_sqr(points[i], points[j])\n",
    "                if current_dis < min_dis:\n",
    "                    min_dis = current_dis\n",
    "        return min_dis\n",
    "\n",
    "\n",
    "\n",
    "    def closest_pair_of_points_sqr(self,points_sorted_on_x, points_sorted_on_y, points_counts):\n",
    "        \"\"\"divide and conquer approach\n",
    "\n",
    "        Parameters :\n",
    "        points, points_count (list(tuple(int, int)), int)\n",
    "\n",
    "        Returns :\n",
    "        (float):  distance btw closest pair of points\n",
    "\n",
    "        closest_pair_of_points_sqr([(1, 2), (3, 4)], [(5, 6), (7, 8)], 2)\n",
    "        8\n",
    "        \"\"\"\n",
    "\n",
    "        # base case\n",
    "        if points_counts <= 3:\n",
    "            return self.dis_between_closest_pair(points_sorted_on_x, points_counts)\n",
    "\n",
    "        # recursion\n",
    "        mid = points_counts // 2\n",
    "        closest_in_left = self.closest_pair_of_points_sqr(\n",
    "            points_sorted_on_x, points_sorted_on_y[:mid], mid\n",
    "        )\n",
    "        closest_in_right = self.closest_pair_of_points_sqr(\n",
    "            points_sorted_on_y, points_sorted_on_y[mid:], points_counts - mid\n",
    "        )\n",
    "        closest_pair_dis = min(closest_in_left, closest_in_right)\n",
    "\n",
    "        \"\"\"\n",
    "        cross_strip contains the points, whose Xcoords are at a\n",
    "        distance(< closest_pair_dis) from mid's Xcoord\n",
    "        \"\"\"\n",
    "\n",
    "        cross_strip = []\n",
    "        for point in points_sorted_on_x:\n",
    "            if abs(point[0] - points_sorted_on_x[mid][0]) < closest_pair_dis:\n",
    "                cross_strip.append(point)\n",
    "\n",
    "        closest_in_strip = self.dis_between_closest_in_strip(\n",
    "            cross_strip, len(cross_strip), closest_pair_dis\n",
    "        )\n",
    "        return min(closest_pair_dis, closest_in_strip)\n",
    "\n",
    "\n",
    "    def closest_pair_of_points(self,points, points_counts):\n",
    "        \"\"\"\n",
    "        closest_pair_of_points([(2, 3), (12, 30)], len([(2, 3), (12, 30)]))\n",
    "        28.792360097775937\n",
    "        \"\"\"\n",
    "        points_sorted_on_x = self.column_based_sort(points, column=0)\n",
    "        points_sorted_on_y = self.column_based_sort(points, column=1)\n",
    "        return (\n",
    "            self.closest_pair_of_points_sqr(\n",
    "                points_sorted_on_x, points_sorted_on_y, points_counts\n",
    "            )\n",
    "        ) ** 0.5\n",
    "\n",
    "\n",
    "\n",
    "    def perpendicular( self, a ) :\n",
    "        b = np.empty_like(a)\n",
    "        b[0] = -a[1]\n",
    "        b[1] = a[0]\n",
    "        return b\n",
    "\n",
    "    def normalize(self,a):\n",
    "        a = np.array(a)\n",
    "        return a/np.linalg.norm(a)\n",
    "\n",
    "        \n",
    "    def dis_between_farthest_pair(self,points, points_counts, min_dis=float(0)):\n",
    "        \"\"\"\n",
    "        brute force approach to find distance between closest pair points\n",
    "\n",
    "        Parameters :\n",
    "        points, points_count, min_dis (list(tuple(int, int)), int, int)\n",
    "\n",
    "        Returns :\n",
    "        min_dis (float):  distance between closest pair of points\n",
    "\n",
    "        dis_between_closest_pair([[1,2],[2,4],[5,7],[8,9],[11,0]],5)\n",
    "        5\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        for i in range(points_counts - 1):\n",
    "            for j in range(i + 1, points_counts):\n",
    "                current_dis = self.euclidean_distance_sqr(points[i], points[j])\n",
    "                if current_dis > min_dis:\n",
    "                    min_dis = current_dis\n",
    "        return min_dis\n",
    "\n",
    "    def dis_between_farthest_in_strip(self,points, points_counts, min_dis=float(0)):\n",
    "        \"\"\"\n",
    "        closest pair of points in strip\n",
    "\n",
    "        Parameters :\n",
    "        points, points_count, min_dis (list(tuple(int, int)), int, int)\n",
    "\n",
    "        Returns :\n",
    "        min_dis (float):  distance btw closest pair of points in the strip (< min_dis)\n",
    "\n",
    "        dis_between_closest_in_strip([[1,2],[2,4],[5,7],[8,9],[11,0]],5)\n",
    "        85\n",
    "        \"\"\"\n",
    "\n",
    "        for i in range(min(6, points_counts - 1), points_counts):\n",
    "            for j in range(max(0, i - 6), i):\n",
    "                current_dis = self.euclidean_distance_sqr(points[i], points[j])\n",
    "                if current_dis > min_dis:\n",
    "                    min_dis = current_dis\n",
    "        return min_dis\n",
    "\n",
    "    def farthest_pair_of_points_sqr(self,points_sorted_on_x, points_sorted_on_y, points_counts):\n",
    "        \"\"\"divide and conquer approach\n",
    "\n",
    "        Parameters :\n",
    "        points, points_count (list(tuple(int, int)), int)\n",
    "\n",
    "        Returns :\n",
    "        (float):  distance btw closest pair of points\n",
    "\n",
    "        closest_pair_of_points_sqr([(1, 2), (3, 4)], [(5, 6), (7, 8)], 2)\n",
    "        8\n",
    "        \"\"\"\n",
    "\n",
    "        # base case\n",
    "        if points_counts <= 3:\n",
    "            return self.dis_between_farthest_pair(points_sorted_on_x, points_counts)\n",
    "\n",
    "        # recursion\n",
    "        mid = points_counts // 2\n",
    "        closest_in_left = self.closest_pair_of_points_sqr(\n",
    "            points_sorted_on_x, points_sorted_on_y[:mid], mid\n",
    "        )\n",
    "        closest_in_right = self.closest_pair_of_points_sqr(\n",
    "            points_sorted_on_y, points_sorted_on_y[mid:], points_counts - mid\n",
    "        )\n",
    "        closest_pair_dis = max(closest_in_left, closest_in_right)\n",
    "\n",
    "        \"\"\"\n",
    "        cross_strip contains the points, whose Xcoords are at a\n",
    "        distance(< closest_pair_dis) from mid's Xcoord\n",
    "        \"\"\"\n",
    "\n",
    "        cross_strip = []\n",
    "        for point in points_sorted_on_x:\n",
    "            if abs(point[0] - points_sorted_on_x[mid][0]) > closest_pair_dis:\n",
    "                cross_strip.append(point)\n",
    "\n",
    "        closest_in_strip = self.dis_between_farthest_in_strip(\n",
    "            cross_strip, len(cross_strip), closest_pair_dis\n",
    "        )\n",
    "        return max(closest_pair_dis, closest_in_strip)\n",
    "\n",
    "\n",
    "    def farthest_pair_of_points(self,points, points_counts):\n",
    "        \"\"\"\n",
    "        closest_pair_of_points([(2, 3), (12, 30)], len([(2, 3), (12, 30)]))\n",
    "        28.792360097775937\n",
    "        \"\"\"\n",
    "        points_sorted_on_x = self.column_based_sort(points, column=0)\n",
    "        points_sorted_on_y = self.column_based_sort(points, column=1)\n",
    "        return (\n",
    "            self.farthest_pair_of_points_sqr(\n",
    "                points_sorted_on_x, points_sorted_on_y, points_counts\n",
    "            )\n",
    "        ) ** 0.5\n",
    "\n",
    "    def normalize(self,v):\n",
    "        norm = np.linalg.norm(v)\n",
    "        if norm == 0: \n",
    "            return v\n",
    "        return v / norm\n",
    "\n",
    "    def normalize_vectors(self,v):\n",
    "        for i in range(v.shape[1]):\n",
    "            temp = [v[0,i],v[1,i]]\n",
    "            norm = np.linalg.norm(temp)\n",
    "            if norm > 0.0: \n",
    "                v[0,i] = v[0,i]/norm\n",
    "                v[1,i] = v[1,i]/norm\n",
    "        return v\n",
    "\n",
    "    def dist(self,p1, p2):\n",
    "        return math.sqrt((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2)\n",
    "    \n",
    "    def rutherford_scattering(self,Y,N,f):\n",
    "        ndim = 2\n",
    "    \n",
    "        charges = np.ones((N))*f  \n",
    "\n",
    "        loc_arr = np.transpose(Y) \n",
    "        speed_arr = np.zeros((N, ndim))\n",
    "\n",
    "        # compute charge matrix, ie c1 * c2\n",
    "        charge_matrix = -1 * np.outer(charges, charges)\n",
    "        #print(charge_matrix)\n",
    "        time = np.linspace(0, 0.5,500)\n",
    "        dt = np.ediff1d(time).mean()\n",
    "        masses = np.ones(N) *dt  \n",
    "\n",
    "\n",
    "        for i, t in enumerate(time):\n",
    "            # get (dx, dy) for every point\n",
    "            delta = (loc_arr.T[..., np.newaxis] - loc_arr.T[:, np.newaxis]).T\n",
    "            # calculate Euclidean distance\n",
    "            distances = np.linalg.norm(delta, axis=-1)\n",
    "            # and normalised unit vector\n",
    "            unit_vector = (delta.T / distances).T\n",
    "            unit_vector[np.isnan(unit_vector)] = 0 # replace NaN values with 0\n",
    "\n",
    "            # calculate force\n",
    "            force = charge_matrix / distances**2 # norm gives length of delta vector\n",
    "            force[np.isinf(force)] = 0 # NaN forces are 0\n",
    "\n",
    "            # calculate acceleration in all dimensions\n",
    "            acc = (unit_vector.T * force / masses).T.sum(axis=1)\n",
    "            # v = a * dt\n",
    "            speed_arr = acc * dt\n",
    "\n",
    "            # increment position, xyz = v * dt\n",
    "            loc_arr += speed_arr * dt \n",
    "\n",
    "        return(np.transpose(loc_arr))\n",
    "\n",
    "def eul2rotm(theta) :\n",
    "    s_1 = math.sin(theta[0])\n",
    "    c_1 = math.cos(theta[0]) \n",
    "    s_2 = math.sin(theta[1]) \n",
    "    c_2 = math.cos(theta[1]) \n",
    "    s_3 = math.sin(theta[2]) \n",
    "    c_3 = math.cos(theta[2])\n",
    "    rotm = np.identity(3)\n",
    "    rotm[0,0] =  c_1*c_2\n",
    "    rotm[0,1] =  c_1*s_2*s_3 - s_1*c_3\n",
    "    rotm[0,2] =  c_1*s_2*c_3 + s_1*s_3\n",
    "\n",
    "    rotm[1,0] =  s_1*c_2\n",
    "    rotm[1,1] =  s_1*s_2*s_3 + c_1*c_3\n",
    "    rotm[1,2] =  s_1*s_2*c_3 - c_1*s_3\n",
    "\n",
    "    rotm[2,0] = -s_2\n",
    "    rotm[2,1] =  c_2*s_3\n",
    "    rotm[2,2] =  c_2*c_3        \n",
    "\n",
    "    return rotm\n",
    "\n",
    "\n",
    "def imshow(image, *args, **kwargs):\n",
    "     \n",
    "    if len(image.shape) == 3: \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    plt.imshow(image, *args, **kwargs)\n",
    "    plt.axis('off')\n",
    "    \n",
    "\n",
    "def divide_by_alpha(img):\n",
    "    a = img[:,:,3]\n",
    "    aaa = np.stack((a,a,a),axis=-1)\n",
    "    rgb = img[:,:,:3]/aaa \n",
    "    rgb[aaa==0] = np.nan\n",
    "    return rgb\n",
    "\n",
    "def divide_by_alpha1(rimg2):\n",
    "    a = np.stack((rimg2[:,:,3],rimg2[:,:,3],rimg2[:,:,3]),axis=-1)\n",
    "    return rimg2[:,:,:3]/a\n",
    "\n",
    "\n",
    "def createviewmateuler(eulerang, camLocation):\n",
    "    \n",
    "    rotationmat = eul2rotm(eulerang)\n",
    "    translVec =  np.reshape((-camLocation @ rotationmat),(3,1))\n",
    "    conjoinedmat = (np.append(np.transpose(rotationmat), translVec, axis=1))\n",
    "    return conjoinedmat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################Get Drones Initial Positions###############################################################\n",
    "test_drone_pso = drone_pso(aos,NumberofDrones,fov,rxthreshold,distance_btwn_drones,Scanning_direction,Scanning_direction_Waypoint_Distance,emptyblobthreshold,(48.335836, 14.326644),changing_to_linear_speed,local_fac,global_fac,minimum_distance_btwn_drone,False)\n",
    "current_gps_locations,ref_loc = test_drone_pso.get_current_waypoints()\n",
    "prevwaypoints = ref_loc\n",
    "\n",
    "drone_names = ['1','2','3','4','5','6','7','8','9','10']\n",
    "\n",
    "#############################For First Step --- Determining Person Blob Size###############################################################\n",
    "step_count = 0\n",
    "#############################Create Link for Initial Positions###############################################################\n",
    "\n",
    "#### For 10 drones\n",
    "link1=\"http://127.0.0.1:5504/?drone1x=\"+str(ref_loc[0][0])+\"&drone1y=\"+str(ref_loc[1][0])+\"&drone2x=\"+str(ref_loc[0][1])+\"&drone2y=\"+str(ref_loc[1][1])+\"&drone3x=\"+str(ref_loc[0][2])+\"&drone3y=\"+str(ref_loc[1][2])+\"&drone4x=\"+str(ref_loc[0][3])+\"&drone4y=\"+str(ref_loc[1][3])+\"&drone5x=\"+str(ref_loc[0][4])+\"&drone5y=\"+str(ref_loc[1][4])+\"&drone6x=\"+str(ref_loc[0][5])+\"&drone6y=\"+str(ref_loc[1][5])+\"&drone7x=\"+str(ref_loc[0][6])+\"&drone7y=\"+str(ref_loc[1][6])+\"&drone8x=\"+str(ref_loc[0][7])+\"&drone8y=\"+str(ref_loc[1][7])+\"&drone9x=\"+str(ref_loc[0][8])+\"&drone9y=\"+str(ref_loc[1][8])+\"&drone10x=\"+str(ref_loc[0][9])+\"&drone10y=\"+str(ref_loc[1][9])+\"&personx=\"+str(person[0])+\"&persony=\"+str(person[1])+\"&personorient=\"+str(personorientation)+\"&filename=\"+('Waypoint'+str(step_count))+\"&xlist=\"+(treex)+\"&ylist=\"+(treey)+\"&prevdrone1x=\"+str(prevwaypoints[0][0])+\"&prevdrone1y=\"+str(prevwaypoints[1][0])+\"&prevdrone2x=\"+str(prevwaypoints[0][1])+\"&prevdrone2y=\"+str(prevwaypoints[1][1])+\"&prevdrone3x=\"+str(prevwaypoints[0][2])+\"&prevdrone3y=\"+str(prevwaypoints[1][2])+\"&prevdrone4x=\"+str(prevwaypoints[0][3])+\"&prevdrone4y=\"+str(prevwaypoints[1][3])+\"&prevdrone5x=\"+str(prevwaypoints[0][4])+\"&prevdrone5y=\"+str(prevwaypoints[1][4])+\"&prevdrone6x=\"+str(prevwaypoints[0][5])+\"&prevdrone6y=\"+str(prevwaypoints[1][5])+\"&prevdrone7x=\"+str(prevwaypoints[0][6])+\"&prevdrone7y=\"+str(prevwaypoints[1][6])+\"&prevdrone8x=\"+str(prevwaypoints[0][7])+\"&prevdrone8y=\"+str(prevwaypoints[1][7])+\"&prevdrone9x=\"+str(prevwaypoints[0][8])+\"&prevdrone9y=\"+str(prevwaypoints[1][8])+\"&prevdrone10x=\"+str(prevwaypoints[0][9])+\"&prevdrone10y=\"+str(prevwaypoints[1][9])+\"&altd1=\"+str(altitude_list[0])+\"&altd2=\"+str(altitude_list[1])+\"&altd3=\"+str(altitude_list[2])+\"&altd4=\"+str(altitude_list[3])+\"&altd5=\"+str(altitude_list[4])+\"&altd6=\"+str(altitude_list[5])+\"&altd7=\"+str(altitude_list[6])+\"&altd8=\"+str(altitude_list[7])+\"&altd9=\"+str(altitude_list[8])+\"&altd10=\"+str(altitude_list[9])\n",
    "\n",
    "print(link1)\n",
    "Saved_Img_Location = \"Waypoint\"+str(step_count) + '.'+'zip'\n",
    "print(Saved_Img_Location)\n",
    "print(os.path.splitext(Saved_Img_Location)[0])\n",
    "Current_Waypoint_Images_Loc = os.path.join(Download_Location,'images', os.path.splitext(Saved_Img_Location)[0])\n",
    "os.mkdir(Current_Waypoint_Images_Loc)\n",
    "Current_Path = os.path.join(Download_Location,Saved_Img_Location)\n",
    "print(Current_Path)\n",
    "#############################Create Poses for Initial Positions###############################################################\n",
    "#############################Create Poses for Initial Positions###############################################################\n",
    "site_poses = []\n",
    "for i in range(NumberofDrones):\n",
    "    EastCentered = (ref_loc[0][i] - 0.0) #Get MeanEast and Set MeanEast\n",
    "    NorthCentered = (0.0 - ref_loc[1][i]) #Get MeanNorth and Set MeanNorth\n",
    "    Alt = dem_height\n",
    "    M = createviewmateuler(np.array([0.0, 0.0, 0.0]),np.array( [ref_loc[0][i], ref_loc[1][i], 35 - altitude_list[i]] ))\n",
    "    ViewMatrix = np.vstack((M, np.array([0.0,0.0,0.0,1.0],dtype=np.float32)))\n",
    "    camerapose = np.asarray(ViewMatrix.transpose(),dtype=np.float32)\n",
    "    site_poses.append(camerapose)  \n",
    "#############################Send the Link to Simulator to generate the images###############################################################\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "options = Options()\n",
    "\n",
    "\n",
    "options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "options.add_experimental_option(\"excludeSwitches\",[\"enable-automation\"])\n",
    "options.add_argument(\"start-maximized\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "driver.maximize_window()\n",
    "driver.get(link1)\n",
    "\n",
    "time.sleep(10)\n",
    "while not os.path.exists(Current_Path):\n",
    "    time.sleep(1)\n",
    "\n",
    "if os.path.isfile(Current_Path):\n",
    "    print(\"read file\")\n",
    "    with ZipFile(Current_Path,'r') as zipObj:\n",
    "        zipObj.extractall(path=Current_Path.split(\".\")[0])\n",
    "else:\n",
    "    print('error')#\n",
    "Current_Path = os.path.join(Download_Location,os.path.splitext(Saved_Img_Location)[0])\n",
    "#############################Read the generated images###############################################################\n",
    "single_images = []\n",
    "for i in range(NumberofDrones):\n",
    "    image_name = [os.path.basename(x) for x in sorted(glob.glob(os.path.join(Current_Path, drone_names[i], 'camera', '*.png')))]\n",
    "    g_1 = cv2.imread(os.path.join(Current_Path, drone_names[i], 'camera',image_name[0]))\n",
    "    g_2 = cv2.imread(os.path.join(Current_Path, drone_names[i], 'camera',image_name[1]),cv2.IMREAD_GRAYSCALE)\n",
    "    result = np.dstack((g_1, g_2))\n",
    "    print('result: ', result.shape)\n",
    "    \n",
    "    cv2.imwrite(os.path.join(Current_Path, drone_names[i], 'camera','test'+str(i)+'.png'),result)\n",
    "  \n",
    "    \n",
    "for i in range(NumberofDrones):\n",
    "    image_name = [os.path.basename(x) for x in sorted(glob.glob(os.path.join(Current_Path, drone_names[i], 'camera', '*.png')))]\n",
    "   \n",
    "    print('camera',image_name[0]) \n",
    "   \n",
    "    shutil.copy2(os.path.join(Current_Path, drone_names[i], 'camera',image_name[2]), os.path.join(Current_Waypoint_Images_Loc,image_name[2]))\n",
    "    img = cv2.imread(os.path.join(Current_Path, drone_names[i], 'camera',image_name[2]),cv2.IMREAD_UNCHANGED)\n",
    "    print('Image Dimensions :', img.shape)\n",
    "    single_images.append(img)\n",
    "print(os.path.splitext(Saved_Img_Location)[0])\n",
    "shutil.copy2(os.path.join(Current_Path, 'stage', 'cropped_image.png'), os.path.join(Stages_Path,os.path.splitext(Saved_Img_Location)[0]+'.png'))\n",
    "print(prevwaypoints)\n",
    "#############################For the First Step ---- Compute the Blob Threshold###############################################################\n",
    "\n",
    "center_rgb_integral_image, leader_rx_image, Leader_index, leader_contour = test_drone_pso.determine_emptyblob_threshold(single_images,site_poses, fov = fov, rxthreshold =  rxthreshold, dem_height = dem_height, compasscorrection = compasscorrection , pos = None)\n",
    "cv2.imwrite(\"rendered_image_setting_threshold.png\",center_rgb_integral_image)\n",
    "cv2.imwrite(\"leaderrx_image_setting_threshold.png\",leader_rx_image)\n",
    "print(leader_contour)\n",
    "print(Leader_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drone_pso.set_emptyblob_threshold(emptyblobthreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######################################Change Person Location After Initialization##########################################################\n",
    "step_count = 1\n",
    "print(ref_loc)\n",
    "print(prevwaypoints)\n",
    "\n",
    "drawing_current_location = ref_loc\n",
    "drawing_previous_location = prevwaypoints\n",
    "print(ref_loc)\n",
    "print(prevwaypoints)\n",
    "c = []\n",
    "for i in range (0, NumberofDrones):\n",
    "    distance = math.sqrt( ((ref_loc[0][i]-prevwaypoints[0][i])**2)+((ref_loc[1][i]-prevwaypoints[1][i])**2) )\n",
    "    c.append(distance)\n",
    "    \n",
    "print(c)\n",
    "max_distance =  max(c)    \n",
    "print(max(c))\n",
    "\n",
    "import json\n",
    "import os\n",
    "Dataloc = os.path.join(Download_Location,'data.json')\n",
    "d = {\n",
    "    1:ref_loc.tolist(),\n",
    "    2:prevwaypoints.tolist()\n",
    "}\n",
    "json.dump(d,open(Dataloc,\"w\"))\n",
    "personloc = os.path.join(Download_Location,'personpositions.json')\n",
    "jd = {\n",
    "    1:person,\n",
    "    \n",
    "}\n",
    "json.dump(jd,open(personloc,\"w\"))\n",
    "personorientloc = os.path.join(Download_Location,'personorientation.json')\n",
    "\n",
    "po = {\n",
    "    1:personorientation,\n",
    "    \n",
    "}\n",
    "json.dump(po,open(personorientloc,\"w\"))\n",
    "rectpositionsloc = os.path.join(Download_Location,'rectpositions.json')\n",
    "\n",
    "rt2 = {\n",
    "    \n",
    "    \n",
    "}\n",
    "json.dump(rt2,open(rectpositionsloc,\"w\"))\n",
    "blobpositionsloc = os.path.join(Download_Location,'blobpositions.json')\n",
    "import json\n",
    "bd ={\n",
    "        \n",
    "        \n",
    "    }\n",
    "json.dump(bd,open(blobpositionsloc,\"w\"))\n",
    "import json\n",
    "sdloc = os.path.join(Download_Location,'scanningwaypointdistance.json')\n",
    "sd ={\n",
    "        \n",
    "        \n",
    "    }\n",
    "json.dump(sd,open(sdloc,\"w\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "link1=\"http://127.0.0.1:5504/?drone1x=\"+str(ref_loc[0][0])+\"&drone1y=\"+str(ref_loc[1][0])+\"&drone2x=\"+str(ref_loc[0][1])+\"&drone2y=\"+str(ref_loc[1][1])+\"&drone3x=\"+str(ref_loc[0][2])+\"&drone3y=\"+str(ref_loc[1][2])+\"&drone4x=\"+str(ref_loc[0][3])+\"&drone4y=\"+str(ref_loc[1][3])+\"&drone5x=\"+str(ref_loc[0][4])+\"&drone5y=\"+str(ref_loc[1][4])+\"&drone6x=\"+str(ref_loc[0][5])+\"&drone6y=\"+str(ref_loc[1][5])+\"&drone7x=\"+str(ref_loc[0][6])+\"&drone7y=\"+str(ref_loc[1][6])+\"&drone8x=\"+str(ref_loc[0][7])+\"&drone8y=\"+str(ref_loc[1][7])+\"&drone9x=\"+str(ref_loc[0][8])+\"&drone9y=\"+str(ref_loc[1][8])+\"&drone10x=\"+str(ref_loc[0][9])+\"&drone10y=\"+str(ref_loc[1][9])+\"&personx=\"+str(person[0])+\"&persony=\"+str(person[1])+\"&personorient=\"+str(personorientation)+\"&filename=\"+('Waypoint'+str(step_count))+\"&xlist=\"+(treex)+\"&ylist=\"+(treey)+\"&prevdrone1x=\"+str(prevwaypoints[0][0])+\"&prevdrone1y=\"+str(prevwaypoints[1][0])+\"&prevdrone2x=\"+str(prevwaypoints[0][1])+\"&prevdrone2y=\"+str(prevwaypoints[1][1])+\"&prevdrone3x=\"+str(prevwaypoints[0][2])+\"&prevdrone3y=\"+str(prevwaypoints[1][2])+\"&prevdrone4x=\"+str(prevwaypoints[0][3])+\"&prevdrone4y=\"+str(prevwaypoints[1][3])+\"&prevdrone5x=\"+str(prevwaypoints[0][4])+\"&prevdrone5y=\"+str(prevwaypoints[1][4])+\"&prevdrone6x=\"+str(prevwaypoints[0][5])+\"&prevdrone6y=\"+str(prevwaypoints[1][5])+\"&prevdrone7x=\"+str(prevwaypoints[0][6])+\"&prevdrone7y=\"+str(prevwaypoints[1][6])+\"&prevdrone8x=\"+str(prevwaypoints[0][7])+\"&prevdrone8y=\"+str(prevwaypoints[1][7])+\"&prevdrone9x=\"+str(prevwaypoints[0][8])+\"&prevdrone9y=\"+str(prevwaypoints[1][8])+\"&prevdrone10x=\"+str(prevwaypoints[0][9])+\"&prevdrone10y=\"+str(prevwaypoints[1][9])+\"&altd1=\"+str(altitude_list[0])+\"&altd2=\"+str(altitude_list[1])+\"&altd3=\"+str(altitude_list[2])+\"&altd4=\"+str(altitude_list[3])+\"&altd5=\"+str(altitude_list[4])+\"&altd6=\"+str(altitude_list[5])+\"&altd7=\"+str(altitude_list[6])+\"&altd8=\"+str(altitude_list[7])+\"&altd9=\"+str(altitude_list[8])+\"&altd10=\"+str(altitude_list[9])+\"&leader=\"+str(Leader_index)\n",
    "# Leader_index\n",
    "print(link1)\n",
    "print(ref_loc)\n",
    "print(prevwaypoints)\n",
    "Saved_Img_Location = \"Waypoint\"+ str(step_count) + '.'+'zip'\n",
    "print(Saved_Img_Location)\n",
    "print(os.path.splitext(Saved_Img_Location)[0])\n",
    "Current_Waypoint_Images_Loc = os.path.join(Download_Location,'images', os.path.splitext(Saved_Img_Location)[0])\n",
    "os.mkdir(Current_Waypoint_Images_Loc)\n",
    "Current_Path = os.path.join(Download_Location,Saved_Img_Location)\n",
    "print(Current_Path)\n",
    "#############################Create Poses for Initial Positions###############################################################\n",
    "#############################Create Poses for Initial Positions###############################################################\n",
    "site_poses = []\n",
    "for i in range(NumberofDrones):\n",
    "    EastCentered = (ref_loc[0][i] - 0.0) #Get MeanEast and Set MeanEast\n",
    "    NorthCentered = (0.0 - ref_loc[1][i]) #Get MeanNorth and Set MeanNorth\n",
    "    Alt = dem_height\n",
    "    M = createviewmateuler(np.array([0.0, 0.0, 0.0]),np.array( [ref_loc[0][i], ref_loc[1][i],  35 - altitude_list[i]] ))\n",
    "    ViewMatrix = np.vstack((M, np.array([0.0,0.0,0.0,1.0],dtype=np.float32)))\n",
    "    camerapose = np.asarray(ViewMatrix.transpose(),dtype=np.float32)\n",
    "    site_poses.append(camerapose)\n",
    "#############################Send the Link to Simulator to generate the images###############################################################\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "driver.get(link1)\n",
    "driver.maximize_window()\n",
    "time.sleep(10)\n",
    "while not os.path.exists(Current_Path):\n",
    "    time.sleep(1)\n",
    "\n",
    "if os.path.isfile(Current_Path):\n",
    "    print(\"read file\")\n",
    "    with ZipFile(Current_Path,'r') as zipObj:\n",
    "        zipObj.extractall(path=Current_Path.split(\".\")[0])\n",
    "else:\n",
    "    print('error')#\n",
    "Current_Path = os.path.join(Download_Location,os.path.splitext(Saved_Img_Location)[0])\n",
    "#############################Read the generated images###############################################################\n",
    "single_images = []\n",
    "\n",
    "for i in range(NumberofDrones):\n",
    "    image_name = [os.path.basename(x) for x in sorted(glob.glob(os.path.join(Current_Path, drone_names[i], 'camera', '*.png')))]\n",
    "    g_1 = cv2.imread(os.path.join(Current_Path, drone_names[i], 'camera',image_name[0]))\n",
    "    g_2 = cv2.imread(os.path.join(Current_Path, drone_names[i], 'camera',image_name[1]),cv2.IMREAD_GRAYSCALE)\n",
    "    result = np.dstack((g_1, g_2))\n",
    "    print('result: ', result.shape)\n",
    "   \n",
    "    cv2.imwrite(os.path.join(Current_Path, drone_names[i], 'camera','test'+str(i)+'.png'),result)\n",
    "\n",
    "for i in range(NumberofDrones):\n",
    "    image_name = [os.path.basename(x) for x in sorted(glob.glob(os.path.join(Current_Path, drone_names[i], 'camera', '*.png')))]\n",
    "  \n",
    "    shutil.copy2(os.path.join(Current_Path, drone_names[i], 'camera',image_name[2]), os.path.join(Current_Waypoint_Images_Loc,image_name[2]))\n",
    "    \n",
    "    shutil.copy2(os.path.join(Current_Path, drone_names[i], 'camera',image_name[1]), os.path.join(Current_Waypoint_Images_Loc,image_name[1]))\n",
    "    img = cv2.imread(os.path.join(Current_Path, drone_names[i], 'camera',image_name[2]),cv2.IMREAD_UNCHANGED)\n",
    "    print('Image Dimensions :', img.shape)\n",
    "    single_images.append(img)\n",
    "print(os.path.splitext(Saved_Img_Location)[0])\n",
    "shutil.copy2(os.path.join(Current_Path, 'stage', 'cropped_image.png'), os.path.join(Stages_Path,os.path.splitext(Saved_Img_Location)[0]+'.png'))\n",
    "\n",
    "#############################For the First Step ---- Compute the Blob Threshold###############################################################\n",
    "\n",
    "\n",
    "aos.clearViews();\n",
    "print(ref_loc)\n",
    "print(prevwaypoints)\n",
    "prevwaypoints = ref_loc\n",
    "x_axis_mean = np.mean(np.asarray(ref_loc[0][:]))\n",
    "y_axis_mean = np.mean(np.asarray(ref_loc[1][:]))\n",
    "Alts = dem_height\n",
    "\n",
    "#############################For the First Step ---- Get the Next Locations###############################################################            \n",
    "center_EastCentered = (x_axis_mean - 0.0) #Get MeanEast and Set MeanEast\n",
    "center_NorthCentered = (0.0 - y_axis_mean) #Get MeanNorth and Set MeanNorth\n",
    "#center_M = createviewmateuler(np.array([(0.0), 0, 0]),np.array( [center_EastCentered, center_NorthCentered, -Alts] ))\n",
    "center_M = createviewmateuler(np.array([0.0, 0.0, 0.0]),np.array( [x_axis_mean, y_axis_mean, 0.0] ))\n",
    "center_ViewMatrix = np.vstack((center_M, np.array([0.0,0.0,0.0,1.0],dtype=np.float32)))\n",
    "center_camerapose = np.asarray(center_ViewMatrix.transpose(),dtype=np.float32)\n",
    "newgps, newloc, new_integral_image, new_leader_contour,new_leader_index,metric_area,cameraid,leader_blob_image, leader_rx_image,gen_integral_blob_img,rect,personorientation,blobposition = test_drone_pso.get_waypoints_with_pso_motion(single_images,site_poses,center_camerapose) ## Change Virtual Camera Pose to Center Position\n",
    "gen_integral_blob_img_bw = gen_integral_blob_img > 1\n",
    "leader_blob_image_bw = leader_blob_image > 1 \n",
    "print(\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",rect)\n",
    "print(\"yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy\",new_leader_index)\n",
    "cv2.imwrite(os.path.join( leader_blob_image_folder,  str(1)+ 'leader_blob_image.png'), np.asarray(leader_blob_image_bw*255,dtype=np.uint8))\n",
    "cv2.imwrite(os.path.join( leader_rx_image_folder,  str(1)+ 'leader_rx_image.png'), leader_rx_image)\n",
    "cv2.imwrite(os.path.join( gen_integral_blob_img_folder,  str(1)+ 'gen_integral_blob_img.png'), np.asarray(gen_integral_blob_img_bw*255,dtype=np.uint8))\n",
    "print(newloc)\n",
    "print(prevwaypoints)\n",
    "print(new_leader_contour)\n",
    "print(new_leader_index, cameraid)\n",
    "print(metric_area)\n",
    "drawing_leader_index = cameraid\n",
    "cameraloc = os.path.join(Download_Location,'cameraid.json')\n",
    "v1 = {\n",
    "    0:cameraid\n",
    "    \n",
    "}\n",
    "json.dump(v1,open(cameraloc,\"w\"))\n",
    "leaderloc = os.path.join(Download_Location,'leader.json')\n",
    "v12 = {\n",
    "    0:new_leader_index\n",
    "    \n",
    "}\n",
    "json.dump(v12,open(leaderloc,\"w\"))\n",
    "metricloc = os.path.join(Download_Location,'metric_area.json')\n",
    "v13 = {\n",
    "    0:metric_area\n",
    "  \n",
    "}\n",
    "json.dump(v13,open(metricloc,\"w\"))\n",
    "leadercontourloc = os.path.join(Download_Location,'new_leader_contour.json')\n",
    "v14 = {\n",
    "    0:new_leader_contour\n",
    "    \n",
    "}\n",
    "json.dump(v14,open(leadercontourloc,\"w\"))\n",
    "aos.clearViews();\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iter=1\n",
    "iter_list = []\n",
    "time_list = []\n",
    "metric_list = []\n",
    "k = 0\n",
    "metric_list.append(metric_area)\n",
    "iter_list.append(iter)\n",
    "\n",
    "print(metric_list)\n",
    "if max_distance == 0:\n",
    "    time_taken = 0\n",
    "else:    \n",
    "\n",
    "    time_taken = (max_distance/drone_speed)\n",
    "previous_time = time_taken\n",
    "time_list.append(time_taken)\n",
    "\n",
    "plt.axis([-0.5, 120, -40, 1500])\n",
    "print(time_list)\n",
    "print(metric_list)\n",
    "timeloc = os.path.join(Download_Location,'time_taken.json')\n",
    "v15 = {\n",
    "    0:time_taken\n",
    "    \n",
    "}\n",
    "json.dump(v15,open(timeloc,\"w\"))\n",
    "plt.xlabel(\"Time (seconds)\", fontsize=14)\n",
    "plt.ylabel(\"Metric\", fontsize=14)\n",
    "plt.plot(time_list, metric_list,'xb-', markersize = 6)\n",
    "save_results_to = os.path.join(Download_Location,'plots','image')\n",
    "\n",
    "plt.savefig(save_results_to + str(k) + '.png')\n",
    "print(metric_list[0])\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "iter = 1\n",
    "\n",
    "stageloc = os.path.join(Download_Location,'stages','Waypoint')\n",
    "\n",
    "stageimg = cv2.imread( stageloc + str(iter) + '.png')\n",
    "\n",
    "img_folder = os.path.join( Download_Location,'images','Waypoint' + str(iter))\n",
    "print(img_folder)\n",
    "import re\n",
    "\n",
    "numbers = re.compile(r'(\\d+)')\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts\n",
    "\n",
    "imagelist = []\n",
    "\n",
    "import glob\n",
    "\n",
    "\n",
    "\n",
    "for img in sorted(glob.glob( img_folder + '/*.png'),key=numericalSort):\n",
    "    n= cv2.imread(img)\n",
    "    imagelist.append(n)\n",
    "\n",
    "\n",
    "integral = []\n",
    "integral_img = os.path.join(Download_Location,'integrals')\n",
    "for imges in sorted(glob.glob(integral_img + '/*.png'),key=numericalSort):\n",
    "    r= cv2.imread(imges)\n",
    "    integral.append(r)\n",
    "    print('Image Dimensions :', r.shape)\n",
    "\n",
    "from cmath import tan\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "thermal_dimension = round((2*(altitude_list[drawing_leader_index])*0.4663*9.33))     # Fov is 50 so theta by 2 is 25  \n",
    "\n",
    "print(thermal_dimension)\n",
    "\n",
    "mask = np.ones((thermal_dimension,thermal_dimension,3), np.uint8)   #(should be changed based on the leader)\n",
    "h, w , k = mask.shape\n",
    "print(drawing_current_location[0][drawing_leader_index])\n",
    "xoff = round((467 + 33 + (9.33 * drawing_current_location[0][drawing_leader_index]) - (thermal_dimension /2)))  # leader x position instead of 18\n",
    "yoff = round((467 + 31 + (9.33 * drawing_current_location[1][drawing_leader_index]) - (thermal_dimension /2)))   # leader y position instead of zero\n",
    "result = stageimg.copy()\n",
    "result[yoff:yoff+h, xoff:xoff+w] = mask    \n",
    "\n",
    "final = result.copy()\n",
    "dim = (thermal_dimension,thermal_dimension)  #(should be changed based on the leader)\n",
    "thermalresizeimg = cv2.resize(integral[3], dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "h1, w1, k1 = thermalresizeimg.shape\n",
    "print('resiyedimage',h1,w1,k1)\n",
    "final[yoff:yoff+h1, xoff:xoff+w1] = thermalresizeimg\n",
    "for i in range (NumberofDrones):\n",
    "    x_currentposition = round(467 + 33 + ((275/(275-(altitude_list[i])))*9.33*drawing_current_location[0][i]))\n",
    "    y_currentposition = round(467 + 31 + ((275/(275-(altitude_list[i])))*9.33*drawing_current_location[1][i]))\n",
    "    x_previousposition = round(467 + 33 + ((275/(275-(altitude_list[i])))*9.33*drawing_previous_location[0][i]))\n",
    "    y_previousposition = round(467 + 31 + ((275/(275-(altitude_list[i])))*9.33*drawing_previous_location[1][i]))\n",
    "    print('x_currentposition',x_currentposition)\n",
    "    print('y_currentposition',y_currentposition)\n",
    "    print('x_previousposition',x_previousposition)\n",
    "    print('y_previousposition',y_previousposition)\n",
    "    cv2.circle(final, (x_currentposition, y_currentposition), 6, (255, 191, 0), -1)    # dimensions to be changed\n",
    "    leaderx_currentposition = round(467 + 33 + ((275/(275-(altitude_list[Leader_index])))*9.33*drawing_current_location[0][Leader_index]))\n",
    "    leadery_currentposition = round(467 + 31 + ((275/(275-(altitude_list[Leader_index])))*9.33*drawing_current_location[1][Leader_index]))    \n",
    "    cv2.circle(final, (leaderx_currentposition, leadery_currentposition), 6, (0, 255, 255), -1)   \n",
    "    \n",
    "    if (math.sqrt((x_previousposition-x_currentposition)**2 + (y_previousposition-y_currentposition)**2)) == 0 :\n",
    "            \n",
    "        division  = 0.1\n",
    "    else:\n",
    "        division  = (math.sqrt((x_previousposition-x_currentposition)**2 + (y_previousposition-y_currentposition)**2))\n",
    "    cv2.arrowedLine(final, (x_previousposition, y_previousposition), (x_currentposition, y_currentposition), (255,255,255), 3, tipLength= 10/division)  \n",
    "\n",
    "integral_metric = []\n",
    "integral_metric_img = os.path.join(Download_Location,'plots')\n",
    "for imges1 in sorted(glob.glob(integral_metric_img + '/*.png'),key=numericalSort):\n",
    "    r1= cv2.imread(imges1)\n",
    "    integral_metric.append(r1)\n",
    " \n",
    "leader_blob_image_list = []\n",
    "leader_img = os.path.join(Download_Location,'leader_blob_image')\n",
    "for imges in sorted(glob.glob(leader_img + '/*.png'),key=numericalSort):\n",
    "    r2= cv2.imread(imges)\n",
    "    leader_blob_image_list.append(r2)\n",
    "    \n",
    "leader_rx_image_list = []\n",
    "leaderrx_img = os.path.join(Download_Location,'leader_rx_image')\n",
    "for imges in sorted(glob.glob(leaderrx_img + '/*.png'),key=numericalSort):\n",
    "    r3= cv2.imread(imges)\n",
    "    leader_rx_image_list.append(r3)    \n",
    "    \n",
    "gen_integral_blob_img_list = []\n",
    "genintegral_img = os.path.join(Download_Location,'gen_integral_blob_img')\n",
    "for imges in sorted(glob.glob(genintegral_img + '/*.png'),key=numericalSort):\n",
    "    r4= cv2.imread(imges)\n",
    "    gen_integral_blob_img_list.append(r4)           \n",
    "\n",
    "dim = (1536,1542)\n",
    "dim1 =(256,256)\n",
    "dim2 =(512,512)\n",
    "white = [255,255,0]\n",
    "rgbimg1= cv2.copyMakeBorder(imagelist[10],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "rgbimg6= cv2.copyMakeBorder(imagelist[15],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "stimg= cv2.copyMakeBorder(final,1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "therimg1= cv2.copyMakeBorder(imagelist[0],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "therimg2= cv2.copyMakeBorder(imagelist[1],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "therimg3= cv2.copyMakeBorder(imagelist[2],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "therimg4= cv2.copyMakeBorder(imagelist[3],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "therimg5= cv2.copyMakeBorder(imagelist[4],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "therimg6= cv2.copyMakeBorder(imagelist[5],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "therimg7= cv2.copyMakeBorder(imagelist[6],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "therimg8= cv2.copyMakeBorder(imagelist[7],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "therimg9= cv2.copyMakeBorder(imagelist[8],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "therimg10= cv2.copyMakeBorder(imagelist[9],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "rgbimg2= cv2.copyMakeBorder(imagelist[11],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "rgbimg3= cv2.copyMakeBorder(imagelist[12],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "rgbimg4= cv2.copyMakeBorder(imagelist[13],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "rgbimg5= cv2.copyMakeBorder(imagelist[14],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "rgbimg7= cv2.copyMakeBorder(imagelist[16],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "rgbimg8= cv2.copyMakeBorder(imagelist[17],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "rgbimg9= cv2.copyMakeBorder(imagelist[18],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "rgbimg10= cv2.copyMakeBorder(imagelist[19],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "irgb1= cv2.copyMakeBorder(integral[2],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "it1= cv2.copyMakeBorder(integral[3],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "met1= cv2.copyMakeBorder(integral_metric[0],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "a1 = cv2.copyMakeBorder(leader_blob_image_list[0],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "a2 = cv2.copyMakeBorder(leader_rx_image_list[0],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "a3 = cv2.copyMakeBorder(gen_integral_blob_img_list[0],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "\n",
    "rgbimg1 = cv2.resize(rgbimg1, dim1, interpolation = cv2.INTER_AREA)\n",
    "rgbimg6 = cv2.resize(rgbimg6, dim1, interpolation = cv2.INTER_AREA)\n",
    "stimg = cv2.resize(stimg, dim, interpolation = cv2.INTER_AREA)\n",
    "therimg1 = cv2.resize(therimg1, dim1, interpolation = cv2.INTER_AREA)\n",
    "therimg2 = cv2.resize(therimg2, dim1, interpolation = cv2.INTER_AREA)\n",
    "therimg3 = cv2.resize(therimg3, dim1, interpolation = cv2.INTER_AREA)\n",
    "therimg4 = cv2.resize(therimg4, dim1, interpolation = cv2.INTER_AREA)\n",
    "therimg5 = cv2.resize(therimg5, dim1, interpolation = cv2.INTER_AREA)\n",
    "therimg6 = cv2.resize(therimg6, dim1, interpolation = cv2.INTER_AREA)\n",
    "therimg7 = cv2.resize(therimg7, dim1, interpolation = cv2.INTER_AREA)\n",
    "therimg8 = cv2.resize(therimg8, dim1, interpolation = cv2.INTER_AREA)\n",
    "therimg9 = cv2.resize(therimg9, dim1, interpolation = cv2.INTER_AREA)\n",
    "therimg10 = cv2.resize(therimg10, dim1, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "rgbimg2 = cv2.resize(rgbimg2, dim1, interpolation = cv2.INTER_AREA)\n",
    "rgbimg3 = cv2.resize(rgbimg3, dim1, interpolation = cv2.INTER_AREA)\n",
    "rgbimg4 = cv2.resize(rgbimg4, dim1, interpolation = cv2.INTER_AREA)\n",
    "rgbimg5 = cv2.resize(rgbimg5, dim1, interpolation = cv2.INTER_AREA)\n",
    "rgbimg7 = cv2.resize(rgbimg7, dim1, interpolation = cv2.INTER_AREA)\n",
    "rgbimg8 = cv2.resize(rgbimg8, dim1, interpolation = cv2.INTER_AREA)\n",
    "rgbimg9 = cv2.resize(rgbimg9, dim1, interpolation = cv2.INTER_AREA)\n",
    "rgbimg10 = cv2.resize(rgbimg10, dim1, interpolation = cv2.INTER_AREA)\n",
    "irgb1 = cv2.resize(irgb1, dim2, interpolation = cv2.INTER_AREA)\n",
    "it1 = cv2.resize(it1, dim2, interpolation = cv2.INTER_AREA)\n",
    "met1 = cv2.resize(met1, dim2, interpolation = cv2.INTER_AREA)\n",
    "a1 = cv2.resize(a1, dim1, interpolation = cv2.INTER_AREA)\n",
    "a2 = cv2.resize(a2, dim1, interpolation = cv2.INTER_AREA)\n",
    "a3 = cv2.resize(a3, dim1, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "h1, w1 = rgbimg1.shape[:2]\n",
    "h6, w6 = rgbimg6.shape[:2]\n",
    "sh1, sw1 = stimg.shape[:2]\n",
    "h11, w11 = therimg1.shape[:2]\n",
    "h12, w12 = therimg2.shape[:2]\n",
    "h13, w13 = therimg3.shape[:2]\n",
    "h14, w14 = therimg4.shape[:2]\n",
    "h15, w15 = therimg5.shape[:2]\n",
    "h16, w16 = therimg6.shape[:2]\n",
    "h17, w17 = therimg7.shape[:2]\n",
    "h18, w18 = therimg8.shape[:2]\n",
    "h19, w19 = therimg9.shape[:2]\n",
    "h20, w20 = therimg10.shape[:2]\n",
    "h2, w2 = rgbimg2.shape[:2]\n",
    "h3, w3 = rgbimg3.shape[:2]\n",
    "h4, w4 = rgbimg4.shape[:2]\n",
    "h5, w5 = rgbimg5.shape[:2]\n",
    "h7, w7 = rgbimg7.shape[:2]\n",
    "h8, w8 = rgbimg8.shape[:2]\n",
    "h9, w9 = rgbimg9.shape[:2]\n",
    "h10, w10 = rgbimg10.shape[:2]\n",
    "ih1, iw1 = irgb1.shape[:2]\n",
    "ith1, itw1 = it1.shape[:2]\n",
    "meth1, metw1 = met1.shape[:2]\n",
    "a1h, a1w = a1.shape[:2]\n",
    "a2h, a2w = a2.shape[:2]\n",
    "a3h, a3w = a3.shape[:2]\n",
    "\n",
    "\n",
    "img_3 = np.zeros((1542,3084,3), dtype=np.uint8)\n",
    "img_3[:h1, :w1,:3] = rgbimg1\n",
    "img_3[:h1, w1:w1+w6,:3] = rgbimg6\n",
    "img_3[:h6+h1+sh1, w1+w6:w1+w6+sw1 ,:3] = stimg\n",
    "img_3[:h1, w1+w6+sw1:w1+w6+sw1+w11 ,:3] = therimg1\n",
    "img_3[h1:h1+h2, w1+w6+sw1:w1+w6+sw1+w11 ,:3] = therimg2\n",
    "img_3[h1+h2:h1+h2+h3, w1+w6+sw1:w1+w6+sw1+w11 ,:3] = therimg3\n",
    "img_3[h1+h2+h3:h1+h2+h3+h4, w1+w6+sw1:w1+w6+sw1+w11 ,:3] = therimg4\n",
    "img_3[h1+h2+h3+h4:h1+h2+h3+h4+h5, w1+w6+sw1:w1+w6+sw1+w11 ,:3] = therimg5\n",
    "img_3[h1+h2+h3+h4+h5:h1+h2+h3+h4+h5+a1h, w1+w6+sw1:w1+w6+sw1+w11 ,:3] = a1\n",
    "\n",
    "img_3[:h1, w1+w6+sw1+w11:w1+w6+sw1+w11+w16 ,:3] = therimg6\n",
    "img_3[h1:h1+h2, w1+w6+sw1+w11:w1+w6+sw1+w11+w16 ,:3] = therimg7\n",
    "img_3[h1+h2:h1+h2+h3, w1+w6+sw1+w11:w1+w6+sw1+w11+w16 ,:3] = therimg8\n",
    "img_3[h1+h2+h3:h1+h2+h3+h4, w1+w6+sw1+w11:w1+w6+sw1+w11+w16 ,:3] = therimg9\n",
    "img_3[h1+h2+h3+h4:h1+h2+h3+h4+h5, w1+w6+sw1+w11:w1+w6+sw1+w11+w16 ,:3] = therimg10\n",
    "img_3[h1+h2+h3+h4+h5:h1+h2+h3+h4+h5+a3h, w1+w6+sw1+w11:w1+w6+sw1+w11+w16 ,:3] = a3\n",
    "img_3[h1:h1+h2, :w2,:3] = rgbimg2\n",
    "img_3[h1+h2:h1+h2+h3, :w3,:3] = rgbimg3\n",
    "img_3[h1+h2+h3:h1+h2+h3+h4, :w2,:3] = rgbimg4\n",
    "img_3[h1+h2+h3+h4:h1+h2+h3+h4+h5, :w2,:3] = rgbimg5\n",
    "img_3[h1:h1+h2, w1:w1+w7,:3] = rgbimg7\n",
    "img_3[h1+h2:h1+h2+h3, w1:w1+w8,:3] = rgbimg8\n",
    "img_3[h1+h2+h3:h1+h2+h3+h4, w1:w1+w9,:3] = rgbimg9\n",
    "img_3[h1+h2+h3+h4:h1+h2+h3+h4+h5, w1:w1+w10,:3] = rgbimg10\n",
    "img_3[:h1+h6, w1+w6+sw1+w11+w16:w1+w6+sw1+w11+w16+iw1,:3] = irgb1\n",
    "img_3[h1+h2:h1+h6+ith1, w1+w6+sw1+w11+w16:w1+w6+sw1+w11+w16+iw1,:3] = it1\n",
    "img_3[h1+h2+ith1:h1+h6+ith1+meth1, w1+w6+sw1+w11+w16:w1+w6+sw1+w11+w16+iw1,:3] = met1\n",
    "\n",
    "cv2.imwrite(os.path.join(Download_Location,'Final_result', ('stage_' + str(iter) + '.png')),img_3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ybefore = []\n",
    "yafter = []\n",
    "xbefore = []\n",
    "xafter = []\n",
    "ycamerabefore = []\n",
    "ycameraafter = []\n",
    "xcamerabefore = []\n",
    "xcameraafter = []\n",
    "cameralist = []\n",
    "leaderlist = []\n",
    "currentmeanx = []\n",
    "currentmeany =[]\n",
    "s = 1\n",
    "o = 3\n",
    "p = 4\n",
    "start_time_person = 0\n",
    "iter = 1\n",
    "step_count = 1\n",
    "old_theta = 270\n",
    "for i in range(300):\n",
    "    iter = iter + 1\n",
    "     \n",
    "    \n",
    "    aos.clearViews();\n",
    "    \n",
    "    step_count = step_count + 1\n",
    "    ref_loc = newloc\n",
    "   \n",
    "    print(ref_loc)\n",
    "     \n",
    "    drawing_current_location = ref_loc\n",
    "    drawing_previous_location = prevwaypoints\n",
    "    c = []\n",
    "    for i in range (0, NumberofDrones):\n",
    "        distance = math.sqrt( ((ref_loc[0][i]-prevwaypoints[0][i])**2)+((ref_loc[1][i]-prevwaypoints[1][i])**2) )\n",
    "        c.append(distance)\n",
    "        \n",
    "    print(c)\n",
    "    new_max_distance =  max(c)    \n",
    "    print(max(c))\n",
    "    \n",
    "    drone_totaltime = (new_max_distance/drone_speed)\n",
    "    total_time = start_time_person + drone_totaltime\n",
    "    \n",
    "    ########################### update person position for the next waypoints (circular path)\n",
    "    theta = 2*3.14*20\n",
    "    theta = theta/360\n",
    "    \n",
    "    person_speed = 4\n",
    "    personinx = person_speed * total_time\n",
    "    personiny = person_speed * total_time\n",
    "    new_theta = personinx / theta\n",
    "    old_theta  = old_theta + new_theta\n",
    "    x_dir = 20*np.cos(np.deg2rad(old_theta))\n",
    "    y_dir = -10 + (-20*np.sin(np.deg2rad(old_theta)))\n",
    "    new_person = [x_dir,y_dir]\n",
    "    dx = new_person[0] - person[0]\n",
    "    # Difference in y coordinates\n",
    "    dy = -new_person[1] +person[1]\n",
    "    # Angle between p1 and p2 in radians\n",
    "    personorientation = math.atan2(dy, dx)\n",
    "    personorientation = ((np.degrees(personorientation))%360)+90\n",
    "    person = new_person\n",
    "\n",
    "    ############################################################################\n",
    "    Dataloc = os.path.join(Download_Location,'data.json')\n",
    "\n",
    "    a = {\n",
    "        o:ref_loc.tolist(),\n",
    "        p:prevwaypoints.tolist()\n",
    "    }\n",
    "    with open(Dataloc , 'r+') as file:\n",
    "            data = json.load(file)\n",
    "            data.update(a)\n",
    "            file.seek(0)\n",
    "            json.dump(data, file)   \n",
    "          \n",
    "    personloc = os.path.join(Download_Location,'personpositions.json')       \n",
    "    jd1 = {\n",
    "        iter:person,\n",
    "    \n",
    "    }\n",
    "    with open(personloc,'r+') as file1:\n",
    "            data1 = json.load(file1)\n",
    "            data1.update(jd1)\n",
    "            file1.seek(0)\n",
    "            json.dump(data1, file1) \n",
    "\n",
    "    personorientloc = os.path.join(Download_Location,'personorientation.json') \n",
    "    po1 = {\n",
    "        iter:personorientation,\n",
    "        \n",
    "    }\n",
    "    with open(personorientloc,'r+') as file2: \n",
    "    \n",
    "            data2 = json.load(file2)\n",
    "            data2.update(po1)\n",
    "            file2.seek(0)\n",
    "            json.dump(data2, file2)      \n",
    "        \n",
    "    \n",
    "    \n",
    "    link1=\"http://127.0.0.1:5504/?drone1x=\"+str(ref_loc[0][0])+\"&drone1y=\"+str(ref_loc[1][0])+\"&drone2x=\"+str(ref_loc[0][1])+\"&drone2y=\"+str(ref_loc[1][1])+\"&drone3x=\"+str(ref_loc[0][2])+\"&drone3y=\"+str(ref_loc[1][2])+\"&drone4x=\"+str(ref_loc[0][3])+\"&drone4y=\"+str(ref_loc[1][3])+\"&drone5x=\"+str(ref_loc[0][4])+\"&drone5y=\"+str(ref_loc[1][4])+\"&drone6x=\"+str(ref_loc[0][5])+\"&drone6y=\"+str(ref_loc[1][5])+\"&drone7x=\"+str(ref_loc[0][6])+\"&drone7y=\"+str(ref_loc[1][6])+\"&drone8x=\"+str(ref_loc[0][7])+\"&drone8y=\"+str(ref_loc[1][7])+\"&drone9x=\"+str(ref_loc[0][8])+\"&drone9y=\"+str(ref_loc[1][8])+\"&drone10x=\"+str(ref_loc[0][9])+\"&drone10y=\"+str(ref_loc[1][9])+\"&personx=\"+str(person[0])+\"&persony=\"+str(person[1])+\"&personorient=\"+str(personorientation)+\"&filename=\"+('Waypoint'+str(step_count))+\"&xlist=\"+(treex)+\"&ylist=\"+(treey)+\"&prevdrone1x=\"+str(prevwaypoints[0][0])+\"&prevdrone1y=\"+str(prevwaypoints[1][0])+\"&prevdrone2x=\"+str(prevwaypoints[0][1])+\"&prevdrone2y=\"+str(prevwaypoints[1][1])+\"&prevdrone3x=\"+str(prevwaypoints[0][2])+\"&prevdrone3y=\"+str(prevwaypoints[1][2])+\"&prevdrone4x=\"+str(prevwaypoints[0][3])+\"&prevdrone4y=\"+str(prevwaypoints[1][3])+\"&prevdrone5x=\"+str(prevwaypoints[0][4])+\"&prevdrone5y=\"+str(prevwaypoints[1][4])+\"&prevdrone6x=\"+str(prevwaypoints[0][5])+\"&prevdrone6y=\"+str(prevwaypoints[1][5])+\"&prevdrone7x=\"+str(prevwaypoints[0][6])+\"&prevdrone7y=\"+str(prevwaypoints[1][6])+\"&prevdrone8x=\"+str(prevwaypoints[0][7])+\"&prevdrone8y=\"+str(prevwaypoints[1][7])+\"&prevdrone9x=\"+str(prevwaypoints[0][8])+\"&prevdrone9y=\"+str(prevwaypoints[1][8])+\"&prevdrone10x=\"+str(prevwaypoints[0][9])+\"&prevdrone10y=\"+str(prevwaypoints[1][9])+\"&altd1=\"+str(altitude_list[0])+\"&altd2=\"+str(altitude_list[1])+\"&altd3=\"+str(altitude_list[2])+\"&altd4=\"+str(altitude_list[3])+\"&altd5=\"+str(altitude_list[4])+\"&altd6=\"+str(altitude_list[5])+\"&altd7=\"+str(altitude_list[6])+\"&altd8=\"+str(altitude_list[7])+\"&altd9=\"+str(altitude_list[8])+\"&altd10=\"+str(altitude_list[9])+\"&leader=\"+str(new_leader_index)\n",
    "   \n",
    "    Saved_Img_Location = \"Waypoint\"+ str(step_count) + '.'+'zip'\n",
    "  \n",
    "    Current_Waypoint_Images_Loc = os.path.join(Download_Location,'images', os.path.splitext(Saved_Img_Location)[0])\n",
    "    os.mkdir(Current_Waypoint_Images_Loc)\n",
    "    Current_Path = os.path.join(Download_Location,Saved_Img_Location)\n",
    "\n",
    "    #############################Create Poses for Initial Positions###############################################################\n",
    "    site_poses = []\n",
    "    for i in range(NumberofDrones):\n",
    "        EastCentered = (ref_loc[0][i] - 0.0) #Get MeanEast and Set MeanEast\n",
    "        NorthCentered = (0.0 - ref_loc[1][i]) #Get MeanNorth and Set MeanNorth\n",
    "        Alt = dem_height\n",
    "        M = createviewmateuler(np.array([0.0, 0.0, 0.0]),np.array( [ref_loc[0][i], ref_loc[1][i], 35 - altitude_list[i]] ))\n",
    "        ViewMatrix = np.vstack((M, np.array([0.0,0.0,0.0,1.0],dtype=np.float32)))\n",
    "        camerapose = np.asarray(ViewMatrix.transpose(),dtype=np.float32)\n",
    "        site_poses.append(camerapose)\n",
    "    #############################Send the Link to Simulator to generate the images###############################################################\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    driver.get(link1)\n",
    "    driver.maximize_window()\n",
    "    time.sleep(10)\n",
    "    while not os.path.exists(Current_Path):\n",
    "        time.sleep(1)\n",
    "\n",
    "    if os.path.isfile(Current_Path):\n",
    "        #print(\"read file\")\n",
    "        with ZipFile(Current_Path,'r') as zipObj:\n",
    "            zipObj.extractall(path=Current_Path.split(\".\")[0])\n",
    "    else:\n",
    "        print('error')\n",
    "    Current_Path = os.path.join(Download_Location,os.path.splitext(Saved_Img_Location)[0])\n",
    "    #############################Read the generated images###############################################################\n",
    "    single_images = []\n",
    "    \n",
    "    for i in range(NumberofDrones):\n",
    "        image_name = [os.path.basename(x) for x in sorted(glob.glob(os.path.join(Current_Path, drone_names[i], 'camera', '*.png')))]\n",
    "        g_1 = cv2.imread(os.path.join(Current_Path, drone_names[i], 'camera',image_name[0]))\n",
    "        g_2 = cv2.imread(os.path.join(Current_Path, drone_names[i], 'camera',image_name[1]),cv2.IMREAD_GRAYSCALE)\n",
    "        result = np.dstack((g_1, g_2))\n",
    "        \n",
    "        cv2.imwrite(os.path.join(Current_Path, drone_names[i], 'camera','test'+str(i)+'.png'),result)\n",
    "    \n",
    "    for i in range(NumberofDrones):\n",
    "        image_name = [os.path.basename(x) for x in sorted(glob.glob(os.path.join(Current_Path, drone_names[i], 'camera', '*.png')))]\n",
    "\n",
    "        shutil.copy2(os.path.join(Current_Path, drone_names[i], 'camera',image_name[2]), os.path.join(Current_Waypoint_Images_Loc,image_name[2]))\n",
    "        shutil.copy2(os.path.join(Current_Path, drone_names[i], 'camera',image_name[1]), os.path.join(Current_Waypoint_Images_Loc,image_name[1]))\n",
    "        img = cv2.imread(os.path.join(Current_Path, drone_names[i], 'camera',image_name[2]),cv2.IMREAD_UNCHANGED)\n",
    "        single_images.append(img)\n",
    "    shutil.copy2(os.path.join(Current_Path, 'stage', 'cropped_image.png'), os.path.join(Stages_Path,os.path.splitext(Saved_Img_Location)[0]+'.png'))\n",
    "    #############################For the First Step ---- Compute the Blob Threshold###############################################################\n",
    "    x_axis_mean = np.mean(np.asarray(ref_loc[0][:]))\n",
    "    y_axis_mean = np.mean(np.asarray(ref_loc[1][:]))\n",
    "    Alts = dem_height\n",
    "\n",
    "    #############################For the First Step ---- Get the Next Locations###############################################################            \n",
    "    center_EastCentered = (x_axis_mean - 0.0) #Get MeanEast and Set MeanEast\n",
    "    center_NorthCentered = (0.0 - y_axis_mean) #Get MeanNorth and Set MeanNorth\n",
    "    center_M = createviewmateuler(np.array([0.0, 0.0, 0.0]),np.array( [x_axis_mean, y_axis_mean, 0.0] ))\n",
    "    center_ViewMatrix = np.vstack((center_M, np.array([0.0,0.0,0.0,1.0],dtype=np.float32)))\n",
    "    center_camerapose = np.asarray(center_ViewMatrix.transpose(),dtype=np.float32)\n",
    "\n",
    "    newgps, newloc, new_integral_image, new_leader_contour,new_leader_index,metric_area,cameraid,leader_blob_image, leader_rx_image,gen_integral_blob_img,rect,personorientation,blobposition = test_drone_pso.get_waypoints_with_pso_motion(single_images,site_poses,center_camerapose) ## Change Virtual Camera Pose to Center Position   #new_integral_img use this\n",
    " \n",
    "    gen_integral_blob_img_bw = gen_integral_blob_img > 1\n",
    "    leader_blob_image_bw = leader_blob_image > 1 \n",
    "    cv2.imwrite(os.path.join( leader_blob_image_folder,  str(s+1)+ 'leader_blob_image.png'), np.asarray(leader_blob_image_bw*255,dtype=np.uint8))\n",
    "    cv2.imwrite(os.path.join( leader_rx_image_folder,  str(s+1)+ 'leader_rx_image.png'), leader_rx_image)\n",
    "    cv2.imwrite(os.path.join( gen_integral_blob_img_folder,  str(s+1)+ 'gen_integral_blob_img.png'), np.asarray(gen_integral_blob_img_bw*255,dtype=np.uint8))\n",
    "    xafter.append(ref_loc)\n",
    "    yafter.append(ref_loc)\n",
    "    xbefore.append(prevwaypoints)\n",
    "    ybefore.append(prevwaypoints)\n",
    "    cameralist.append(cameraid)\n",
    "    #####################################3 following change to cameraid or new_leader_index \n",
    "    leaderlist.append(cameraid)\n",
    "    xcameraafter.append(ref_loc[0][cameraid])\n",
    "    ycameraafter.append(ref_loc[1][cameraid])\n",
    "    xcamerabefore.append(prevwaypoints[0][cameraid])\n",
    "    ycamerabefore.append(prevwaypoints[1][cameraid])\n",
    "    ############################################ for means centre of the pack\n",
    "    \n",
    "    currentmeanx.append(np.mean(ref_loc[0]))\n",
    "    currentmeany.append(np.mean(ref_loc[1])) \n",
    "    #########################################\n",
    "    \n",
    "    prevwaypoints = ref_loc\n",
    "    #print(prevwaypoints)\n",
    "    print(new_leader_index, cameraid)\n",
    "    print(new_leader_contour)\n",
    "    print(metric_area)\n",
    "    drawing_leader_index = cameraid\n",
    "    \n",
    "    leaderloc = os.path.join(Download_Location,'leader.json')\n",
    "\n",
    "   \n",
    "    v16 = {\n",
    "         o-1:new_leader_index,\n",
    "        \n",
    "    }\n",
    "\n",
    "    with open(leaderloc , 'r+') as file:\n",
    "            data1 = json.load(file)\n",
    "            data1.update(v16)\n",
    "            file.seek(0)\n",
    "            json.dump(data1, file)   \n",
    "            \n",
    "    cameraloc = os.path.join(Download_Location,'cameraid.json')\n",
    "   \n",
    "            \n",
    "    v17 = {\n",
    "         o-1:cameraid,\n",
    "        \n",
    "    }\n",
    "    with open(cameraloc , 'r+') as file:\n",
    "            data2 = json.load(file)\n",
    "            data2.update(v17)\n",
    "            file.seek(0)\n",
    "            json.dump(data2, file)      \n",
    "            \n",
    "    metricloc = os.path.join(Download_Location,'metric_area.json')\n",
    "        \n",
    "    v18 = {\n",
    "         o-1:metric_area,\n",
    "        \n",
    "    }\n",
    "    with open(metricloc , 'r+') as file:\n",
    "            data3 = json.load(file)\n",
    "            data3.update(v18)\n",
    "            file.seek(0)\n",
    "            json.dump(data3, file)              \n",
    "    \n",
    "    leadercontourloc = os.path.join(Download_Location,'new_leader_contour.json')\n",
    "                                            \n",
    "    v19 = {\n",
    "         o-1:new_leader_contour,\n",
    "        \n",
    "    }\n",
    "    with open(leadercontourloc , 'r+') as file:\n",
    "            data4 = json.load(file)\n",
    "            data4.update(v19)\n",
    "            file.seek(0)\n",
    "            json.dump(data4, file)                \n",
    "            \n",
    "    \n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    metric_list.append(metric_area)\n",
    "    iter_list.append(iter)\n",
    "    print(metric_list)\n",
    "    time_taken = (new_max_distance/drone_speed)\n",
    "    previous_time = previous_time + time_taken\n",
    "    time_list.append(previous_time)\n",
    "    \n",
    "    timeloc = os.path.join(Download_Location,'time_taken.json')\n",
    "\n",
    "    \n",
    "    v20 = {\n",
    "         o-1:previous_time,\n",
    "        \n",
    "    }\n",
    "    with open(timeloc , 'r+') as file:\n",
    "            data5 = json.load(file)\n",
    "            data5.update(v20)\n",
    "            file.seek(0)\n",
    "            json.dump(data5, file)   \n",
    "    \n",
    "    plt.axis([-0.5, 120, -40, 1500])\n",
    "    plt.xlabel(\"Time (seconds)\", fontsize=14)\n",
    "    plt.ylabel(\"Metric\", fontsize=14)\n",
    "    plt.plot(time_list, metric_list,'xb-',markersize = 6)\n",
    "    \n",
    "    print(time_taken)\n",
    "    print(time_list)\n",
    "    print(metric_list)\n",
    "\n",
    "    save_results_to = os.path.join(Download_Location,'plots','image')\n",
    "    plt.savefig(save_results_to + str(iter-1) + '.png')\n",
    "    print(metric_list)\n",
    "    aos.clearViews();\n",
    "\n",
    "    #############################For the Second Step ---- Generate the link from the new locations############################################################### \n",
    "\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    import os\n",
    "    \n",
    "    stageloc = os.path.join(Download_Location,'stages','Waypoint')\n",
    "\n",
    "    stageimg = cv2.imread( stageloc + str(iter) + '.png')\n",
    "\n",
    "    img_folder = os.path.join( Download_Location,'images','Waypoint' + str(iter))\n",
    "    import re\n",
    "\n",
    "    numbers = re.compile(r'(\\d+)')\n",
    "    def numericalSort(value):\n",
    "        parts = numbers.split(value)\n",
    "        parts[1::2] = map(int, parts[1::2])\n",
    "        return parts\n",
    "\n",
    "    imagelist = []\n",
    "\n",
    "    import glob\n",
    "\n",
    "    for img in sorted(glob.glob(img_folder + '/*.png'),key=numericalSort):\n",
    "        n= cv2.imread(img)\n",
    "        imagelist.append(n)\n",
    "    \n",
    "    integral = []\n",
    "    integral_img = os.path.join(Download_Location,'integrals')\n",
    "    for imges in sorted(glob.glob(integral_img + '/*.png'),key=numericalSort):\n",
    "        r= cv2.imread(imges)\n",
    "        integral.append(r)\n",
    "        \n",
    "        \n",
    "    thermal_dimension = round((2*(altitude_list[drawing_leader_index])*0.4663*9.33))     # Fov is 50 so theta by 2 is 25  \n",
    "\n",
    "    print(thermal_dimension)\n",
    "\n",
    "    mask = np.ones((thermal_dimension,thermal_dimension,3), np.uint8)   #(should be changed based on the leader)\n",
    "    h, w , k = mask.shape\n",
    "    print(drawing_current_location[0][drawing_leader_index])\n",
    "    xoff = round((467 + 33 + (9.33 * drawing_current_location[0][drawing_leader_index]) - (thermal_dimension /2)))  # leader x position instead of 18\n",
    "    yoff = round((467 + 31 + (9.33 * drawing_current_location[1][drawing_leader_index]) - (thermal_dimension /2)))   # leader y position instead of zero\n",
    "    result = stageimg.copy()\n",
    "    result[yoff:yoff+h, xoff:xoff+w] = mask    \n",
    "\n",
    "    final = result.copy()\n",
    "    dim = (thermal_dimension,thermal_dimension)  #(should be changed based on the leader)\n",
    "    thermalresizeimg = cv2.resize(integral[(iter*3)+(iter-1)], dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    h1, w1, k1 = thermalresizeimg.shape\n",
    "    print('resiyedimage',h1,w1,k1)\n",
    "    final[yoff:yoff+h1, xoff:xoff+w1] = thermalresizeimg\n",
    "    \n",
    "    if s>=2:    \n",
    "        \n",
    "        g = 2   \n",
    "        h = 1 \n",
    "        for m in range (len(xbefore) - 1):\n",
    "                \n",
    "                x_1 = round(467 + 33 + ((275/(275-(np.mean(altitude_list))))*9.33*currentmeanx[h]))   # k replace with a number as index for a drone \n",
    "                y_1 = round(467 + 31 + ((275/(275-(np.mean(altitude_list))))*9.33*currentmeany[h]))\n",
    "                x_0 = round(467 + 33 + ((275/(275-(np.mean(altitude_list))))*9.33*currentmeanx[h-1]))\n",
    "                y_0 = round(467 + 31 + ((275/(275-(np.mean(altitude_list))))*9.33*currentmeany[h-1]))\n",
    "                cv2.line(final,(x_0,y_0),(x_1,y_1),(255,0,0),2)\n",
    "                \n",
    "                \n",
    "        for m in range (len(xbefore)  - 1 ):        \n",
    "            if ((len(xbefore)) >=3  and  g < (len(xbefore))):\n",
    "                    \n",
    "                    x_1 = round(467 + 33 + ((275/(275-(np.mean(altitude_list))))*9.33*currentmeanx[g]))   # k replace with a number as index for a drone \n",
    "                    y_1 = round(467 + 31 + ((275/(275-(np.mean(altitude_list))))*9.33*currentmeany[g]))\n",
    "                    x_0 = round(467 + 33 + ((275/(275-(np.mean(altitude_list))))*9.33*currentmeanx[g-1]))\n",
    "                    y_0 = round(467 + 31 + ((275/(275-(np.mean(altitude_list))))*9.33*currentmeany[g-1]))\n",
    "                    g = g + 1\n",
    "\n",
    "    \n",
    "                    cv2.line(final,(x_0,y_0),(x_1,y_1),(255,0,0),2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for k in range (NumberofDrones):\n",
    "        x_currentposition = round(467 + 33 + ((275/(275-(altitude_list[k])))*9.33*drawing_current_location[0][k]))\n",
    "        y_currentposition = round(467 + 31 + ((275/(275-(altitude_list[k])))*9.33*drawing_current_location[1][k]))\n",
    "        x_previousposition = round(467 + 33 + ((275/(275-(altitude_list[k])))*9.33*drawing_previous_location[0][k]))\n",
    "        y_previousposition = round(467 + 31 + ((275/(275-(altitude_list[k])))*9.33*drawing_previous_location[1][k]))\n",
    "\n",
    "\n",
    "        cv2.circle(final, (x_currentposition, y_currentposition), 6, (255, 191, 0), -1)    # dimensions to be changed\n",
    "        \n",
    "        # dimensions to be changed\n",
    "\n",
    "        leaderx_currentposition = round(467 + 33 + ((275/(275-(altitude_list[new_leader_index])))*9.33*drawing_current_location[0][new_leader_index]))\n",
    "        leadery_currentposition = round(467 + 31 + ((275/(275-(altitude_list[new_leader_index])))*9.33*drawing_current_location[1][new_leader_index]))    \n",
    "        cv2.circle(final, (leaderx_currentposition, leadery_currentposition), 6, (0, 255, 255), -1)   \n",
    "        \n",
    "        if (math.sqrt((x_previousposition-x_currentposition)**2 + (y_previousposition-y_currentposition)**2)) == 0 :\n",
    "            \n",
    "            division  = 0.1\n",
    "        else:\n",
    "            division  = (math.sqrt((x_previousposition-x_currentposition)**2 + (y_previousposition-y_currentposition)**2))  \n",
    "            \n",
    "       \n",
    "        cv2.arrowedLine(final, (x_previousposition, y_previousposition), (x_currentposition, y_currentposition), (255,255,255), 3, tipLength= 10/division)    \n",
    "      \n",
    "    integral_metric = []\n",
    "    integral_metric_img = os.path.join(Download_Location,'plots')\n",
    "    for imges1 in sorted(glob.glob(integral_metric_img + '/*.png'),key=numericalSort):\n",
    "        r1= cv2.imread(imges1)\n",
    "        integral_metric.append(r1)\n",
    "        \n",
    "    leader_blob_image_list = []\n",
    "    leader_img = os.path.join(Download_Location,'leader_blob_image')\n",
    "    for imges in sorted(glob.glob(leader_img + '/*.png'),key=numericalSort):\n",
    "        r2= cv2.imread(imges)\n",
    "        leader_blob_image_list.append(r2)\n",
    "        \n",
    "    leader_rx_image_list = []\n",
    "    leaderrx_img = os.path.join(Download_Location,'leader_rx_image')\n",
    "    for imges in sorted(glob.glob(leaderrx_img + '/*.png'),key=numericalSort):\n",
    "        r3= cv2.imread(imges)\n",
    "        leader_rx_image_list.append(r3)    \n",
    "        \n",
    "    gen_integral_blob_img_list = []\n",
    "    genintegral_img = os.path.join(Download_Location,'gen_integral_blob_img')\n",
    "    for imges in sorted(glob.glob(genintegral_img + '/*.png'),key=numericalSort):\n",
    "        r4= cv2.imread(imges)\n",
    "        gen_integral_blob_img_list.append(r4) \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    dim = (1536,1542)\n",
    "    dim1 =(256,256)\n",
    "    dim2 =(512,512)\n",
    "    white = [255,255,0]\n",
    "    rgbimg1= cv2.copyMakeBorder(imagelist[10],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    rgbimg6= cv2.copyMakeBorder(imagelist[15],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    stimg= cv2.copyMakeBorder(final,1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    therimg1= cv2.copyMakeBorder(imagelist[0],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    therimg2= cv2.copyMakeBorder(imagelist[1],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    therimg3= cv2.copyMakeBorder(imagelist[2],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    therimg4= cv2.copyMakeBorder(imagelist[3],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    therimg5= cv2.copyMakeBorder(imagelist[4],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    therimg6= cv2.copyMakeBorder(imagelist[5],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    therimg7= cv2.copyMakeBorder(imagelist[6],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    therimg8= cv2.copyMakeBorder(imagelist[7],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    therimg9= cv2.copyMakeBorder(imagelist[8],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    therimg10= cv2.copyMakeBorder(imagelist[9],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    rgbimg2= cv2.copyMakeBorder(imagelist[11],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    rgbimg3= cv2.copyMakeBorder(imagelist[12],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    rgbimg4= cv2.copyMakeBorder(imagelist[13],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    rgbimg5= cv2.copyMakeBorder(imagelist[14],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    rgbimg7= cv2.copyMakeBorder(imagelist[16],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    rgbimg8= cv2.copyMakeBorder(imagelist[17],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    rgbimg9= cv2.copyMakeBorder(imagelist[18],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    rgbimg10= cv2.copyMakeBorder(imagelist[19],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    irgb1= cv2.copyMakeBorder(integral[(iter*3)+(iter-2)],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    it1= cv2.copyMakeBorder(integral[(iter*3)+(iter-1)],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    met1= cv2.copyMakeBorder(integral_metric[iter-1],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    a1 = cv2.copyMakeBorder(leader_blob_image_list[s],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    a2 = cv2.copyMakeBorder(leader_rx_image_list[s],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "    a3 = cv2.copyMakeBorder(gen_integral_blob_img_list[s],1,1,1,1,cv2.BORDER_CONSTANT,value=white)\n",
    "\n",
    "    rgbimg1 = cv2.resize(rgbimg1, dim1, interpolation = cv2.INTER_AREA)\n",
    "    rgbimg6 = cv2.resize(rgbimg6, dim1, interpolation = cv2.INTER_AREA)\n",
    "    stimg = cv2.resize(stimg, dim, interpolation = cv2.INTER_AREA)\n",
    "    therimg1 = cv2.resize(therimg1, dim1, interpolation = cv2.INTER_AREA)\n",
    "    therimg2 = cv2.resize(therimg2, dim1, interpolation = cv2.INTER_AREA)\n",
    "    therimg3 = cv2.resize(therimg3, dim1, interpolation = cv2.INTER_AREA)\n",
    "    therimg4 = cv2.resize(therimg4, dim1, interpolation = cv2.INTER_AREA)\n",
    "    therimg5 = cv2.resize(therimg5, dim1, interpolation = cv2.INTER_AREA)\n",
    "    therimg6 = cv2.resize(therimg6, dim1, interpolation = cv2.INTER_AREA)\n",
    "    therimg7 = cv2.resize(therimg7, dim1, interpolation = cv2.INTER_AREA)\n",
    "    therimg8 = cv2.resize(therimg8, dim1, interpolation = cv2.INTER_AREA)\n",
    "    therimg9 = cv2.resize(therimg9, dim1, interpolation = cv2.INTER_AREA)\n",
    "    therimg10 = cv2.resize(therimg10, dim1, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    rgbimg2 = cv2.resize(rgbimg2, dim1, interpolation = cv2.INTER_AREA)\n",
    "    rgbimg3 = cv2.resize(rgbimg3, dim1, interpolation = cv2.INTER_AREA)\n",
    "    rgbimg4 = cv2.resize(rgbimg4, dim1, interpolation = cv2.INTER_AREA)\n",
    "    rgbimg5 = cv2.resize(rgbimg5, dim1, interpolation = cv2.INTER_AREA)\n",
    "    rgbimg7 = cv2.resize(rgbimg7, dim1, interpolation = cv2.INTER_AREA)\n",
    "    rgbimg8 = cv2.resize(rgbimg8, dim1, interpolation = cv2.INTER_AREA)\n",
    "    rgbimg9 = cv2.resize(rgbimg9, dim1, interpolation = cv2.INTER_AREA)\n",
    "    rgbimg10 = cv2.resize(rgbimg10, dim1, interpolation = cv2.INTER_AREA)\n",
    "    irgb1 = cv2.resize(irgb1, dim2, interpolation = cv2.INTER_AREA)\n",
    "    it1 = cv2.resize(it1, dim2, interpolation = cv2.INTER_AREA)\n",
    "    met1 = cv2.resize(met1, dim2, interpolation = cv2.INTER_AREA)\n",
    "    a1 = cv2.resize(a1, dim1, interpolation = cv2.INTER_AREA)\n",
    "    a2 = cv2.resize(a2, dim1, interpolation = cv2.INTER_AREA)\n",
    "    a3 = cv2.resize(a3, dim1, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "    h1, w1 = rgbimg1.shape[:2]\n",
    "    h6, w6 = rgbimg6.shape[:2]\n",
    "    sh1, sw1 = stimg.shape[:2]\n",
    "    h11, w11 = therimg1.shape[:2]\n",
    "    h12, w12 = therimg2.shape[:2]\n",
    "    h13, w13 = therimg3.shape[:2]\n",
    "    h14, w14 = therimg4.shape[:2]\n",
    "    h15, w15 = therimg5.shape[:2]\n",
    "    h16, w16 = therimg6.shape[:2]\n",
    "    h17, w17 = therimg7.shape[:2]\n",
    "    h18, w18 = therimg8.shape[:2]\n",
    "    h19, w19 = therimg9.shape[:2]\n",
    "    h20, w20 = therimg10.shape[:2]\n",
    "    h2, w2 = rgbimg2.shape[:2]\n",
    "    h3, w3 = rgbimg3.shape[:2]\n",
    "    h4, w4 = rgbimg4.shape[:2]\n",
    "    h5, w5 = rgbimg5.shape[:2]\n",
    "    h7, w7 = rgbimg7.shape[:2]\n",
    "    h8, w8 = rgbimg8.shape[:2]\n",
    "    h9, w9 = rgbimg9.shape[:2]\n",
    "    h10, w10 = rgbimg10.shape[:2]\n",
    "    ih1, iw1 = irgb1.shape[:2]\n",
    "    ith1, itw1 = it1.shape[:2]\n",
    "    meth1, metw1 = met1.shape[:2]\n",
    "    a1h, a1w = a1.shape[:2]\n",
    "    a2h, a2w = a2.shape[:2]\n",
    "    a3h, a3w = a3.shape[:2]\n",
    "\n",
    "\n",
    "    img_3 = np.zeros((1542,3084,3), dtype=np.uint8)\n",
    "    img_3[:h1, :w1,:3] = rgbimg1\n",
    "    img_3[:h1, w1:w1+w6,:3] = rgbimg6\n",
    "    img_3[:h6+h1+sh1, w1+w6:w1+w6+sw1 ,:3] = stimg\n",
    "    img_3[:h1, w1+w6+sw1:w1+w6+sw1+w11 ,:3] = therimg1\n",
    "    img_3[h1:h1+h2, w1+w6+sw1:w1+w6+sw1+w11 ,:3] = therimg2\n",
    "    img_3[h1+h2:h1+h2+h3, w1+w6+sw1:w1+w6+sw1+w11 ,:3] = therimg3\n",
    "    img_3[h1+h2+h3:h1+h2+h3+h4, w1+w6+sw1:w1+w6+sw1+w11 ,:3] = therimg4\n",
    "    img_3[h1+h2+h3+h4:h1+h2+h3+h4+h5, w1+w6+sw1:w1+w6+sw1+w11 ,:3] = therimg5\n",
    "    img_3[h1+h2+h3+h4+h5:h1+h2+h3+h4+h5+a1h, w1+w6+sw1:w1+w6+sw1+w11 ,:3] = a1\n",
    "    img_3[:h1, w1+w6+sw1+w11:w1+w6+sw1+w11+w16 ,:3] = therimg6\n",
    "    img_3[h1:h1+h2, w1+w6+sw1+w11:w1+w6+sw1+w11+w16 ,:3] = therimg7\n",
    "    img_3[h1+h2:h1+h2+h3, w1+w6+sw1+w11:w1+w6+sw1+w11+w16 ,:3] = therimg8\n",
    "    img_3[h1+h2+h3:h1+h2+h3+h4, w1+w6+sw1+w11:w1+w6+sw1+w11+w16 ,:3] = therimg9\n",
    "    img_3[h1+h2+h3+h4:h1+h2+h3+h4+h5, w1+w6+sw1+w11:w1+w6+sw1+w11+w16 ,:3] = therimg10\n",
    "    img_3[h1+h2+h3+h4+h5:h1+h2+h3+h4+h5+a3h, w1+w6+sw1+w11:w1+w6+sw1+w11+w16 ,:3] = a3\n",
    "    img_3[h1:h1+h2, :w2,:3] = rgbimg2\n",
    "    img_3[h1+h2:h1+h2+h3, :w3,:3] = rgbimg3\n",
    "    img_3[h1+h2+h3:h1+h2+h3+h4, :w2,:3] = rgbimg4\n",
    "    img_3[h1+h2+h3+h4:h1+h2+h3+h4+h5, :w2,:3] = rgbimg5\n",
    "    img_3[h1:h1+h2, w1:w1+w7,:3] = rgbimg7\n",
    "    img_3[h1+h2:h1+h2+h3, w1:w1+w8,:3] = rgbimg8\n",
    "    img_3[h1+h2+h3:h1+h2+h3+h4, w1:w1+w9,:3] = rgbimg9\n",
    "    img_3[h1+h2+h3+h4:h1+h2+h3+h4+h5, w1:w1+w10,:3] = rgbimg10\n",
    "    img_3[:h1+h6, w1+w6+sw1+w11+w16:w1+w6+sw1+w11+w16+iw1,:3] = irgb1\n",
    "    img_3[h1+h2:h1+h6+ith1, w1+w6+sw1+w11+w16:w1+w6+sw1+w11+w16+iw1,:3] = it1\n",
    "    img_3[h1+h2+ith1:h1+h6+ith1+meth1, w1+w6+sw1+w11+w16:w1+w6+sw1+w11+w16+iw1,:3] = met1\n",
    "\n",
    "\n",
    "    cv2.imwrite(os.path.join(Download_Location,'Final_result', ('stage_' + str(iter) + '.png')),img_3)\n",
    "    s = s+1\n",
    "    o = o+2\n",
    "    p = p+2\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0546a8624a4a236bae0f9fea37c96b2936c9ad1821cd89b71f7783537db0568"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
